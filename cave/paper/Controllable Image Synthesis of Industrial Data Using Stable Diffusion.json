{"title": "Controllable Image Synthesis of Industrial Data Using Stable Diffusion", "summary": "Training supervised deep neural networks that perform defect detection and\nsegmentation requires large-scale fully-annotated datasets, which can be hard\nor even impossible to obtain in industrial environments. Generative AI offers\nopportunities to enlarge small industrial datasets artificially, thus enabling\nthe usage of state-of-the-art supervised approaches in the industry.\nUnfortunately, also good generative models need a lot of data to train, while\nindustrial datasets are often tiny. Here, we propose a new approach for reusing\ngeneral-purpose pre-trained generative models on industrial data, ultimately\nallowing the generation of self-labelled defective images. First, we let the\nmodel learn the new concept, entailing the novel data distribution. Then, we\nforce it to learn to condition the generative process, producing industrial\nimages that satisfy well-defined topological characteristics and show defects\nwith a given geometry and location. To highlight the advantage of our approach,\nwe use the synthetic dataset to optimise a crack segmentor for a real\nindustrial use case. When the available data is small, we observe considerable\nperformance increase under several metrics, showing the method's potential in\nproduction environments.", "tags": ["supervised deep neural networks", "defect detection", "defect segmentation", "generative AI", "artificial dataset enlargement", "state-of-the-art approaches", "industrial environments", "industrial datasets", "pre-trained generative models", "self-labelled images", "data distribution", "industrial images", "topological characteristics", "geometry", "segmentation", "industrial use case", "small datasets", "performance increase", "production environments", "deep learning", "image generation", "data augmentation", "neural networks"], "citations": [], "date": "2024-01-06", "pdf_path": ""}
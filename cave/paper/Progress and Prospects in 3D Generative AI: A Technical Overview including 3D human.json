{"title": "Progress and Prospects in 3D Generative AI: A Technical Overview including 3D human", "summary": "While AI-generated text and 2D images continue to expand its territory, 3D\ngeneration has gradually emerged as a trend that cannot be ignored. Since the\nyear 2023 an abundant amount of research papers has emerged in the domain of 3D\ngeneration. This growth encompasses not just the creation of 3D objects, but\nalso the rapid development of 3D character and motion generation. Several key\nfactors contribute to this progress. The enhanced fidelity in stable diffusion,\ncoupled with control methods that ensure multi-view consistency, and realistic\nhuman models like SMPL-X, contribute synergistically to the production of 3D\nmodels with remarkable consistency and near-realistic appearances. The\nadvancements in neural network-based 3D storing and rendering models, such as\nNeural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), have\naccelerated the efficiency and realism of neural rendered models. Furthermore,\nthe multimodality capabilities of large language models have enabled language\ninputs to transcend into human motion outputs. This paper aims to provide a\ncomprehensive overview and summary of the relevant papers published mostly\nduring the latter half year of 2023. It will begin by discussing the AI\ngenerated object models in 3D, followed by the generated 3D human models, and\nfinally, the generated 3D human motions, culminating in a conclusive summary\nand a vision for the future.", "tags": ["AI-generated text", "3D generation", "3D objects", "3D character generation", "3D motion generation", "stable diffusion", "multi-view consistency", "SMPL-X", "Neural Radiance Fields (NeRF)", "3D Gaussian Splatting (3DGS)", "neural network-based", "rendering models", "multimodality", "large language models", "AI-generated images", "machine learning", "computer vision"], "citations": [], "date": "2024-01-05", "pdf_path": ""}
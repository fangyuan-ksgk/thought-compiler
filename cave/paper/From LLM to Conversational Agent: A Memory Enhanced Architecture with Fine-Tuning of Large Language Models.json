{"title": "From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models", "summary": "This paper introduces RAISE (Reasoning and Acting through Scratchpad and\nExamples), an advanced architecture enhancing the integration of Large Language\nModels (LLMs) like GPT-4 into conversational agents. RAISE, an enhancement of\nthe ReAct framework, incorporates a dual-component memory system, mirroring\nhuman short-term and long-term memory, to maintain context and continuity in\nconversations. It entails a comprehensive agent construction scenario,\nincluding phases like Conversation Selection, Scene Extraction, CoT Completion,\nand Scene Augmentation, leading to the LLMs Training phase. This approach\nappears to enhance agent controllability and adaptability in complex,\nmulti-turn dialogues. Our preliminary evaluations in a real estate sales\ncontext suggest that RAISE has some advantages over traditional agents,\nindicating its potential for broader applications. This work contributes to the\nAI field by providing a robust framework for developing more context-aware and\nversatile conversational agents.", "tags": ["RAISE", "conversational agents", "Large Language Models", "GPT-4", "human memory", "conversations", "agent construction scenario", "Conversation Selection", "Scene Extraction", "CoT Completion", "Scene Augmentation", "LLMs Training", "agent controllability", "adapatability", "multi-turn dialogues", "AI", "natural language processing", "machine learning", "AI field", "context-aware", "versatile conversational agents"], "citations": [], "date": "2024-01-05", "pdf_path": ""}
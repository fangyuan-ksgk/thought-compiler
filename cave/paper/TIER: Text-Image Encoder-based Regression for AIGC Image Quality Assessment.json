{"title": "TIER: Text-Image Encoder-based Regression for AIGC Image Quality Assessment", "summary": "Recently, AIGC image quality assessment (AIGCIQA), which aims to assess the\nquality of AI-generated images (AIGIs) from a human perception perspective, has\nemerged as a new topic in computer vision. Unlike common image quality\nassessment tasks where images are derived from original ones distorted by\nnoise, blur, and compression, \\textit{etc.}, in AIGCIQA tasks, images are\ntypically generated by generative models using text prompts. Considerable\nefforts have been made in the past years to advance AIGCIQA. However, most\nexisting AIGCIQA methods regress predicted scores directly from individual\ngenerated images, overlooking the information contained in the text prompts of\nthese images. This oversight partially limits the performance of these AIGCIQA\nmethods. To address this issue, we propose a text-image encoder-based\nregression (TIER) framework. Specifically, we process the generated images and\ntheir corresponding text prompts as inputs, utilizing a text encoder and an\nimage encoder to extract features from these text prompts and generated images,\nrespectively. To demonstrate the effectiveness of our proposed TIER method, we\nconduct extensive experiments on several mainstream AIGCIQA databases,\nincluding AGIQA-1K, AGIQA-3K, and AIGCIQA2023. The experimental results\nindicate that our proposed TIER method generally demonstrates superior\nperformance compared to baseline in most cases.", "tags": ["image quality assessment", "AIGIQA", "computer vision", "generative models", "text prompts", "AIGCIQA", "regression", "text encoder", "image encoder", "feature extraction", "benchmarking databases", "AGIQA-1K", "AGIQA-3K", "AIGCIQA2023", "machine learning", "artificial intelligence", "deep learning"], "citations": [], "date": "2024-01-08", "pdf_path": ""}
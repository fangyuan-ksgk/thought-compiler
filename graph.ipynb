{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph integration \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import crawl_arxiv_papers \n",
    "\n",
    "# crawl_arxiv_papers() # This will always crawl the latest 200 papers regarding AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import read_quick_info\n",
    "\n",
    "quick_info = read_quick_info() # quick selection required (maybe some human input on each batch here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human-in-the-loop Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Annotated, Literal, List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class Paper(TypedDict):\n",
    "    title: str\n",
    "    summary: str\n",
    "    post: str\n",
    "    comment: str\n",
    "    score: int\n",
    "    argument: str # Argument needs to be approved by a human\n",
    "\n",
    "def add_papers(left: List[Paper], right: List[Paper]) -> List[Paper]:\n",
    "    # When there are duplicate titles, we merge, otherwise we concatenate\n",
    "    merged = {paper['title']: paper for paper in left}\n",
    "    for paper in right:\n",
    "        if paper['title'] in merged:\n",
    "            # Merge the papers with the same title\n",
    "            merged[paper['title']] = Paper(\n",
    "                title=paper['title'],\n",
    "                summary=paper['summary'],\n",
    "                post=paper['post'] if paper['post'] else merged[paper['title']]['post'],\n",
    "                comment=merged[paper['title']]['comment'] if merged[paper['title']]['comment'] else paper['comment'],\n",
    "                score=(merged[paper['title']]['score'] + paper['score']) / 2 if merged[paper['title']]['score'] != 0 and paper['score'] != 0 else max(merged[paper['title']]['score'], paper['score']),\n",
    "                argument=merged[paper['title']]['argument'] if merged[paper['title']]['argument'] else paper['argument']\n",
    "            )\n",
    "        else:\n",
    "            merged[paper['title']] = paper\n",
    "    return list(merged.values())\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    papers: Annotated[list, add_papers]\n",
    "    \n",
    "# initial node should\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test paper selection node \n",
    "# I think a customized agent for AI research might already worth quite a lot (if we could customize it to be efficient enough)\n",
    "SELECT_PAPER_PROMPT = \"\"\"Here is a list of papers with their summaries. \\n{paper_string}\\nFor each paper, conduct an analysis, provide your comment on the contribution and limitations of the paper, as well as a score between 0 and 100 indicating its importance.\n",
    "Your response should be in a JSON format as a list of dictionaries. Each dictionary should have the following keys: title, comment, score. For example:\n",
    "[\n",
    "    {{\n",
    "        \"title\": \"Paper Title 1\",\n",
    "        \"comment\": \"Comment on the importance and contribution of the paper\",\n",
    "        \"score\": 80\n",
    "    }},\n",
    "    {{\n",
    "        \"title\": \"Paper Title 2\",\n",
    "        \"comment\": \"Another comment on a different paper\",\n",
    "        \"score\": 75\n",
    "    }}\n",
    "]\n",
    "\n",
    "Please provide your analysis for each paper in the list.\"\"\"\n",
    "\n",
    "\n",
    "ARGUMENT_PROMPT = \"\"\"Provide argument on why the paper {paper_title} is the best among the selected papers: {paper_string}\"\"\"\n",
    "\n",
    "\n",
    "from src.utils import papers_to_string, parse_paper_response, initialize_papers, add_papers\n",
    "from langchain_openai import ChatOpenAI\n",
    "from src.utils import load_papers\n",
    "\n",
    "class CrawlNode:\n",
    "    def __init__(self, name: str, refresh: bool = False):\n",
    "        self.name = name\n",
    "        self.path = \"cave/arxiv_papers_info.json\"\n",
    "        self.refresh = refresh\n",
    "    def __call__(self, state: State): # Wonderful, now it works (!) I am starting to like LangGraph now ...\n",
    "        list_of_papers = load_papers(refresh=self.refresh, file_path=self.path)\n",
    "        return {\"papers\": list_of_papers}\n",
    "    \n",
    "\n",
    "class SelectNode:\n",
    "    def __init__(self, batch_id: int, model: ChatOpenAI):\n",
    "        self.model = model\n",
    "        self.batch_id = batch_id\n",
    "\n",
    "    def __call__(self, state: State):\n",
    "        papers = state[\"papers\"]\n",
    "        batch_size = 10\n",
    "\n",
    "        start_index = self.batch_id * batch_size\n",
    "        end_index = min((self.batch_id + 1) * batch_size, len(papers))\n",
    "\n",
    "        batch_papers = papers[start_index:end_index]\n",
    "        paper_string = papers_to_string(batch_papers)\n",
    "        select_prompt = SELECT_PAPER_PROMPT.format(paper_string=paper_string)\n",
    "\n",
    "        response = self.model.invoke(select_prompt)\n",
    "        paper_response = parse_paper_response(response.content)\n",
    "        processed_batch = initialize_papers(paper_response)\n",
    "        batch_papers = add_papers(batch_papers, processed_batch) \n",
    "\n",
    "        # Update the state with the processed and verified papers\n",
    "        return {\"papers\": batch_papers}\n",
    "    \n",
    "    \n",
    "class ArgumentNode:\n",
    "    def __init__(self, batch_id: int, model: ChatOpenAI):\n",
    "        self.model = model \n",
    "        self.batch_id = batch_id\n",
    "        \n",
    "    def __call__(self, state: State):\n",
    "        papers = state[\"papers\"]\n",
    "        batch_size = 10\n",
    "        start_index = self.batch_id * batch_size\n",
    "        end_index = min((self.batch_id + 1) * batch_size, len(papers))\n",
    "        batch_papers = papers[start_index:end_index]\n",
    "        \n",
    "        best_paper = max(batch_papers, key=lambda x: x['score'])\n",
    "        best_paper_title = best_paper['title']\n",
    "        best_paper_string = papers_to_string([best_paper])\n",
    "        argument_prompt = ARGUMENT_PROMPT.format(paper_title=best_paper_title, paper_string=best_paper_string)\n",
    "        response = self.model.invoke(argument_prompt)\n",
    "        best_paper['argument'] = response.content\n",
    "        return {\"papers\": best_paper}\n",
    "    \n",
    "# Human Approval Node - focus on paper with argument over its batch \n",
    "class HumanApprovalNode:\n",
    "    def __init__(self, batch_id: int, model: ChatOpenAI):\n",
    "        self.model = model\n",
    "        self.batch_id = batch_id\n",
    "        \n",
    "    def __call__(self, state: State):\n",
    "        papers = state[\"papers\"]\n",
    "        raise NotImplementedError(\"Human Approval Node is not implemented yet\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fractal_nodes(builder, current_node, level, max_level):\n",
    "    if level > max_level:\n",
    "        return\n",
    "\n",
    "    # Number of nodes to create at this level\n",
    "    node_names = [f\"Paper_Batch_{i}\" for i in range(20)]\n",
    "    num_nodes = random.randint(1, 3)  # Adjust randomness as needed\n",
    "    for i in range(num_nodes):\n",
    "        nm = node_names[i]\n",
    "        node_name = f\"node_{current_node}_{nm}\"\n",
    "        builder.add_node(node_name, SelectNode(node_name))\n",
    "        builder.add_edge(current_node, node_name)\n",
    "\n",
    "        # Recursively add more nodes\n",
    "        r = random.random()\n",
    "        if r > 0.2 and level + 1 < max_level:\n",
    "            add_fractal_nodes(builder, node_name, level + 1, max_level)\n",
    "        elif r > 0.05:\n",
    "            builder.add_conditional_edges(node_name, route, node_name)\n",
    "        else:\n",
    "            # End\n",
    "            builder.add_edge(node_name, \"__end__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "    \n",
    "def build_research_graph(): # Researcher LangGraph Agent\n",
    "    builder = StateGraph(State)\n",
    "    entry_point = \"crawl_arxiv_node\"\n",
    "    builder.add_node(entry_point, CrawlNode(entry_point))\n",
    "    builder.add_edge(START, entry_point)\n",
    "\n",
    "    # Pending a paper selection node, and a human selection node\n",
    "    # LLM call on each paper to provide comment and a score\n",
    "    # We would ask it to do a comparative analysis on each cluster and ask human's verification\n",
    "\n",
    "    # Optional: set a finish point if required\n",
    "    builder.add_edge(entry_point, END)  # or any specific node\n",
    "\n",
    "    return builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution result:\n",
      "{'messages': [], 'papers': [{'title': 'Transformer Explainer: Interactive Learning of Text-Generative Models', 'summary': \"Transformers have revolutionized machine learning, yet their inner workings\\nremain opaque to many. We present Transformer Explainer, an interactive\\nvisualization tool designed for non-experts to learn about Transformers through\\nthe GPT-2 model. Our tool helps users understand complex Transformer concepts\\nby integrating a model overview and enabling smooth transitions across\\nabstraction levels of mathematical operations and model structures. It runs a\\nlive GPT-2 instance locally in the user's browser, empowering users to\\nexperiment with their own input and observe in real-time how the internal\\ncomponents and parameters of the Transformer work together to predict the next\\ntokens. Our tool requires no installation or special hardware, broadening the\\npublic's education access to modern generative AI techniques. Our open-sourced\\ntool is available at https://poloclub.github.io/transformer-explainer/. A video\\ndemo is available at https://youtu.be/ECR4oAwocjs.\", 'post': '', 'evaluation': ''}, {'title': 'Quantifying the Impact of Population Shift Across Age and Sex for Abdominal Organ Segmentation', 'summary': 'Deep learning-based medical image segmentation has seen tremendous progress\\nover the last decade, but there is still relatively little transfer into\\nclinical practice. One of the main barriers is the challenge of domain\\ngeneralisation, which requires segmentation models to maintain high performance\\nacross a wide distribution of image data. This challenge is amplified by the\\nmany factors that contribute to the diverse appearance of medical images, such\\nas acquisition conditions and patient characteristics. The impact of shifting\\npatient characteristics such as age and sex on segmentation performance remains\\nrelatively under-studied, especially for abdominal organs, despite that this is\\ncrucial for ensuring the fairness of the segmentation model. We perform the\\nfirst study to determine the impact of population shift with respect to age and\\nsex on abdominal CT image segmentation, by leveraging two large public\\ndatasets, and introduce a novel metric to quantify the impact. We find that\\npopulation shift is a challenge similar in magnitude to cross-dataset shift for\\nabdominal organ segmentation, and that the effect is asymmetric and\\ndataset-dependent. We conclude that dataset diversity in terms of known patient\\ncharacteristics is not necessarily equivalent to dataset diversity in terms of\\nimage features. This implies that simple population matching to ensure good\\ngeneralisation and fairness may be insufficient, and we recommend that fairness\\nresearch should be directed towards better understanding and quantifying\\nmedical image dataset diversity in terms of performance-relevant\\ncharacteristics such as organ morphology.', 'post': '', 'evaluation': ''}, {'title': 'Criticizing Ethics According to Artificial Intelligence', 'summary': 'This article presents a critique of ethics in the context of artificial\\nintelligence (AI). It argues for the need to question established patterns of\\nthought and traditional authorities, including core concepts such as autonomy,\\nmorality, and ethics. These concepts are increasingly inadequate to deal with\\nthe complexities introduced by emerging AI and autonomous agents. This critique\\nhas several key components: clarifying conceptual ambiguities, honestly\\naddressing epistemic issues, and thoroughly exploring fundamental normative\\nproblems. The ultimate goal is to reevaluate and possibly redefine some\\ntraditional ethical concepts to better address the challenges posed by AI.', 'post': '', 'evaluation': ''}, {'title': 'Enhanced Prototypical Part Network (EPPNet) For Explainable Image Classification Via Prototypes', 'summary': \"Explainable Artificial Intelligence (xAI) has the potential to enhance the\\ntransparency and trust of AI-based systems. Although accurate predictions can\\nbe made using Deep Neural Networks (DNNs), the process used to arrive at such\\npredictions is usually hard to explain. In terms of perceptibly human-friendly\\nrepresentations, such as word phrases in text or super-pixels in images,\\nprototype-based explanations can justify a model's decision. In this work, we\\nintroduce a DNN architecture for image classification, the Enhanced\\nPrototypical Part Network (EPPNet), which achieves strong performance while\\ndiscovering relevant prototypes that can be used to explain the classification\\nresults. This is achieved by introducing a novel cluster loss that helps to\\ndiscover more relevant human-understandable prototypes. We also introduce a\\nfaithfulness score to evaluate the explainability of the results based on the\\ndiscovered prototypes. Our score not only accounts for the relevance of the\\nlearned prototypes but also the performance of a model. Our evaluations on the\\nCUB-200-2011 dataset show that the EPPNet outperforms state-of-the-art\\nxAI-based methods, in terms of both classification accuracy and explainability\", 'post': '', 'evaluation': ''}, {'title': 'SAM2-Adapter: Evaluating & Adapting Segment Anything 2 in Downstream Tasks: Camouflage, Shadow, Medical Image Segmentation, and More', 'summary': \"The advent of large models, also known as foundation models, has\\nsignificantly transformed the AI research landscape, with models like Segment\\nAnything (SAM) achieving notable success in diverse image segmentation\\nscenarios. Despite its advancements, SAM encountered limitations in handling\\nsome complex low-level segmentation tasks like camouflaged object and medical\\nimaging. In response, in 2023, we introduced SAM-Adapter, which demonstrated\\nimproved performance on these challenging tasks. Now, with the release of\\nSegment Anything 2 (SAM2), a successor with enhanced architecture and a larger\\ntraining corpus, we reassess these challenges. This paper introduces\\nSAM2-Adapter, the first adapter designed to overcome the persistent limitations\\nobserved in SAM2 and achieve new state-of-the-art (SOTA) results in specific\\ndownstream tasks including medical image segmentation, camouflaged (concealed)\\nobject detection, and shadow detection. SAM2-Adapter builds on the\\nSAM-Adapter's strengths, offering enhanced generalizability and composability\\nfor diverse applications. We present extensive experimental results\\ndemonstrating SAM2-Adapter's effectiveness. We show the potential and encourage\\nthe research community to leverage the SAM2 model with our SAM2-Adapter for\\nachieving superior segmentation outcomes. Code, pre-trained models, and data\\nprocessing protocols are available at\\nhttp://tianrun-chen.github.io/SAM-Adaptor/\", 'post': '', 'evaluation': ''}, {'title': 'SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals', 'summary': 'Explainable Artificial Intelligence (XAI) is essential for enhancing the\\ntransparency and accountability of AI models, especially in natural language\\nprocessing (NLP) tasks. This paper introduces SCENE (Soft Counterfactual\\nEvaluation for Natural language Explainability), a novel evaluation method that\\nleverages large language models (LLMs) to generate Soft Counterfactual\\nexplanations in a zero-shot manner. By focusing on token-based substitutions,\\nSCENE creates contextually appropriate and seman-tically meaningful Soft\\nCounterfactuals without extensive fine-tuning. SCENE adopts Validitysoft and\\nCsoft metrics to evaluate the effectiveness of model-agnostic XAI methods in\\ntext classification tasks. Applied to CNN, RNN, and BERT architectures, SCENE\\nprovides valuable insights into the strengths and limitations of various XAI\\ntechniques.', 'post': '', 'evaluation': ''}, {'title': 'Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models', 'summary': \"Large language models (LLMs) have exhibited remarkable proficiency across a\\ndiverse array of natural language processing (NLP) tasks. However, adapting\\nLLMs to downstream applications typically necessitates computationally\\nintensive and memory-demanding fine-tuning procedures. To mitigate these\\nburdens, parameter-efficient fine-tuning (PEFT) techniques have emerged as a\\npromising approach to tailor LLMs with minimal computational overhead. While\\nPEFT methods offer substantial advantages, they do not fully address the\\npervasive issue of bias propagation from pre-training data. In this work, we\\nintroduce Bias-Aware Low-Rank Adaptation (BA-LoRA), a novel PEFT method\\ndesigned to counteract bias inheritance. BA-LoRA incorporates three distinct\\nregularization terms: (1) consistency regularizer, (2) diversity regularizer,\\nand (3) singular vector decomposition regularizer. These regularizers\\ncollectively aim to improve the generative models' consistency, diversity, and\\ngeneralization capabilities during the fine-tuning process. Through extensive\\nexperiments on a variety of natural language understanding (NLU) and natural\\nlanguage generation (NLG) tasks, employing prominent LLMs such as LLaMA,\\nMistral, and Gemma, we demonstrate that BA-LoRA surpasses the performance of\\nLoRA and its state-of-the-art variants. Moreover, our method effectively\\nmitigates the deleterious effects of pre-training bias, leading to more\\nreliable and robust model outputs. The code is available at\\nhttps://github.com/cyp-jlu-ai/BA-LoRA.\", 'post': '', 'evaluation': ''}, {'title': 'Balancing Efficiency with Equality: Auction Design with Group Fairness Concerns', 'summary': \"The issue of fairness in AI arises from discriminatory practices in\\napplications like job recommendations and risk assessments, emphasising the\\nneed for algorithms that do not discriminate based on group characteristics.\\nThis concern is also pertinent to auctions, commonly used for resource\\nallocation, which necessitate fairness considerations. Our study examines\\nauctions with groups distinguished by specific attributes, seeking to (1)\\ndefine a fairness notion that ensures equitable treatment for all, (2) identify\\nmechanisms that adhere to this fairness while preserving incentive\\ncompatibility, and (3) explore the balance between fairness and seller's\\nrevenue. We introduce two fairness notions-group fairness and individual\\nfairness-and propose two corresponding auction mechanisms: the Group\\nProbability Mechanism, which meets group fairness and incentive criteria, and\\nthe Group Score Mechanism, which also encompasses individual fairness. Through\\nexperiments, we validate these mechanisms' effectiveness in promoting fairness\\nand examine their implications for seller revenue.\", 'post': '', 'evaluation': ''}, {'title': 'ParetoTracker: Understanding Population Dynamics in Multi-objective Evolutionary Algorithms through Visual Analytics', 'summary': 'Multi-objective evolutionary algorithms (MOEAs) have emerged as powerful\\ntools for solving complex optimization problems characterized by multiple,\\noften conflicting, objectives. While advancements have been made in\\ncomputational efficiency as well as diversity and convergence of solutions, a\\ncritical challenge persists: the internal evolutionary mechanisms are opaque to\\nhuman users. Drawing upon the successes of explainable AI in explaining complex\\nalgorithms and models, we argue that the need to understand the underlying\\nevolutionary operators and population dynamics within MOEAs aligns well with a\\nvisual analytics paradigm. This paper introduces ParetoTracker, a visual\\nanalytics framework designed to support the comprehension and inspection of\\npopulation dynamics in the evolutionary processes of MOEAs. Informed by\\npreliminary literature review and expert interviews, the framework establishes\\na multi-level analysis scheme, which caters to user engagement and exploration\\nranging from examining overall trends in performance metrics to conducting\\nfine-grained inspections of evolutionary operations. In contrast to\\nconventional practices that require manual plotting of solutions for each\\ngeneration, ParetoTracker facilitates the examination of temporal trends and\\ndynamics across consecutive generations in an integrated visual interface. The\\neffectiveness of the framework is demonstrated through case studies and expert\\ninterviews focused on widely adopted benchmark optimization problems.', 'post': '', 'evaluation': ''}, {'title': 'Saliency Detection in Educational Videos: Analyzing the Performance of Current Models, Identifying Limitations and Advancement Directions', 'summary': \"Identifying the regions of a learning resource that a learner pays attention\\nto is crucial for assessing the material's impact and improving its design and\\nrelated support systems. Saliency detection in videos addresses the automatic\\nrecognition of attention-drawing regions in single frames. In educational\\nsettings, the recognition of pertinent regions in a video's visual stream can\\nenhance content accessibility and information retrieval tasks such as video\\nsegmentation, navigation, and summarization. Such advancements can pave the way\\nfor the development of advanced AI-assisted technologies that support learning\\nwith greater efficacy. However, this task becomes particularly challenging for\\neducational videos due to the combination of unique characteristics such as\\ntext, voice, illustrations, animations, and more. To the best of our knowledge,\\nthere is currently no study that evaluates saliency detection approaches in\\neducational videos. In this paper, we address this gap by evaluating four\\nstate-of-the-art saliency detection approaches for educational videos. We\\nreproduce the original studies and explore the replication capabilities for\\ngeneral-purpose (non-educational) datasets. Then, we investigate the\\ngeneralization capabilities of the models and evaluate their performance on\\neducational videos. We conduct a comprehensive analysis to identify common\\nfailure scenarios and possible areas of improvement. Our experimental results\\nshow that educational videos remain a challenging context for generic video\\nsaliency detection models.\", 'post': '', 'evaluation': ''}, {'title': 'SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios', 'summary': 'Most of the sophisticated AI models utilize huge amounts of annotated data\\nand heavy training to achieve high-end performance. However, there are certain\\nchallenges that hinder the deployment of AI models \"in-the-wild\" scenarios,\\ni.e., inefficient use of unlabeled data, lack of incorporation of human\\nexpertise, and lack of interpretation of the results. To mitigate these\\nchallenges, we propose a novel Explainable Active Learning (XAL) model,\\nXAL-based semantic segmentation model \"SegXAL\", that can (i) effectively\\nutilize the unlabeled data, (ii) facilitate the \"Human-in-the-loop\" paradigm,\\nand (iii) augment the model decisions in an interpretable way. In particular,\\nwe investigate the application of the SegXAL model for semantic segmentation in\\ndriving scene scenarios. The SegXAL model proposes the image regions that\\nrequire labeling assistance from Oracle by dint of explainable AI (XAI) and\\nuncertainty measures in a weakly-supervised manner. Specifically, we propose a\\nnovel Proximity-aware Explainable-AI (PAE) module and Entropy-based Uncertainty\\n(EBU) module to get an Explainable Error Mask, which enables the machine\\nteachers/human experts to provide intuitive reasoning behind the results and to\\nsolicit feedback to the AI system via an active learning strategy. Such a\\nmechanism bridges the semantic gap between man and machine through\\ncollaborative intelligence, where humans and AI actively enhance each other\\'s\\ncomplementary strengths. A novel high-confidence sample selection technique\\nbased on the DICE similarity coefficient is also presented within the SegXAL\\nframework. Extensive quantitative and qualitative analyses are carried out in\\nthe benchmarking Cityscape dataset. Results show the outperformance of our\\nproposed SegXAL against other state-of-the-art models.', 'post': '', 'evaluation': ''}, {'title': 'NFDI4Health workflow and service for synthetic data generation, assessment and risk management', 'summary': \"Individual health data is crucial for scientific advancements, particularly\\nin developing Artificial Intelligence (AI); however, sharing real patient\\ninformation is often restricted due to privacy concerns. A promising solution\\nto this challenge is synthetic data generation. This technique creates entirely\\nnew datasets that mimic the statistical properties of real data, while\\npreserving confidential patient information. In this paper, we present the\\nworkflow and different services developed in the context of Germany's National\\nData Infrastructure project NFDI4Health. First, two state-of-the-art AI tools\\n(namely, VAMBN and MultiNODEs) for generating synthetic health data are\\noutlined. Further, we introduce SYNDAT (a public web-based tool) which allows\\nusers to visualize and assess the quality and risk of synthetic data provided\\nby desired generative models. Additionally, the utility of the proposed methods\\nand the web-based tool is showcased using data from Alzheimer's Disease\\nNeuroimaging Initiative (ADNI) and the Center for Cancer Registry Data of the\\nRobert Koch Institute (RKI).\", 'post': '', 'evaluation': ''}, {'title': 'Analysis of the dynamics of the decay $D^{+}\\\\to K_{S}^{0} π^{0} e^{+}ν_{e}$', 'summary': 'The branching fraction of $D^+\\\\to K_{S}^{0} \\\\pi^{0}e^+\\\\nu_e$ is measured for\\nthe first time using $7.93~\\\\mathrm{fb}^{-1}$ of $e^+e^-$ annihilation data\\ncollected at the center-of-mass energy $\\\\sqrt{s}=3.773$~GeV with the BESIII\\ndetector operating at the BEPCII collider, and is determined to be ${\\\\mathcal\\nB}$($D^+\\\\to K_S^0\\\\pi^0e^+\\\\nu_e$) = $(0.881~\\\\pm~0.017_{\\\\rm stat.}~\\\\pm~0.016_{\\\\rm\\nsyst.})$\\\\%. Based on an analysis of the $D^+\\\\to K_S^0\\\\pi^0e^+\\\\nu_e$ decay\\ndynamics, we observe the $S\\\\text{-}{\\\\rm wave}$ and $P$-wave components with\\nfractions of $f_{S\\\\text{-}{\\\\rm wave}}$ = $(6.13~\\\\pm~0.27_{\\\\rm stat.}~\\\\pm\\n~0.30_{\\\\rm syst.})\\\\%$ and $f_{\\\\bar K^{*}(892)^0}$ = $(93.88~\\\\pm~0.27_{\\\\rm\\nstat.}~\\\\pm~0.29_{\\\\rm syst.})$\\\\%, respectively. From these results, we obtain\\nthe branching fractions ${\\\\mathcal B}$($D^+\\\\to (K_S^0\\\\pi^0)_{S\\\\text{-}{\\\\rm\\nwave}}~e^+\\\\nu_e$) = $(5.41~\\\\pm~0.35_{\\\\rm stat.}~\\\\pm~0.37_{\\\\rm\\nsyst.})\\\\times10^{-4}$ and ${\\\\mathcal B}$($D^+\\\\to \\\\bar K^{*}(892)^0e^+\\\\nu_e$) =\\n$(4.97~\\\\pm~0.11_{\\\\rm stat.}~\\\\pm~0.12_{\\\\rm syst.})$\\\\%. In addition, the hadronic\\nform-factor ratios of $D^{+} \\\\to \\\\bar {K}^{*}(892)^0e^+\\\\nu_e$ at $q^2=0$,\\nassuming a single-pole dominance parameterization, are determined to be\\n$r_V=\\\\frac{V(0)}{A_1(0)}= 1.43~\\\\pm~0.07_{\\\\rm stat.}~\\\\pm~0.03_{\\\\rm syst.}$ and\\n$r_2=\\\\frac{A_2(0)}{A_1(0)}=0.72~\\\\pm~0.06_{\\\\rm stat.}~\\\\pm~0.02_{\\\\rm syst.}$.', 'post': '', 'evaluation': ''}, {'title': 'Evaluating the Impact of Pulse Oximetry Bias in Machine Learning under Counterfactual Thinking', 'summary': 'Algorithmic bias in healthcare mirrors existing data biases. However, the\\nfactors driving unfairness are not always known. Medical devices capture\\nsignificant amounts of data but are prone to errors; for instance, pulse\\noximeters overestimate the arterial oxygen saturation of darker-skinned\\nindividuals, leading to worse outcomes. The impact of this bias in machine\\nlearning (ML) models remains unclear. This study addresses the technical\\nchallenges of quantifying the impact of medical device bias in downstream ML.\\nOur experiments compare a \"perfect world\", without pulse oximetry bias, using\\nSaO2 (blood-gas), to the \"actual world\", with biased measurements, using SpO2\\n(pulse oximetry). Under this counterfactual design, two models are trained with\\nidentical data, features, and settings, except for the method of measuring\\noxygen saturation: models using SaO2 are a \"control\" and models using SpO2 a\\n\"treatment\". The blood-gas oximetry linked dataset was a suitable test-bed,\\ncontaining 163,396 nearly-simultaneous SpO2 - SaO2 paired measurements, aligned\\nwith a wide array of clinical features and outcomes. We studied three\\nclassification tasks: in-hospital mortality, respiratory SOFA score in the next\\n24 hours, and SOFA score increase by two points. Models using SaO2 instead of\\nSpO2 generally showed better performance. Patients with overestimation of O2 by\\npulse oximetry of > 3% had significant decreases in mortality prediction\\nrecall, from 0.63 to 0.59, P < 0.001. This mirrors clinical processes where\\nbiased pulse oximetry readings provide clinicians with false reassurance of\\npatients\\' oxygen levels. A similar degradation happened in ML models, with\\npulse oximetry biases leading to more false negatives in predicting adverse\\noutcomes.', 'post': '', 'evaluation': ''}, {'title': \"Automated Educational Question Generation at Different Bloom's Skill Levels using Large Language Models: Strategies and Evaluation\", 'summary': \"Developing questions that are pedagogically sound, relevant, and promote\\nlearning is a challenging and time-consuming task for educators. Modern-day\\nlarge language models (LLMs) generate high-quality content across multiple\\ndomains, potentially helping educators to develop high-quality questions.\\nAutomated educational question generation (AEQG) is important in scaling online\\neducation catering to a diverse student population. Past attempts at AEQG have\\nshown limited abilities to generate questions at higher cognitive levels. In\\nthis study, we examine the ability of five state-of-the-art LLMs of different\\nsizes to generate diverse and high-quality questions of different cognitive\\nlevels, as defined by Bloom's taxonomy. We use advanced prompting techniques\\nwith varying complexity for AEQG. We conducted expert and LLM-based evaluations\\nto assess the linguistic and pedagogical relevance and quality of the\\nquestions. Our findings suggest that LLms can generate relevant and\\nhigh-quality educational questions of different cognitive levels when prompted\\nwith adequate information, although there is a significant variance in the\\nperformance of the five LLms considered. We also show that automated evaluation\\nis not on par with human evaluation.\", 'post': '', 'evaluation': ''}, {'title': 'Open-domain Implicit Format Control for Large Language Model Generation', 'summary': \"Controlling the format of outputs generated by large language models (LLMs)\\nis a critical functionality in various applications. Current methods typically\\nemploy constrained decoding with rule-based automata or fine-tuning with\\nmanually crafted format instructions, both of which struggle with open-domain\\nformat requirements. To address this limitation, we introduce a novel framework\\nfor controlled generation in LLMs, leveraging user-provided, one-shot QA pairs.\\nThis study investigates LLMs' capabilities to follow open-domain, one-shot\\nconstraints and replicate the format of the example answers. We observe that\\nthis is a non-trivial problem for current LLMs. We also develop a dataset\\ncollection methodology for supervised fine-tuning that enhances the open-domain\\nformat control of LLMs without degrading output quality, as well as a benchmark\\non which we evaluate both the helpfulness and format correctness of LLM\\noutputs. The resulting datasets, named OIFC-SFT, along with the related code,\\nwill be made publicly available at https://github.com/cofe-ai/OIFC.\", 'post': '', 'evaluation': ''}, {'title': 'Twisted q-Yangians and Sklyanin determinants', 'summary': '$q$-Yangians can be viewed as quantum deformations of the upper triangular\\nloop Lie algebras, and also be viewed as deformation of the Yangian algebra. In\\nthis paper, we study the twisted $q$-Yangians as coideal subalgebras of the\\nquantum affine algebra introduced by Molev, Ragoucy and Sorba. We investigate\\nthe invariant theory of the quantum symmetric spaces in affine types $AI, AII$\\nand use the Sklyanin determinants to study the invariant theory and show that\\nthey also obey classical type identities similar to the quantum coordinate\\nalgebras of finite types.', 'post': '', 'evaluation': ''}, {'title': 'KnowPC: Knowledge-Driven Programmatic Reinforcement Learning for Zero-shot Coordination', 'summary': \"Zero-shot coordination (ZSC) remains a major challenge in the cooperative AI\\nfield, which aims to learn an agent to cooperate with an unseen partner in\\ntraining environments or even novel environments. In recent years, a popular\\nZSC solution paradigm has been deep reinforcement learning (DRL) combined with\\nadvanced self-play or population-based methods to enhance the neural policy's\\nability to handle unseen partners. Despite some success, these approaches\\nusually rely on black-box neural networks as the policy function. However,\\nneural networks typically lack interpretability and logic, making the learned\\npolicies difficult for partners (e.g., humans) to understand and limiting their\\ngeneralization ability. These shortcomings hinder the application of\\nreinforcement learning methods in diverse cooperative scenarios.We suggest to\\nrepresent the agent's policy with an interpretable program. Unlike neural\\nnetworks, programs contain stable logic, but they are non-differentiable and\\ndifficult to optimize.To automatically learn such programs, we introduce\\nKnowledge-driven Programmatic reinforcement learning for zero-shot Coordination\\n(KnowPC). We first define a foundational Domain-Specific Language (DSL),\\nincluding program structures, conditional primitives, and action primitives. A\\nsignificant challenge is the vast program search space, making it difficult to\\nfind high-performing programs efficiently. To address this, KnowPC integrates\\nan extractor and an reasoner. The extractor discovers environmental transition\\nknowledge from multi-agent interaction trajectories, while the reasoner deduces\\nthe preconditions of each action primitive based on the transition knowledge.\", 'post': '', 'evaluation': ''}, {'title': 'Enhancing Journalism with AI: A Study of Contextualized Image Captioning for News Articles using LLMs and LMMs', 'summary': 'Large language models (LLMs) and large multimodal models (LMMs) have\\nsignificantly impacted the AI community, industry, and various economic\\nsectors. In journalism, integrating AI poses unique challenges and\\nopportunities, particularly in enhancing the quality and efficiency of news\\nreporting. This study explores how LLMs and LMMs can assist journalistic\\npractice by generating contextualised captions for images accompanying news\\narticles. We conducted experiments using the GoodNews dataset to evaluate the\\nability of LMMs (BLIP-2, GPT-4v, or LLaVA) to incorporate one of two types of\\ncontext: entire news articles, or extracted named entities. In addition, we\\ncompared their performance to a two-stage pipeline composed of a captioning\\nmodel (BLIP-2, OFA, or ViT-GPT2) with post-hoc contextualisation with LLMs\\n(GPT-4 or LLaMA). We assess a diversity of models, and we find that while the\\nchoice of contextualisation model is a significant factor for the two-stage\\npipelines, this is not the case in the LMMs, where smaller, open-source models\\nperform well compared to proprietary, GPT-powered ones. Additionally, we found\\nthat controlling the amount of provided context enhances performance. These\\nresults highlight the limitations of a fully automated approach and underscore\\nthe necessity for an interactive, human-in-the-loop strategy.', 'post': '', 'evaluation': ''}, {'title': 'Project Archetypes: A Blessing and a Curse for AI Development', 'summary': 'Software projects rely on what we call project archetypes, i.e., pre-existing\\nmental images of how projects work. They guide distribution of\\nresponsibilities, planning, or expectations. However, with the technological\\nprogress, project archetypes may become outdated, ineffective, or\\ncounterproductive by impeding more adequate approaches. Understanding\\narchetypes of software development projects is core to leverage their\\npotential. The development of applications using machine learning and\\nartificial intelligence provides a context in which existing archetypes might\\noutdate and need to be questioned, adapted, or replaced. We analyzed 36\\ninterviews from 21 projects between IBM Watson and client companies and\\nidentified four project archetypes members initially used to understand the\\nprojects. We then derive a new project archetype, cognitive computing project,\\nfrom the interviews. It can inform future development projects based on\\nAI-development platforms. Project leaders should proactively manage project\\narchetypes while researchers should investigate what guides initial\\nunderstandings of software projects.', 'post': '', 'evaluation': ''}, {'title': 'Making sense of AI systems development', 'summary': \"We identify and describe episodes of sensemaking around challenges in modern\\nAI-based systems development that emerged in projects carried out by IBM and\\nclient companies. All projects used IBM Watson as the development platform for\\nbuilding tailored AI-based solutions to support workers or customers of the\\nclient companies. Yet, many of the projects turned out to be significantly more\\nchallenging than IBM and its clients had expected. The analysis reveals that\\nproject members struggled to establish reliable meanings about the technology,\\nthe project, context, and data to act upon. The project members report multiple\\naspects of the projects that they were not expecting to need to make sense of\\nyet were problematic. Many issues bear upon the current-generation AI's\\ninherent characteristics, such as dependency on large data sets and continuous\\nimprovement as more data becomes available. Those characteristics increase the\\ncomplexity of the projects and call for balanced mindfulness to avoid\\nunexpected problems.\", 'post': '', 'evaluation': ''}, {'title': 'Partial Experts Checkpoint: Efficient Fault Tolerance for Sparse Mixture-of-Experts Model Training', 'summary': 'As large language models continue to scale up, the imperative for fault\\ntolerance in distributed deep learning systems intensifies, becoming a focal\\narea of AI infrastructure research. Checkpoint has emerged as the predominant\\nfault tolerance strategy, with extensive studies dedicated to optimizing its\\nefficiency. However, the advent of the sparse Mixture-of-Experts (MoE) model\\npresents new challenges for traditional checkpoint techniques due to the\\nsubstantial increase in model size, despite comparable computational demands to\\ndense models. Breaking new ground in the realm of efficient fault tolerance for\\nMoE model training, we introduce a novel Partial Experts Checkpoint (PEC)\\nmechanism alongside a corresponding PEC fault-tolerant system. Our approach\\nstrategically checkpoints a selected subset of experts, thereby significantly\\nreducing the checkpoint size for MoE models to a level comparable with that of\\ndense models. The empirical analysis on our 8-expert GPT-MoE model demonstrates\\nthat the proposed PEC approach facilitates a substantial 54.2% decrease in the\\nsize of non-redundant checkpoint (no data-parallel duplication), without\\ncompromising the final model quality. Moreover, our PEC fault-tolerant system\\nachieves a 76.9% reduction in checkpoint workload per data-parallel distributed\\nrank, thereby correspondingly diminishing the checkpointing time and\\nfacilitating complete overlap with the training process.', 'post': '', 'evaluation': ''}, {'title': 'AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent', 'summary': \"In today's contemporary digital landscape, chatbots have become indispensable\\ntools across various sectors, streamlining customer service, providing personal\\nassistance, automating routine tasks, and offering health advice. However,\\ntheir potential remains underexplored in the realm of network security,\\nparticularly for intrusion detection. To bridge this gap, we propose an\\narchitecture chatbot specifically designed to enhance security within edge\\nnetworks specifically for intrusion detection. Leveraging advanced machine\\nlearning algorithms, this chatbot will monitor network traffic to identify and\\nmitigate potential intrusions. By securing the network environment using an\\nedge network managed by a Raspberry Pi module and ensuring ethical user consent\\npromoting transparency and trust, this innovative solution aims to safeguard\\nsensitive data and maintain a secure workplace, thereby addressing the growing\\nneed for robust network security measures in the digital age.\", 'post': '', 'evaluation': ''}, {'title': 'Addressing Model and Data Heterogeneity in Multimodal Large Language Model Training', 'summary': 'Multimodal large language models (LLMs) have demonstrated significant\\npotential in a wide range of AI applications. Yet, training multimodal LLMs\\nsuffers from low efficiency and scalability, due to the inherent model\\nheterogeneity and data heterogeneity across different modalities.\\n  We present MMScale, an efficient and adaptive framework to reform the\\ntraining of multimodal large language models on large-scale clusters. MMScale\\nexploits the system characteristics of multimodal LLM training to achieve high\\nefficiency and scalability. The core of MMScale is the adaptive resource\\nallocation and data-aware reordering techniques to eliminate the model and data\\nheterogeneity respectively. We also tailor system optimizations for multimodal\\nLLM training to offload certain operations from the GPU training. We evaluate\\nMMScale across different sizes of multimodal LLMs on a large-scale production\\ncluster with thousands of GPUs. The experimental results show that MMScale\\nachieves 54.7% Model FLOPs Utilization (MFU) when training a 72B multimodal LLM\\non 1172 GPUs and outperforms Megatron-LM by up to 2.2$\\\\times$ on throughput.\\nThe ablation study shows the main techniques of MMScale are both effective and\\nlightweight.', 'post': '', 'evaluation': ''}, {'title': 'Generating Fine-Grained Causality in Climate Time Series Data for Forecasting and Anomaly Detection', 'summary': 'Understanding the causal interaction of time series variables can contribute\\nto time series data analysis for many real-world applications, such as climate\\nforecasting and extreme weather alerts. However, causal relationships are\\ndifficult to be fully observed in real-world complex settings, such as\\nspatial-temporal data from deployed sensor networks. Therefore, to capture\\nfine-grained causal relations among spatial-temporal variables for further a\\nmore accurate and reliable time series analysis, we first design a conceptual\\nfine-grained causal model named TBN Granger Causality, which adds\\ntime-respecting Bayesian Networks to the previous time-lagged Neural Granger\\nCausality to offset the instantaneous effects. Second, we propose an end-to-end\\ndeep generative model called TacSas, which discovers TBN Granger Causality in a\\ngenerative manner to help forecast time series data and detect possible\\nanomalies during the forecast. For evaluations, besides the causality discovery\\nbenchmark Lorenz-96, we also test TacSas on climate benchmark ERA5 for climate\\nforecasting and the extreme weather benchmark of NOAA for extreme weather\\nalerts.', 'post': '', 'evaluation': ''}, {'title': 'Adapting to Reality: Over-the-Air Validation of AI-Based Receivers Trained with Simulated Channels', 'summary': \"Recent research has shown that integrating artificial intelligence (AI) into\\nwireless communication systems can significantly improve spectral efficiency.\\nHowever, the prevalent use of simulated radio channel data for training and\\nvalidating neural network-based radios raises concerns about their\\ngeneralization capability to diverse real-world environments. To address this,\\nwe conducted empirical over-the-air (OTA) experiments using software-defined\\nradio (SDR) technology to test the performance of an NN-based orthogonal\\nfrequency division multiplexing (OFDM) receiver in a real-world small cell\\nscenario. Our assessment reveals that the performance of receivers trained on\\ndiverse 3GPP TS38.901 channel models and broad parameter ranges significantly\\nsurpasses conventional receivers in our testing environment, demonstrating\\nstrong generalization to a new environment. Conversely, setting simulation\\nparameters to narrowly reflect the actual measurement environment led to\\nsuboptimal OTA performance, highlighting the crucial role of rich and\\nrandomized training data in improving the NN-based receiver's performance.\\nWhile our empirical test results are promising, they also suggest that\\ndeveloping new channel models tailored for training these learned receivers\\nwould enhance their generalization capability and reduce training time. Our\\ntesting was limited to a relatively narrow environment, and we encourage\\nfurther testing in more complex environments.\", 'post': '', 'evaluation': ''}, {'title': 'EdgeShield: A Universal and Efficient Edge Computing Framework for Robust AI', 'summary': \"The increasing prevalence of adversarial attacks on Artificial Intelligence\\n(AI) systems has created a need for innovative security measures. However, the\\ncurrent methods of defending against these attacks often come with a high\\ncomputing cost and require back-end processing, making real-time defense\\nchallenging. Fortunately, there have been remarkable advancements in\\nedge-computing, which make it easier to deploy neural networks on edge devices.\\nBuilding upon these advancements, we propose an edge framework design to enable\\nuniversal and efficient detection of adversarial attacks. This framework\\nincorporates an attention-based adversarial detection methodology and a\\nlightweight detection network formation, making it suitable for a wide range of\\nneural networks and can be deployed on edge devices. To assess the\\neffectiveness of our proposed framework, we conducted evaluations on five\\nneural networks. The results indicate an impressive 97.43% F-score can be\\nachieved, demonstrating the framework's proficiency in detecting adversarial\\nattacks. Moreover, our proposed framework also exhibits significantly reduced\\ncomputing complexity and cost in comparison to previous detection methods. This\\naspect is particularly beneficial as it ensures that the defense mechanism can\\nbe efficiently implemented in real-time on-edge devices.\", 'post': '', 'evaluation': ''}, {'title': 'Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions', 'summary': 'This paper considers a scenario in city navigation: an AI agent is provided\\nwith language descriptions of the goal location with respect to some well-known\\nlandmarks; By only observing the scene around, including recognizing landmarks\\nand road network connections, the agent has to make decisions to navigate to\\nthe goal location without instructions. This problem is very challenging,\\nbecause it requires agent to establish self-position and acquire spatial\\nrepresentation of complex urban environment, where landmarks are often\\ninvisible. In the absence of navigation instructions, such abilities are vital\\nfor the agent to make high-quality decisions in long-range city navigation.\\nWith the emergent reasoning ability of large language models (LLMs), a tempting\\nbaseline is to prompt LLMs to \"react\" on each observation and make decisions\\naccordingly. However, this baseline has very poor performance that the agent\\noften repeatedly visits same locations and make short-sighted, inconsistent\\ndecisions. To address these issues, this paper introduces a novel agentic\\nworkflow featured by its abilities to perceive, reflect and plan. Specifically,\\nwe find LLaVA-7B can be fine-tuned to perceive the direction and distance of\\nlandmarks with sufficient accuracy for city navigation. Moreover, reflection is\\nachieved through a memory mechanism, where past experiences are stored and can\\nbe retrieved with current perception for effective decision argumentation.\\nPlanning uses reflection results to produce long-term plans, which can avoid\\nshort-sighted decisions in long-range navigation. We show the designed workflow\\nsignificantly improves navigation ability of the LLM agent compared with the\\nstate-of-the-art baselines.', 'post': '', 'evaluation': ''}, {'title': 'Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization', 'summary': \"Large language models (LLMs) can help writers build story worlds by\\ngenerating world elements, such as factions, characters, and locations.\\nHowever, making sense of many generated elements can be overwhelming. Moreover,\\nif the user wants to precisely control aspects of generated elements that are\\ndifficult to specify verbally, prompting alone may be insufficient. We\\nintroduce Patchview, a customizable LLM-powered system that visually aids\\nworldbuilding by allowing users to interact with story concepts and elements\\nthrough the physical metaphor of magnets and dust. Elements in Patchview are\\nvisually dragged closer to concepts with high relevance, facilitating\\nsensemaking. The user can also steer the generation with verbally elusive\\nconcepts by indicating the desired position of the element between concepts.\\nWhen the user disagrees with the LLM's visualization and generation, they can\\ncorrect those by repositioning the element. These corrections can be used to\\nalign the LLM's future behaviors to the user's perception. With a user study,\\nwe show that Patchview supports the sensemaking of world elements and steering\\nof element generation, facilitating exploration during the worldbuilding\\nprocess. Patchview provides insights on how customizable visual representation\\ncan help sensemake, steer, and align generative AI model behaviors with the\\nuser's intentions.\", 'post': '', 'evaluation': ''}, {'title': 'Digital Avatars: Framework Development and Their Evaluation', 'summary': \"We present a novel prompting strategy for artificial intelligence driven\\ndigital avatars. To better quantify how our prompting strategy affects\\nanthropomorphic features like humor, authenticity, and favorability we present\\nCrowd Vote - an adaptation of Crowd Score that allows for judges to elect a\\nlarge language model (LLM) candidate over competitors answering the same or\\nsimilar prompts. To visualize the responses of our LLM, and the effectiveness\\nof our prompting strategy we propose an end-to-end framework for creating\\nhigh-fidelity artificial intelligence (AI) driven digital avatars. This\\npipeline effectively captures an individual's essence for interaction and our\\nstreaming algorithm delivers a high-quality digital avatar with real-time\\naudio-video streaming from server to mobile device. Both our visualization\\ntool, and our Crowd Vote metrics demonstrate our AI driven digital avatars have\\nstate-of-the-art humor, authenticity, and favorability outperforming all\\ncompetitors and baselines. In the case of our Donald Trump and Joe Biden\\navatars, their authenticity and favorability are rated higher than even their\\nreal-world equivalents.\", 'post': '', 'evaluation': ''}, {'title': 'From Black Box to Clarity: AI-Powered Smart Grid Optimization with Kolmogorov-Arnold Networks', 'summary': \"This work is the first to adopt Kolmogorov-Arnold Networks (KAN), a recent\\nbreakthrough in artificial intelligence, for smart grid optimizations. To fully\\nleverage KAN's interpretability, a general framework is proposed considering\\ncomplex uncertainties. The stochastic optimal power flow problem in hybrid\\nAC/DC systems is chosen as a particularly tough case study for demonstrating\\nthe effectiveness of this framework.\", 'post': '', 'evaluation': ''}, {'title': 'Information Seeking Using AI Assistants', 'summary': \"A good portion of a software practitioners' day involves seeking and using\\ninformation to support task completion. Although the information needs of\\nsoftware practitioners have been studied extensively, the impact of AI-assisted\\ntools on their needs and information-seeking behaviors remains largely\\nunexplored. To addresses this gap, we conducted a mixed-method study to\\nunderstand AI-assisted information seeking behavior of practitioners and its\\nimpact on their perceived productivity and skill development. We found that\\ndevelopers are increasingly using AI tools to support their information\\nseeking, citing increased efficiency as a key benefit. Our findings also\\namplify caveats that come with effectively using AI tools for information\\nseeking, especially for learning and skill development, such as the importance\\nof foundational developer knowledge that can guide and inform the information\\nprovided by AI tools. Our efforts have implications for the effective\\nintegration of AI tools into developer workflows as information retrieval and\\nlearning aids.\", 'post': '', 'evaluation': ''}, {'title': 'Improving Large Language Model (LLM) fidelity through context-aware grounding: A systematic approach to reliability and veracity', 'summary': \"As Large Language Models (LLMs) become increasingly sophisticated and\\nubiquitous in natural language processing (NLP) applications, ensuring their\\nrobustness, trustworthiness, and alignment with human values has become a\\ncritical challenge. This paper presents a novel framework for contextual\\ngrounding in textual models, with a particular emphasis on the Context\\nRepresentation stage. Our approach aims to enhance the reliability and ethical\\nalignment of these models through a comprehensive, context-aware methodology.\\nBy explicitly capturing and representing relevant situational, cultural, and\\nethical contexts in a machine-readable format, we lay the foundation for\\nanchoring a model's behavior within these contexts. Our approach leverages\\ntechniques from knowledge representation and reasoning, such as ontologies,\\nsemantic web technologies, and logic-based formalisms. We evaluate our\\nframework on real-world textual datasets, demonstrating its effectiveness in\\nimproving model performance, fairness, and alignment with human expectations,\\nwhile maintaining high accuracy. Furthermore, we discuss the other key\\ncomponents of the framework, including context-aware encoding, context-aware\\nlearning, interpretability and explainability, and continuous monitoring and\\nadaptation. This research contributes to the growing body of work on\\nresponsible AI, offering a practical approach to developing more reliable,\\ntrustworthy, and ethically-aligned language models. Our findings have\\nsignificant implications for the deployment of LLMs in sensitive domains such\\nas healthcare, legal systems, and social services, where contextual\\nunderstanding is paramount.\", 'post': '', 'evaluation': ''}, {'title': 'Cold fronts in galaxy clusters I: A case for the large-scale global eigen modes in unmagnetized and weakly magnetized cluster core', 'summary': 'Galaxy clusters show large-scale azimuthal X-ray surface brightness\\nfluctuations known as cold fronts. These are overdense (average density jumps\\n$\\\\sim 30\\\\%$ or post-jump density $\\\\sim 130\\\\%$) and have milder discontinuity in\\npressure. Cold fronts are argued to originate due to sloshing driven by\\nsub-halo passage at close proximity to the cluster center. While this is a\\nviable source of large-scale perturbations, the physical mechanisms that can\\nsustain such density structures (of specific geometry) are not clear. In this\\nwork, we explore whether long wavelength thermal instability is an explanation\\nfor cold front formation in a cluster core which is perturbed by sub-halos or\\nAGN activity. Using global linear perturbation analysis, we show that internal\\ngravity waves (thermally unstable) can form large-scale three-dimensional\\nspiral structures, akin to observed cold fronts. We explore if the presence of\\nmagnetic field (along spherical $\\\\hat{\\\\phi}$) may support such structures (by\\nsuppressing small scale Kelvin-Helmholtz modes) or disrupt them (by promoting\\nadditional thermal instability). We find that latter happens at shorter\\nwavelengths and only at frequencies above the characteristic buoyancy or Brunt\\nV\\\\\"ais\\\\\"al\\\\\"a frequency ($>N_{\\\\rm BV}$). Our work implies, firstly, that\\nlarge-scale spirals may be formed and sustained over a long timescale\\n($>N^{-1}_{\\\\rm BV}$) even in presence of aligned magnetic fields that is\\notherwise supportive against mixing at the interface. Secondly,\\nshort-wavelength (but relatively longer along the field) unstable compressive\\nmodes may form within or in the vicinity of such spirals. The instability is an\\noverstable slow wave, and grows in 2D at timescales $\\\\gtrsim 2-3$ times longer\\nthan the spiral growth timescale (via thermal instability). Thus we claim that\\nthis instability cannot destroy the large scale coherence.', 'post': '', 'evaluation': ''}, {'title': 'MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems', 'summary': 'Cyber-Physical Systems (CPSs) are increasingly prevalent across various\\nindustrial and daily-life domains, with applications ranging from robotic\\noperations to autonomous driving. With recent advancements in artificial\\nintelligence (AI), learning-based components, especially AI controllers, have\\nbecome essential in enhancing the functionality and efficiency of CPSs.\\nHowever, the lack of interpretability in these AI controllers presents\\nchallenges to the safety and quality assurance of AI-enabled CPSs (AI-CPSs).\\nExisting methods for improving the safety of AI controllers often involve\\nneural network repair, which requires retraining with additional adversarial\\nexamples or access to detailed internal information of the neural network.\\nHence, these approaches have limited applicability for black-box policies,\\nwhere only the inputs and outputs are accessible during operation. To overcome\\nthis, we propose MORTAR, a runtime action repair framework designed for AI-CPSs\\nin this work. MORTAR begins by constructing a prediction model that forecasts\\nthe quality of actions proposed by the AI controller. If an unsafe action is\\ndetected, MORTAR then initiates a repair process to correct it. The generation\\nof repaired actions is achieved through an optimization process guided by the\\nsafety estimates from the prediction model. We evaluate the effectiveness of\\nMORTAR across various CPS tasks and AI controllers. The results demonstrate\\nthat MORTAR can efficiently improve task completion rates of AI controllers\\nunder specified safety specifications. Meanwhile, it also maintains minimal\\ncomputational overhead, ensuring real-time operation of the AI-CPSs.', 'post': '', 'evaluation': ''}, {'title': 'PackMamba: Efficient Processing of Variable-Length Sequences in Mamba training', 'summary': 'With the evolution of large language models, traditional Transformer models\\nbecome computationally demanding for lengthy sequences due to the quadratic\\ngrowth in computation with respect to the sequence length. Mamba, emerging as a\\ngroundbreaking architecture in the field of generative AI, demonstrates\\nremarkable proficiency in handling elongated sequences with reduced\\ncomputational and memory complexity. Nevertheless, the existing training\\nframework of Mamba presents inefficiency with variable-length sequence inputs.\\nEither single-sequence training results in low GPU utilization, or batched\\nprocessing of variable-length sequences to a maximum length incurs considerable\\nmemory and computational overhead. To address this problem, we analyze the\\nperformance of bottleneck operators in Mamba under diverse tensor shapes and\\nproposed PackMamba, a high-throughput Mamba that efficiently handles\\nvariable-length sequences. Diving deep into state-space models (SSMs), we\\nmodify the parallel operators to avoid passing information between individual\\nsequences while maintaining high performance. Experimental results on an NVIDIA\\nA100 GPU demonstrate throughput exceeding the baseline single-sequence\\nprocessing scheme: 3.06x speedup on the 1.4B model and 2.62x on the 2.8B model.', 'post': '', 'evaluation': ''}, {'title': 'MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models', 'summary': \"The application of large language models to facilitate automated software\\noperations and tool generation (SOTG), thus augmenting software productivity,\\nmirrors the early stages of human evolution when the ability to create and use\\ntools accelerated the progress of civilization. These complex tasks require AI\\nto continuously summarize and improve. Current research often overlooks the\\nimportance of converting real-time task experiences into system memory and\\ndifferentiating the value of existing knowledge for future reference. This\\npaper addresses these issues by evolving external memory models into\\nMemory-Loop Networks for timely memorization and experience referencing. We\\nalso enhance a RAG mechanism with knowledge precision segmentation to utilize\\nmemory based on value differentiation, and design the MaxMind model for SOTG\\naccordingly.To demonstrate our approach, we developed MaxMind4Sheet, an\\nelectronic spreadsheet processing system aligned with the MaxMind philosophy.\\nComparative experiments with SheetCopilot have demonstrated that the\\naccumulation and recycling of task memories lead to a steady enhancement in\\ntask success rate, with an improvement rate of approximately 3%-6% per round in\\nthis implementation example. Note that as the memories continue to grow, this\\ncumulative improvement may be substantial. The inclusion of memory recycling\\ncan also boost the system's task execution efficiency by up to 25%, and it can\\naddress the retraining issue faced by LLMs when handling specialized tasks\\nthrough memories transfer.These suggest that MaxMind has significant potential\\nto enhance the capabilities and productivity of LLM systems in SOTG.\", 'post': '', 'evaluation': ''}, {'title': 'WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models', 'summary': 'WalledEval is a comprehensive AI safety testing toolkit designed to evaluate\\nlarge language models (LLMs). It accommodates a diverse range of models,\\nincluding both open-weight and API-based ones, and features over 35 safety\\nbenchmarks covering areas such as multilingual safety, exaggerated safety, and\\nprompt injections. The framework supports both LLM and judge benchmarking, and\\nincorporates custom mutators to test safety against various text-style\\nmutations such as future tense and paraphrasing. Additionally, WalledEval\\nintroduces WalledGuard, a new, small and performant content moderation tool,\\nand SGXSTest, a benchmark for assessing exaggerated safety in cultural\\ncontexts. We make WalledEval publicly available at\\nhttps://github.com/walledai/walledevalA.', 'post': '', 'evaluation': ''}, {'title': 'Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning', 'summary': 'Active Learning (AL) allows models to learn interactively from user feedback.\\nThis paper introduces a counterfactual data augmentation approach to AL,\\nparticularly addressing the selection of datapoints for user querying, a\\npivotal concern in enhancing data efficiency. Our approach is inspired by\\nVariation Theory, a theory of human concept learning that emphasizes the\\nessential features of a concept by focusing on what stays the same and what\\nchanges. Instead of just querying with existing datapoints, our approach\\nsynthesizes artificial datapoints that highlight potential key similarities and\\ndifferences among labels using a neuro-symbolic pipeline combining large\\nlanguage models (LLMs) and rule-based models. Through an experiment in the\\nexample domain of text classification, we show that our approach achieves\\nsignificantly higher performance when there are fewer annotated data. As the\\nannotated training data gets larger the impact of the generated data starts to\\ndiminish showing its capability to address the cold start problem in AL. This\\nresearch sheds light on integrating theories of human learning into the\\noptimization of AL.', 'post': '', 'evaluation': ''}, {'title': 'An AI-aided algorithm for multivariate polynomial reconstruction on Cartesian grids and the PLG finite difference method', 'summary': 'Polynomial reconstruction on Cartesian grids is a key problem in developing\\nfinite difference methods as well as in many other engineering applications,\\nyet it is still an open problem how to construct for a finite subset $K$ of\\n$\\\\mathbb{Z}^{\\\\textsf{D}}$ a lattice $\\\\mathcal{T}\\\\subset K$ so that multivariate\\npolynomial interpolation on this lattice is unisolvent. In this work, we solve\\nthis open problem of poised lattice generation (PLG) via an interdisciplinary\\nresearch of approximation theory, abstract algebra, and artificial intelligence\\n(AI). Specifically, we focus on the triangular lattices in approximation\\ntheory, study group actions of permutations upon triangular lattices, prove an\\nisomorphism between the group of permutations and that of triangular lattices,\\nand dynamically organize the AI state space of permutations so that a\\ndepth-first search of poised lattices has optimal efficiency. Based on this\\nalgorithm, we further develop the PLG finite difference method that retains the\\nsimplicity of Cartesian grids yet overcomes the disadvantage of legacy finite\\ndifference methods in handling irregular geometries. Results of various\\nnumerical tests demonstrate the effectiveness of our algorithm and the\\nsimplicity, efficiency, and fourth-order accuracy of the PLG finite difference\\nmethod.', 'post': '', 'evaluation': ''}, {'title': 'Methodological Explainability Evaluation of an Interpretable Deep Learning Model for Post-Hepatectomy Liver Failure Prediction Incorporating Counterfactual Explanations and Layerwise Relevance Propagation: A Prospective In Silico Trial', 'summary': \"Artificial intelligence (AI)-based decision support systems have demonstrated\\nvalue in predicting post-hepatectomy liver failure (PHLF) in hepatocellular\\ncarcinoma (HCC). However, they often lack transparency, and the impact of model\\nexplanations on clinicians' decisions has not been thoroughly evaluated.\\nBuilding on prior research, we developed a variational autoencoder-multilayer\\nperceptron (VAE-MLP) model for preoperative PHLF prediction. This model\\nintegrated counterfactuals and layerwise relevance propagation (LRP) to provide\\ninsights into its decision-making mechanism. Additionally, we proposed a\\nmethodological framework for evaluating the explainability of AI systems. This\\nframework includes qualitative and quantitative assessments of explanations\\nagainst recognized biomarkers, usability evaluations, and an in silico clinical\\ntrial. Our evaluations demonstrated that the model's explanation correlated\\nwith established biomarkers and exhibited high usability at both the case and\\nsystem levels. Furthermore, results from the three-track in silico clinical\\ntrial showed that clinicians' prediction accuracy and confidence increased when\\nAI explanations were provided.\", 'post': '', 'evaluation': ''}, {'title': 'MTDSense: AI-Based Fingerprinting of Moving Target Defense Techniques in Software-Defined Networking', 'summary': \"Moving target defenses (MTD) are proactive security techniques that enhance\\nnetwork security by confusing the attacker and limiting their attack window.\\nMTDs have been shown to have significant benefits when evaluated against\\ntraditional network attacks, most of which are automated and untargeted.\\nHowever, little has been done to address an attacker who is aware the network\\nuses an MTD. In this work, we propose a novel approach named MTDSense, which\\ncan determine when the MTD has been triggered using the footprints the MTD\\noperation leaves in the network traffic. MTDSense uses unsupervised clustering\\nto identify traffic following an MTD trigger and extract the MTD interval. An\\nattacker can use this information to maximize their attack window and tailor\\ntheir attacks, which has been shown to significantly reduce the effectiveness\\nof MTD. Through analyzing the attacker's approach, we propose and evaluate two\\nnew MTD update algorithms that aim to reduce the information leaked into the\\nnetwork by the MTD. We present an extensive experimental evaluation by\\ncreating, to our knowledge, the first dataset of the operation of an\\nIP-shuffling MTD in a software-defined network. Our work reveals that despite\\nprevious results showing the effectiveness of MTD as a defense, traditional\\nimplementations of MTD are highly susceptible to a targeted attacker.\", 'post': '', 'evaluation': ''}, {'title': 'Impact Analysis of Data Drift Towards The Development of Safety-Critical Automotive System', 'summary': 'A significant part of contemporary research in autonomous vehicles is\\ndedicated to the development of safety critical systems where state-of-the-art\\nartificial intelligence (AI) algorithms, like computer vision (CV), can play a\\nmajor role. Vision models have great potential for the real-time detection of\\nnumerous traffic signs and obstacles, which is essential to avoid accidents and\\nprotect human lives. Despite vast potential, computer vision-based systems have\\ncritical safety concerns too if the traffic condition drifts over time. This\\npaper represents an analysis of how data drift can affect the performance of\\nvision models in terms of traffic sign detection. The novelty in this research\\nis provided through a YOLO-based fusion model that is trained with drifted data\\nfrom the CARLA simulator and delivers a robust and enhanced performance in\\nobject detection. The enhanced model showed an average precision of 97.5\\\\%\\ncompared to the 58.27\\\\% precision of the original model. A detailed performance\\nreview of the original and fusion models is depicted in the paper, which\\npromises to have a significant impact on safety-critical automotive systems.', 'post': '', 'evaluation': ''}, {'title': 'Smart Health Software to Support Rescue Personnel in Emergency Situations', 'summary': \"Rescue stations around the world receive millions of emergency rescue calls\\neach year, most of which are due to health complications. Due to the high\\nfrequency and necessity of rescue services, there is always an increasing\\ndemand for quick, accurate, and coordinated responses from rescue personnel to\\nsave lives and mitigate damage. This paper introduces a rescue health\\nmanagement software solution designed to improve the efficiency and\\neffectiveness of rescue situational awareness by rapidly assessing the health\\nstatus of emergency patients using AI-driven decision support systems. The\\nnovelty in this software approach is it's user-centered design principles to\\nensure that its solutions are specifically tailored to meet the unique\\nrequirements of emergency responders. It used pre-trained machine learning\\nmodels with rescue data and accepted new patient's input data to provide a\\nprobability of the major health complications so that rescue personnel can\\nexpedite treatment plan following the outcome. The paper focuses primarily on\\nthe software development and implementation steps with three use cases, while\\nalso providing a short overview of the previous machine learning-based\\ndevelopment phases.\", 'post': '', 'evaluation': ''}, {'title': 'Generative Design of Periodic Orbits in the Restricted Three-Body Problem', 'summary': 'The Three-Body Problem has fascinated scientists for centuries and it has\\nbeen crucial in the design of modern space missions. Recent developments in\\nGenerative Artificial Intelligence hold transformative promise for addressing\\nthis longstanding problem. This work investigates the use of Variational\\nAutoencoder (VAE) and its internal representation to generate periodic orbits.\\nWe utilize a comprehensive dataset of periodic orbits in the Circular\\nRestricted Three-Body Problem (CR3BP) to train deep-learning architectures that\\ncapture key orbital characteristics, and we set up physical evaluation metrics\\nfor the generated trajectories. Through this investigation, we seek to enhance\\nthe understanding of how Generative AI can improve space mission planning and\\nastrodynamics research, leading to novel, data-driven approaches in the field.', 'post': '', 'evaluation': ''}, {'title': 'NACL: A General and Effective KV Cache Eviction Framework for LLMs at Inference Time', 'summary': \"Large Language Models (LLMs) have ignited an innovative surge of AI\\napplications, marking a new era of exciting possibilities equipped with\\nextended context windows. However, hosting these models is cost-prohibitive\\nmainly due to the extensive memory consumption of KV Cache involving\\nlong-context modeling. Despite several works proposing to evict unnecessary\\ntokens from the KV Cache, most of them rely on the biased local statistics of\\naccumulated attention scores and report performance using unconvincing metric\\nlike perplexity on inadequate short-text evaluation. In this paper, we propose\\nNACL, a general framework for long-context KV cache eviction that achieves more\\noptimal and efficient eviction in a single operation during the encoding phase.\\nDue to NACL's efficiency, we combine more accurate attention score statistics\\nin PROXY TOKENS EVICTION with the diversified random eviction strategy of\\nRANDOM EVICTION, aiming to alleviate the issue of attention bias and enhance\\nthe robustness in maintaining pivotal tokens for long-context modeling tasks.\\nNotably, our method significantly improves the performance on short- and\\nlong-text tasks by 80% and 76% respectively, reducing KV Cache by up to 50%\\nwith over 95% performance maintenance. The code is available at\\nhttps://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2024-NACL.\", 'post': '', 'evaluation': ''}, {'title': \"AI-Driven approach for sustainable extraction of earth's subsurface renewable energy while minimizing seismic activity\", 'summary': \"Deep Geothermal Energy, Carbon Capture and Storage, and Hydrogen Storage hold\\nconsiderable promise for meeting the energy sector's large-scale requirements\\nand reducing CO$_2$ emissions. However, the injection of fluids into the\\nEarth's crust, essential for these activities, can induce or trigger\\nearthquakes. In this paper, we highlight a new approach based on Reinforcement\\nLearning for the control of human-induced seismicity in the highly complex\\nenvironment of an underground reservoir. This complex system poses significant\\nchallenges in the control design due to parameter uncertainties and unmodeled\\ndynamics. We show that the reinforcement learning algorithm can interact\\nefficiently with a robust controller, by choosing the controller parameters in\\nreal-time, reducing human-induced seismicity and allowing the consideration of\\nfurther production objectives, \\\\textit{e.g.}, minimal control power.\\nSimulations are presented for a simplified underground reservoir under various\\nenergy demand scenarios, demonstrating the reliability and effectiveness of the\\nproposed control-reinforcement learning approach.\", 'post': '', 'evaluation': ''}, {'title': 'Towards Multimodal Emotional Support Conversation Systems', 'summary': \"The integration of conversational artificial intelligence (AI) into mental\\nhealth care promises a new horizon for therapist-client interactions, aiming to\\nclosely emulate the depth and nuance of human conversations. Despite the\\npotential, the current landscape of conversational AI is markedly limited by\\nits reliance on single-modal data, constraining the systems' ability to\\nempathize and provide effective emotional support. This limitation stems from a\\npaucity of resources that encapsulate the multimodal nature of human\\ncommunication essential for therapeutic counseling. To address this gap, we\\nintroduce the Multimodal Emotional Support Conversation (MESC) dataset, a\\nfirst-of-its-kind resource enriched with comprehensive annotations across text,\\naudio, and video modalities. This dataset captures the intricate interplay of\\nuser emotions, system strategies, system emotion, and system responses, setting\\na new precedent in the field. Leveraging the MESC dataset, we propose a general\\nSequential Multimodal Emotional Support framework (SMES) grounded in\\nTherapeutic Skills Theory. Tailored for multimodal dialogue systems, the SMES\\nframework incorporates an LLM-based reasoning model that sequentially generates\\nuser emotion recognition, system strategy prediction, system emotion\\nprediction, and response generation. Our rigorous evaluations demonstrate that\\nthis framework significantly enhances the capability of AI systems to mimic\\ntherapist behaviors with heightened empathy and strategic responsiveness. By\\nintegrating multimodal data in this innovative manner, we bridge the critical\\ngap between emotion recognition and emotional support, marking a significant\\nadvancement in conversational AI for mental health support.\", 'post': '', 'evaluation': ''}, {'title': 'Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent', 'summary': 'Traditional base station siting (BSS) methods rely heavily on drive testing\\nand user feedback, which are laborious and require extensive expertise in\\ncommunication, networking, and optimization. As large language models (LLMs)\\nand their associated technologies advance, particularly in the realms of prompt\\nengineering and agent engineering, network optimization will witness a\\nrevolutionary approach. This approach entails the strategic use of well-crafted\\nprompts to infuse human experience and knowledge into these sophisticated LLMs,\\nand the deployment of autonomous agents as a communication bridge to seamlessly\\nconnect the machine language based LLMs with human users using natural\\nlanguage. This integration represents the future paradigm of artificial\\nintelligence (AI) as a service and AI for more ease. As a preliminary\\nexploration, this research first develops a novel LLM-empowered BSS\\noptimization framework, and heuristically proposes four different potential\\nimplementations: the strategies based on Prompt-optimized LLM (PoL),\\nhuman-in-the-Loop LLM (HiLL), LLM-empowered autonomous BSS agent (LaBa), and\\nCooperative multiple LLM-based autonomous BSS agents (CLaBa). Through\\nevaluation on real-world data, the experiments demonstrate that prompt-assisted\\nLLMs and LLM-based agents can generate more efficient, cost-effective, and\\nreliable network deployments, noticeably enhancing the efficiency of BSS\\noptimization and reducing trivial manual participation.', 'post': '', 'evaluation': ''}, {'title': 'PRISM: PRogressive dependency maxImization for Scale-invariant image Matching', 'summary': \"Image matching aims at identifying corresponding points between a pair of\\nimages. Currently, detector-free methods have shown impressive performance in\\nchallenging scenarios, thanks to their capability of generating dense matches\\nand global receptive field. However, performing feature interaction and\\nproposing matches across the entire image is unnecessary, because not all image\\nregions contribute to the matching process. Interacting and matching in\\nunmatchable areas can introduce errors, reducing matching accuracy and\\nefficiency. Meanwhile, the scale discrepancy issue still troubles existing\\nmethods. To address above issues, we propose PRogressive dependency\\nmaxImization for Scale-invariant image Matching (PRISM), which jointly prunes\\nirrelevant patch features and tackles the scale discrepancy. To do this, we\\nfirstly present a Multi-scale Pruning Module (MPM) to adaptively prune\\nirrelevant features by maximizing the dependency between the two feature sets.\\nMoreover, we design the Scale-Aware Dynamic Pruning Attention (SADPA) to\\naggregate information from different scales via a hierarchical design. Our\\nmethod's superior matching performance and generalization capability are\\nconfirmed by leading accuracy across various evaluation benchmarks and\\ndownstream tasks. The code is publicly available at\\nhttps://github.com/Master-cai/PRISM.\", 'post': '', 'evaluation': ''}, {'title': 'HistoSPACE: Histology-Inspired Spatial Transcriptome Prediction And Characterization Engine', 'summary': 'Spatial transcriptomics (ST) enables the visualization of gene expression\\nwithin the context of tissue morphology. This emerging discipline has the\\npotential to serve as a foundation for developing tools to design precision\\nmedicines. However, due to the higher costs and expertise required for such\\nexperiments, its translation into a regular clinical practice might be\\nchallenging. Despite the implementation of modern deep learning to enhance\\ninformation obtained from histological images using AI, efforts have been\\nconstrained by limitations in the diversity of information. In this paper, we\\ndeveloped a model, HistoSPACE that explore the diversity of histological images\\navailable with ST data to extract molecular insights from tissue image. Our\\nproposed study built an image encoder derived from universal image autoencoder.\\nThis image encoder was connected to convolution blocks to built the final\\nmodel. It was further fine tuned with the help of ST-Data. This model is\\nnotably lightweight in compared to traditional histological models. Our\\ndeveloped model demonstrates significant efficiency compared to contemporary\\nalgorithms, revealing a correlation of 0.56 in leave-one-out cross-validation.\\nFinally, its robustness was validated through an independent dataset, showing a\\nwell matched preditction with predefined disease pathology.', 'post': '', 'evaluation': ''}, {'title': 'Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity', 'summary': 'Cardiotoxicity induced by cancer treatment has become a major clinical\\nconcern, affecting the long-term survival and quality of life of cancer\\npatients. Effective clinical decision-making, including the detection of cancer\\ntreatment-induced cardiotoxicity and the monitoring of associated symptoms,\\nremains a challenging task for clinicians. This study investigates the current\\npractices and needs of clinicians in the clinical decision making of cancer\\ntreatment-induced cardiotoxicity and explores the potential of digital health\\ntechnologies to support this process. Through semi-structured interviews with\\nseven clinical experts, we identify a three-step decision-making paradigm: 1)\\nsymptom identification, 2) diagnostic testing and specialist collaboration, and\\n3) clinical decision-making and intervention. Our findings highlight the\\ndifficulties of diagnosing cardiotoxicity (absence of unified protocols and\\nhigh variability in symptoms) and monitoring patient symptoms (lacking accurate\\nand timely patient self-reported symptoms). The clinicians also expressed their\\nneed for effective early detection tools that can integrate remote patient\\nmonitoring capabilities. Based on these insights, we discuss the importance of\\nunderstanding the dynamic nature of clinical workflows, and the design\\nconsiderations for future digital tools to support cancer-treatment-induced\\ncardiotoxicity decision-making.', 'post': '', 'evaluation': ''}, {'title': 'A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case', 'summary': 'This research compares large language model (LLM) fine-tuning methods,\\nincluding Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning\\n(RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally\\ncompared LLM evaluation methods including End to End (E2E) benchmark method of\\n\"Golden Answers\", traditional natural language processing (NLP) metrics, RAG\\nAssessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation,\\nusing the travel chatbot use case. The travel dataset was sourced from the the\\nReddit API by requesting posts from travel-related subreddits to get\\ntravel-related conversation prompts and personalized travel experiences, and\\naugmented for each fine-tuning method. We used two pretrained LLMs utilized for\\nfine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to\\nthe two pretrained models. The inferences from these models are extensively\\nevaluated against the aforementioned metrics. The best model according to human\\nevaluation and some GPT-4 metrics was Mistral RAFT, so this underwent a\\nReinforcement Learning from Human Feedback (RLHF) training pipeline, and\\nultimately was evaluated as the best model. Our main findings are that: 1)\\nquantitative and Ragas metrics do not align with human evaluation, 2) Open AI\\nGPT-4 evaluation most aligns with human evaluation, 3) it is essential to keep\\nhumans in the loop for evaluation because, 4) traditional NLP metrics\\ninsufficient, 5) Mistral generally outperformed LLaMa, 6) RAFT outperforms\\nQLoRA, but still needs postprocessing, 7) RLHF improves model performance\\nsignificantly. Next steps include improving data quality, increasing data\\nquantity, exploring RAG methods, and focusing data collection on a specific\\ncity, which would improve data quality by narrowing the focus, while creating a\\nuseful product.', 'post': '', 'evaluation': ''}, {'title': 'EXAONE 3.0 7.8B Instruction Tuned Language Model', 'summary': 'We introduce EXAONE 3.0 instruction-tuned language model, the first open\\nmodel in the family of Large Language Models (LLMs) developed by LG AI\\nResearch. Among different model sizes, we publicly release the 7.8B\\ninstruction-tuned model to promote open research and innovations. Through\\nextensive evaluations across a wide range of public and in-house benchmarks,\\nEXAONE 3.0 demonstrates highly competitive real-world performance with\\ninstruction-following capability against other state-of-the-art open models of\\nsimilar size. Our comparative analysis shows that EXAONE 3.0 excels\\nparticularly in Korean, while achieving compelling performance across general\\ntasks and complex reasoning. With its strong real-world effectiveness and\\nbilingual proficiency, we hope that EXAONE keeps contributing to advancements\\nin Expert AI. Our EXAONE 3.0 instruction-tuned model is available at\\nhttps://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct', 'post': '', 'evaluation': ''}, {'title': 'Measurement of the Branching Fraction of \\\\boldmath{$ψ(2S) \\\\to γ π^0$}', 'summary': 'Based on $(2712.4\\\\pm14.1)\\\\times10^{6}~\\\\psi(2S)$ events, 7.9 fb$^{-1}$\\n$\\\\psi(3773)$ data, and 0.8 fb$^{-1}$ off-resonance data samples collected with\\nthe BESIII detector, we measure the branching fraction of\\n$\\\\psi(2S)\\\\rightarrow\\\\gamma\\\\pi^{0}$ and $e^{+}e^{-}\\\\rightarrow\\\\gamma\\\\pi^{0}$\\nform factor at momentum transfers $Q^{2}\\\\sim13$ GeV$^{2}$. The\\n$e^{+}e^{-}\\\\rightarrow\\\\gamma\\\\pi^{0}$ cross section is fitted with considering\\nthe interference between the $\\\\psi(2S)$ and continuum amplitudes and two\\nsolutions are found, ${\\\\cal B}=3.74\\\\times10^{-7}$ with $\\\\phi=3.93$ rad and\\n${\\\\cal B}=7.87\\\\times10^{-7}$ with $\\\\phi=2.08$ rad. Here, ${\\\\cal B}$ is the\\nbranching fraction of $\\\\psi(2S)\\\\rightarrow\\\\gamma\\\\pi^{0}$ and $\\\\phi$ is the\\nrelative phase angle between the $\\\\psi(2S)$ and continuum amplitudes. Due to\\ninsufficient off-resonance data, the branching fraction ${\\\\cal\\nB}(\\\\psi(2S)\\\\rightarrow\\\\gamma\\\\pi^{0})$ is determined to be in the range $[2.7,\\n9.7]\\\\times10^{-7}$ within one standard deviation of the contour region.', 'post': '', 'evaluation': ''}, {'title': 'MoExtend: Tuning New Experts for Modality and Task Extension', 'summary': 'Large language models (LLMs) excel in various tasks but are primarily trained\\non text data, limiting their application scope. Expanding LLM capabilities to\\ninclude vision-language understanding is vital, yet training them on multimodal\\ndata from scratch is challenging and costly. Existing instruction tuning\\nmethods, e.g., LLAVA, often connects a pretrained CLIP vision encoder and LLMs\\nvia fully fine-tuning LLMs to bridge the modality gap. However, full\\nfine-tuning is plagued by catastrophic forgetting, i.e., forgetting previous\\nknowledge, and high training costs particularly in the era of increasing tasks\\nand modalities. To solve this issue, we introduce MoExtend, an effective\\nframework designed to streamline the modality adaptation and extension of\\nMixture-of-Experts (MoE) models. MoExtend seamlessly integrates new experts\\ninto pre-trained MoE models, endowing them with novel knowledge without the\\nneed to tune pretrained models such as MoE and vision encoders. This approach\\nenables rapid adaptation and extension to new modal data or tasks, effectively\\naddressing the challenge of accommodating new modalities within LLMs.\\nFurthermore, MoExtend avoids tuning pretrained models, thus mitigating the risk\\nof catastrophic forgetting. Experimental results demonstrate the efficacy and\\nefficiency of MoExtend in enhancing the multimodal capabilities of LLMs,\\ncontributing to advancements in multimodal AI research. Code:\\nhttps://github.com/zhongshsh/MoExtend.', 'post': '', 'evaluation': ''}, {'title': '1.5-Pints Technical Report: Pretraining in Days, Not Months -- Your Language Model Thrives on Quality Data', 'summary': 'This paper presents a compute-efficient approach to pre-training a Language\\nModel-the \"1.5-Pints\"-in only 9 days, while outperforming state-of-the-art\\nmodels as an instruction-following assistant.Based on MT-Bench (a benchmark\\nthat emulates human judgments), 1.5-Pints outperforms Apple\\'s OpenELM and\\nMicrosoft\\'s Phi.This is achieved by a carefully curated pre-training dataset of\\n57 billion tokens, using a mix of automated workflows and manual human review.\\nThe selection of the dataset prioritizes content that is considered expository\\nand \"textbook-like\" to aid the model in reasoning and logical deduction,\\nculminating in its overall ability as a strong and versatile AI model. In terms\\nof the model architecture, we employed a modified Mistral tokenizer, alongside\\na Llama-2 architecture for wider compatibility. For training, we adopted the\\nmethodologies used by StableLM, TinyLlama, and Huggingface Zephyr. 1.5-Pints\\ndemonstrates that by focusing on data quality over quantity in LLM training, we\\ncan significantly reduce training time and resources required. We believe this\\napproach will not only make pre-training more accessible but also reduce our\\ncarbon footprint. Our findings and resources from this research are\\nopen-sourced, aiming to facilitate further advancements in the field. The\\n1.5-Pints model is available in two versions: 2K and 16K context windows.', 'post': '', 'evaluation': ''}, {'title': 'Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and Tabnet with SMOTEENN', 'summary': \"Bank credit risk is a significant challenge in modern financial transactions,\\nand the ability to identify qualified credit card holders among a large number\\nof applicants is crucial for the profitability of a bank'sbank's credit card\\nbusiness. In the past, screening applicants'applicants' conditions often\\nrequired a significant amount of manual labor, which was time-consuming and\\nlabor-intensive. Although the accuracy and reliability of previously used ML\\nmodels have been continuously improving, the pursuit of more reliable and\\npowerful AI intelligent models is undoubtedly the unremitting pursuit by major\\nbanks in the financial industry. In this study, we used a dataset of over\\n40,000 records provided by a commercial bank as the research object. We\\ncompared various dimensionality reduction techniques such as PCA and T-SNE for\\npreprocessing high-dimensional datasets and performed in-depth adaptation and\\ntuning of distributed models such as LightGBM and XGBoost, as well as deep\\nmodels like Tabnet. After a series of research and processing, we obtained\\nexcellent research results by combining SMOTEENN with these techniques. The\\nexperiments demonstrated that LightGBM combined with PCA and SMOTEENN\\ntechniques can assist banks in accurately predicting potential high-quality\\ncustomers, showing relatively outstanding performance compared to other models.\", 'post': '', 'evaluation': ''}, {'title': 'AI Foundation Models in Remote Sensing: A Survey', 'summary': 'Artificial Intelligence (AI) technologies have profoundly transformed the\\nfield of remote sensing, revolutionizing data collection, processing, and\\nanalysis. Traditionally reliant on manual interpretation and task-specific\\nmodels, remote sensing has been significantly enhanced by the advent of\\nfoundation models--large-scale, pre-trained AI models capable of performing a\\nwide array of tasks with unprecedented accuracy and efficiency. This paper\\nprovides a comprehensive survey of foundation models in the remote sensing\\ndomain, covering models released between June 2021 and June 2024. We categorize\\nthese models based on their applications in computer vision and domain-specific\\ntasks, offering insights into their architectures, pre-training datasets, and\\nmethodologies. Through detailed performance comparisons, we highlight emerging\\ntrends and the significant advancements achieved by these foundation models.\\nAdditionally, we discuss the technical challenges, practical implications, and\\nfuture research directions, addressing the need for high-quality data,\\ncomputational resources, and improved model generalization. Our research also\\nfinds that pre-training methods, particularly self-supervised learning\\ntechniques like contrastive learning and masked autoencoders, significantly\\nenhance the performance and robustness of foundation models in remote sensing\\ntasks such as scene classification, object detection, and other applications.\\nThis survey aims to serve as a resource for researchers and practitioners by\\nproviding a panorama of advances and promising pathways for continued\\ndevelopment and application of foundation models in remote sensing.', 'post': '', 'evaluation': ''}, {'title': 'Spacecraft inertial parameters estimation using time series clustering and reinforcement learning', 'summary': 'This paper presents a machine learning approach to estimate the inertial\\nparameters of a spacecraft in cases when those change during operations, e.g.\\nmultiple deployments of payloads, unfolding of appendages and booms, propellant\\nconsumption as well as during in-orbit servicing and active debris removal\\noperations. The machine learning approach uses time series clustering together\\nwith an optimised actuation sequence generated by reinforcement learning to\\nfacilitate distinguishing among different inertial parameter sets. The\\nperformance of the proposed strategy is assessed against the case of a\\nmulti-satellite deployment system showing that the algorithm is resilient\\ntowards common disturbances in such kinds of operations.', 'post': '', 'evaluation': ''}, {'title': 'Working with Color: How Color Quantization Can Aid Researchers of Problematic Information', 'summary': 'Analyzing large sets of visual media remains a challenging task, particularly\\nin mixed-method studies dealing with problematic information and human\\nsubjects. Using AI tools in such analyses risks reifying and exacerbating\\nbiases, as well as untenable computational and cost limitations. As such, we\\nturn to adopting geometric computer graphics and vision methods towards\\nanalyzing a large set of images from a problematic information campaign, in\\nconjunction with human-in-the-loop qualitative analysis. We illustrate an\\neffective case of this approach with the implementation of color quantization\\ntowards analyzing online hate image at the US-Mexico border, along with a\\nhistoricist trace of the history of color quantization and skin tone scales, to\\ninform our usage and reclamation of these methodologies from their racist\\norigins. To that end, we scaffold motivations and the need for more researchers\\nto consider the advantages and risks of reclaiming such methodologies in their\\nown work, situated in our case study.', 'post': '', 'evaluation': ''}, {'title': 'The AI-Native Software Development Lifecycle: A Theoretical and Practical New Methodology', 'summary': 'As AI continues to advance and impact every phase of the software development\\nlifecycle (SDLC), a need for a new way of building software will emerge. By\\nanalyzing the factors that influence the current state of the SDLC and how\\nthose will change with AI we propose a new model of development. This white\\npaper proposes the emergence of a fully AI-native SDLC, where AI is integrated\\nseamlessly into every phase of development, from planning to deployment. We\\nintroduce the V-Bounce model, an adaptation of the traditional V-model that\\nincorporates AI from end to end. The V-Bounce model leverages AI to\\ndramatically reduce time spent in implementation phases, shifting emphasis\\ntowards requirements gathering, architecture design, and continuous validation.\\nThis model redefines the role of humans from primary implementers to primarily\\nvalidators and verifiers with AI acting as an implementation engine.', 'post': '', 'evaluation': ''}, {'title': 'Logistic Regression makes small LLMs strong and explainable \"tens-of-shot\" classifiers', 'summary': 'For simple classification tasks, we show that users can benefit from the\\nadvantages of using small, local, generative language models instead of large\\ncommercial models without a trade-off in performance or introducing extra\\nlabelling costs. These advantages, including those around privacy,\\navailability, cost, and explainability, are important both in commercial\\napplications and in the broader democratisation of AI. Through experiments on\\n17 sentence classification tasks (2-4 classes), we show that penalised logistic\\nregression on the embeddings from a small LLM equals (and usually betters) the\\nperformance of a large LLM in the \"tens-of-shot\" regime. This requires no more\\nlabelled instances than are needed to validate the performance of the large\\nLLM. Finally, we extract stable and sensible explanations for classification\\ndecisions.', 'post': '', 'evaluation': ''}, {'title': 'GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI', 'summary': \"Large Vision-Language Models (LVLMs) are capable of handling diverse data\\ntypes such as imaging, text, and physiological signals, and can be applied in\\nvarious fields. In the medical field, LVLMs have a high potential to offer\\nsubstantial assistance for diagnosis and treatment. Before that, it is crucial\\nto develop benchmarks to evaluate LVLMs' effectiveness in various medical\\napplications. Current benchmarks are often built upon specific academic\\nliterature, mainly focusing on a single domain, and lacking varying perceptual\\ngranularities. Thus, they face specific challenges, including limited clinical\\nrelevance, incomplete evaluations, and insufficient guidance for interactive\\nLVLMs. To address these limitations, we developed the GMAI-MMBench, the most\\ncomprehensive general medical AI benchmark with well-categorized data structure\\nand multi-perceptual granularity to date. It is constructed from 285 datasets\\nacross 39 medical image modalities, 18 clinical-related tasks, 18 departments,\\nand 4 perceptual granularities in a Visual Question Answering (VQA) format.\\nAdditionally, we implemented a lexical tree structure that allows users to\\ncustomize evaluation tasks, accommodating various assessment needs and\\nsubstantially supporting medical AI research and applications. We evaluated 50\\nLVLMs, and the results show that even the advanced GPT-4o only achieves an\\naccuracy of 52%, indicating significant room for improvement. Moreover, we\\nidentified five key insufficiencies in current cutting-edge LVLMs that need to\\nbe addressed to advance the development of better medical applications. We\\nbelieve that GMAI-MMBench will stimulate the community to build the next\\ngeneration of LVLMs toward GMAI.\\n  Project Page: https://uni-medical.github.io/GMAI-MMBench.github.io/\", 'post': '', 'evaluation': ''}, {'title': 'Left of Fab: Securing Design and Collaboration in the Semiconductor Value Chain', 'summary': 'The purpose of this paper is to fill a gap in the general understanding --\\nand academic scrutiny -- of current and emerging workflows for designing and\\nfabricating integrated circuits. The approach is to compare the IC design\\nworkflow with that for printed circuit boards, then to discern a classification\\nfor threats. The need to define and secure workflows is amplified by both U.S.\\ninvestment in the semiconductor manufacturing and market forces affecting GPU\\nproduction for AI applications. The origin of this knowledge gap can be the\\nproprietary nature of solution spaces, but it can be the lack of demand for\\nteaching and learning for engineers and technicians in this domain. This paper\\npresents a framework for understanding the security of design workflows in a\\nvendor- and tool-agnostic way.', 'post': '', 'evaluation': ''}, {'title': 'Measurement of $Σ^+$ transverse polarization in $e^+e^-$ collisions at $\\\\sqrt{s} = 3.68-3.71$ GeV', 'summary': 'Using $e^+e^-$ collision data collected with the BESIII detector at seven\\nenergy points ranging from 3.68 to 3.71 GeV and corresponding to an integrated\\nluminosity of $652.1~{\\\\rm pb^{-1}}$, we present an energy-dependent measurement\\nof the transverse polarization, relative phase and modulus ratio of the\\nelectromagnetic form factors of the $\\\\Sigma^+$ hyperon in the $e^+e^- \\\\to\\n\\\\Sigma^+ \\\\bar{\\\\Sigma}^-$ reaction. These results are helpful to understand the\\nproduction mechanism of the $\\\\Sigma^+$-$\\\\bar\\\\Sigma^-$ pairs.', 'post': '', 'evaluation': ''}, {'title': 'Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study', 'summary': \"Dilated Convolution with Learnable Spacing (DCLS) is a recent advanced\\nconvolution method that allows enlarging the receptive fields (RF) without\\nincreasing the number of parameters, like the dilated convolution, yet without\\nimposing a regular grid. DCLS has been shown to outperform the standard and\\ndilated convolutions on several computer vision benchmarks. Here, we show that,\\nin addition, DCLS increases the models' interpretability, defined as the\\nalignment with human visual strategies. To quantify it, we use the Spearman\\ncorrelation between the models' GradCAM heatmaps and the ClickMe dataset\\nheatmaps, which reflect human visual attention. We took eight reference models\\n- ResNet50, ConvNeXt (T, S and B), CAFormer, ConvFormer, and FastViT (sa 24 and\\n36) - and drop-in replaced the standard convolution layers with DCLS ones. This\\nimproved the interpretability score in seven of them. Moreover, we observed\\nthat Grad-CAM generated random heatmaps for two models in our study: CAFormer\\nand ConvFormer models, leading to low interpretability scores. We addressed\\nthis issue by introducing Threshold-Grad-CAM, a modification built on top of\\nGrad-CAM that enhanced interpretability across nearly all models. The code and\\ncheckpoints to reproduce this study are available at:\\nhttps://github.com/rabihchamas/DCLS-GradCAM-Eval.\", 'post': '', 'evaluation': ''}, {'title': 'Iterative CT Reconstruction via Latent Variable Optimization of Shallow Diffusion Models', 'summary': \"Image generative AI has garnered significant attention in recent years. In\\nparticular, the diffusion model, a core component of recent generative AI,\\nproduces high-quality images with rich diversity. In this study, we propose a\\nnovel CT reconstruction method by combining the denoising diffusion\\nprobabilistic model with iterative CT reconstruction. In sharp contrast to\\nprevious studies, we optimize the fidelity loss of CT reconstruction with\\nrespect to the latent variable of the diffusion model, instead of the image and\\nmodel parameters. To suppress anatomical structure changes produced by the\\ndiffusion model, we shallow the diffusion and reverse processes, and fix a set\\nof added noises in the reverse process to make it deterministic during\\ninference. We demonstrate the effectiveness of the proposed method through\\nsparse view CT reconstruction of 1/10 view projection data. Despite the\\nsimplicity of the implementation, the proposed method shows the capability of\\nreconstructing high-quality images while preserving the patient's anatomical\\nstructure, and outperforms existing methods including iterative reconstruction,\\niterative reconstruction with total variation, and the diffusion model alone in\\nterms of quantitative indices such as SSIM and PSNR. We also explore further\\nsparse view CT using 1/20 view projection data with the same trained diffusion\\nmodel. As the number of iterations increases, image quality improvement\\ncomparable to that of 1/10 sparse view CT reconstruction is achieved. In\\nprinciple, the proposed method can be widely applied not only to CT but also to\\nother imaging modalities such as MRI, PET, and SPECT.\", 'post': '', 'evaluation': ''}, {'title': 'L3iTC at the FinLLM Challenge Task: Quantization for Financial Text Classification & Summarization', 'summary': 'This article details our participation (L3iTC) in the FinLLM Challenge Task\\n2024, focusing on two key areas: Task 1, financial text classification, and\\nTask 2, financial text summarization. To address these challenges, we\\nfine-tuned several large language models (LLMs) to optimize performance for\\neach task. Specifically, we used 4-bit quantization and LoRA to determine which\\nlayers of the LLMs should be trained at a lower precision. This approach not\\nonly accelerated the fine-tuning process on the training data provided by the\\norganizers but also enabled us to run the models on low GPU memory. Our\\nfine-tuned models achieved third place for the financial classification task\\nwith an F1-score of 0.7543 and secured sixth place in the financial\\nsummarization task on the official test datasets.', 'post': '', 'evaluation': ''}, {'title': 'NeurDB: On the Design and Implementation of an AI-powered Autonomous Database', 'summary': 'Databases are increasingly embracing AI to provide autonomous system\\noptimization and intelligent in-database analytics, aiming to relieve end-user\\nburdens across various industry sectors. Nonetheless, most existing approaches\\nfail to account for the dynamic nature of databases, which renders them\\nineffective for real-world applications characterized by evolving data and\\nworkloads. This paper introduces NeurDB, an AI-powered autonomous database that\\ndeepens the fusion of AI and databases with adaptability to data and workload\\ndrift. NeurDB establishes a new in-database AI ecosystem that seamlessly\\nintegrates AI workflows within the database. This integration enables efficient\\nand effective in-database AI analytics and fast-adaptive learned system\\ncomponents. Empirical evaluations demonstrate that NeurDB substantially\\noutperforms existing solutions in managing AI analytics tasks, with the\\nproposed learned components more effectively handling environmental dynamism\\nthan state-of-the-art approaches.', 'post': '', 'evaluation': ''}, {'title': 'Sample-agnostic Adversarial Perturbation for Vision-Language Pre-training Models', 'summary': \"Recent studies on AI security have highlighted the vulnerability of\\nVision-Language Pre-training (VLP) models to subtle yet intentionally designed\\nperturbations in images and texts. Investigating multimodal systems' robustness\\nvia adversarial attacks is crucial in this field. Most multimodal attacks are\\nsample-specific, generating a unique perturbation for each sample to construct\\nadversarial samples. To the best of our knowledge, it is the first work through\\nmultimodal decision boundaries to explore the creation of a universal,\\nsample-agnostic perturbation that applies to any image. Initially, we explore\\nstrategies to move sample points beyond the decision boundaries of linear\\nclassifiers, refining the algorithm to ensure successful attacks under the top\\n$k$ accuracy metric. Based on this foundation, in visual-language tasks, we\\ntreat visual and textual modalities as reciprocal sample points and decision\\nhyperplanes, guiding image embeddings to traverse text-constructed decision\\nboundaries, and vice versa. This iterative process consistently refines a\\nuniversal perturbation, ultimately identifying a singular direction within the\\ninput space which is exploitable to impair the retrieval performance of VLP\\nmodels. The proposed algorithms support the creation of global perturbations or\\nadversarial patches. Comprehensive experiments validate the effectiveness of\\nour method, showcasing its data, task, and model transferability across various\\nVLP models and datasets. Code: https://github.com/LibertazZ/MUAP\", 'post': '', 'evaluation': ''}, {'title': 'Adversarial Robustness of Open-source Text Classification Models and Fine-Tuning Chains', 'summary': \"Context:With the advancement of artificial intelligence (AI) technology and\\napplications, numerous AI models have been developed, leading to the emergence\\nof open-source model hosting platforms like Hugging Face (HF). Thanks to these\\nplatforms, individuals can directly download and use models, as well as\\nfine-tune them to construct more domain-specific models. However, just like\\ntraditional software supply chains face security risks, AI models and\\nfine-tuning chains also encounter new security risks, such as adversarial\\nattacks. Therefore, the adversarial robustness of these models has garnered\\nattention, potentially influencing people's choices regarding open-source\\nmodels. Objective:This paper aims to explore the adversarial robustness of\\nopen-source AI models and their chains formed by the upstream-downstream\\nrelationships via fine-tuning to provide insights into the potential\\nadversarial risks. Method:We collect text classification models on HF and\\nconstruct the fine-tuning chains.Then, we conduct an empirical analysis of\\nmodel reuse and associated robustness risks under existing adversarial attacks\\nfrom two aspects, i.e., models and their fine-tuning chains. Results:Despite\\nthe models' widespread downloading and reuse, they are generally susceptible to\\nadversarial attack risks, with an average of 52.70% attack success rate.\\nMoreover, fine-tuning typically exacerbates this risk, resulting in an average\\n12.60% increase in attack success rates. We also delve into the influence of\\nfactors such as attack techniques, datasets, and model architectures on the\\nsuccess rate, as well as the transitivity along the model chains.\", 'post': '', 'evaluation': ''}, {'title': 'WWW: Where, Which and Whatever Enhancing Interpretability in Multimodal Deepfake Detection', 'summary': 'All current benchmarks for multimodal deepfake detection manipulate entire\\nframes using various generation techniques, resulting in oversaturated\\ndetection accuracies exceeding 94% at the video-level classification. However,\\nthese benchmarks struggle to detect dynamic deepfake attacks with challenging\\nframe-by-frame alterations presented in real-world scenarios. To address this\\nlimitation, we introduce FakeMix, a novel clip-level evaluation benchmark aimed\\nat identifying manipulated segments within both video and audio, providing\\ninsight into the origins of deepfakes. Furthermore, we propose novel evaluation\\nmetrics, Temporal Accuracy (TA) and Frame-wise Discrimination Metric (FDM), to\\nassess the robustness of deepfake detection models. Evaluating state-of-the-art\\nmodels against diverse deepfake benchmarks, particularly FakeMix, demonstrates\\nthe effectiveness of our approach comprehensively. Specifically, while\\nachieving an Average Precision (AP) of 94.2% at the video-level, the evaluation\\nof the existing models at the clip-level using the proposed metrics, TA and\\nFDM, yielded sharp declines in accuracy to 53.1%, and 52.1%, respectively.', 'post': '', 'evaluation': ''}, {'title': 'Observation of $η_{c}(2S) \\\\to K^{+}K^{-}η$', 'summary': 'By analyzing $(27.12 \\\\pm 0.14)\\\\times10^{8}$ $\\\\psi(3686)$ events accumulated\\nwith the BESIII detector, the decay $\\\\eta_{c}(2S) \\\\to K^{+} K^{-} \\\\eta$ is\\nobserved for the first time with a significance of $6.2\\\\sigma$ after\\nconsidering systematic uncertainties. The product of the branching fractions of\\n$\\\\psi(3686) \\\\to \\\\gamma\\\\eta_{c}(2S)$ and $\\\\eta_{c}(2S) \\\\to K^{+} K^{-} \\\\eta$ is\\nmeasured to be $\\\\mathcal{B}(\\\\psi(3686) \\\\to\\\\gamma\\\\eta_{c}(2S))\\\\times\\n\\\\mathcal{B}(\\\\eta_{c}(2S)\\\\to K^{+} K^{-}\\\\eta)=(2.39 \\\\pm 0.32 \\\\pm 0.34) \\\\times\\n10^{-6}$, where the first uncertainty is statistical, and the second one is\\nsystematic. The branching fraction of $\\\\eta_{c}(2S)\\\\to K^{+} K^{-}\\\\eta$ is\\ndetermined to be $\\\\mathcal{B}(\\\\eta_{c}(2S)\\\\to K^{+} K^{-}\\\\eta) = (3.42 \\\\pm 0.46\\n\\\\pm 0.48 \\\\pm 2.44) \\\\times 10^{-3}$, where the third uncertainty is due to the\\nbranching fraction of $\\\\psi(3686) \\\\to \\\\gamma\\\\eta_{c}(2S)$. Using a recent\\nBESIII measurement of $\\\\mathcal{B} (\\\\eta_{c}(2S) \\\\to K^{+} K^{-}\\\\pi^{0})$, we\\nalso determine the ratio between the branching fractions of $\\\\eta_{c}(2S) \\\\to\\nK^{+} K^{-}\\\\eta$ and $\\\\eta_{c}(2S) \\\\to K^{+} K^{-}\\\\pi^{0}$ to be $1.49 \\\\pm 0.22\\n\\\\pm 0.25$, which is consistent with the previous result of BaBar at a\\ncomparable precision level.', 'post': '', 'evaluation': ''}, {'title': 'Interoperability and Explicable AI-based Zero-Day Attacks Detection Process in Smart Community', 'summary': \"Systems, technologies, protocols, and infrastructures all face\\ninteroperability challenges. It is among the most crucial parameters to give\\nreal-world effectiveness. Organizations that achieve interoperability will be\\nable to identify, prevent, and provide appropriate protection on an\\ninternational scale, which can be relied upon. This paper aims to explain how\\nfuture technologies such as 6G mobile communication, Internet of Everything\\n(IoE), Artificial Intelligence (AI), and Smart Contract embedded WPA3\\nprotocol-based WiFi-8 can work together to prevent known attack vectors and\\nprovide protection against zero-day attacks, thus offering intelligent\\nsolutions for smart cities. The phrase zero-day refers to an attack that occurs\\non the day zero of the vulnerability's disclosure to the public or vendor.\\nExisting systems require an extra layer of security. In the security world,\\ninteroperability enables disparate security solutions and systems to\\ncollaborate seamlessly. AI improves cybersecurity by enabling improved\\ncapabilities for detecting, responding, and preventing zero-day attacks. When\\ninteroperability and Explainable Artificial Intelligence (XAI) are integrated\\ninto cybersecurity, they form a strong protection against zero-day assaults.\\nAdditionally, we evaluate a couple of parameters based on the accuracy and time\\nrequired for efficiently analyzing attack patterns and anomalies.\", 'post': '', 'evaluation': ''}, {'title': 'A Taxonomy of Architecture Options for Foundation Model-based Agents: Analysis and Decision Model', 'summary': 'The rapid advancement of AI technology has led to widespread applications of\\nagent systems across various domains. However, the need for detailed\\narchitecture design poses significant challenges in designing and operating\\nthese systems. This paper introduces a taxonomy focused on the architectures of\\nfoundation-model-based agents, addressing critical aspects such as functional\\ncapabilities and non-functional qualities. We also discuss the operations\\ninvolved in both design-time and run-time phases, providing a comprehensive\\nview of architectural design and operational characteristics. By unifying and\\ndetailing these classifications, our taxonomy aims to improve the design of\\nfoundation-model-based agents. Additionally, the paper establishes a decision\\nmodel that guides critical design and runtime decisions, offering a structured\\napproach to enhance the development of foundation-model-based agents. Our\\ncontributions include providing a structured architecture design option and\\nguiding the development process of foundation-model-based agents, thereby\\naddressing current fragmentation in the field.', 'post': '', 'evaluation': ''}, {'title': 'MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular Annotations for Medicine', 'summary': 'This paper introduces MedTrinity-25M, a comprehensive, large-scale multimodal\\ndataset for medicine, covering over 25 million images across 10 modalities,\\nwith multigranular annotations for more than 65 diseases. These enriched\\nannotations encompass both global textual information, such as disease/lesion\\ntype, modality, region-specific descriptions, and inter-regional relationships,\\nas well as detailed local annotations for regions of interest (ROIs), including\\nbounding boxes, segmentation masks. Unlike existing approach which is limited\\nby the availability of image-text pairs, we have developed the first automated\\npipeline that scales up multimodal data by generating multigranular visual and\\ntexual annotations (in the form of image-ROI-description triplets) without the\\nneed for any paired text descriptions. Specifically, data from over 90\\ndifferent sources have been collected, preprocessed, and grounded using\\ndomain-specific expert models to identify ROIs related to abnormal regions. We\\nthen build a comprehensive knowledge base and prompt multimodal large language\\nmodels to perform retrieval-augmented generation with the identified ROIs as\\nguidance, resulting in multigranular texual descriptions. Compared to existing\\ndatasets, MedTrinity-25M provides the most enriched annotations, supporting a\\ncomprehensive range of multimodal tasks such as captioning and report\\ngeneration, as well as vision-centric tasks like classification and\\nsegmentation. Pretraining on MedTrinity-25M, our model achieves\\nstate-of-the-art performance on VQA-RAD and PathVQA, surpassing both multimodal\\nlarge language models and other representative SoTA approaches. This dataset\\ncan also be utilized to support large-scale pre-training of multimodal medical\\nAI models, contributing to the development of future foundation models in the\\nmedical domain.', 'post': '', 'evaluation': ''}, {'title': 'Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning', 'summary': 'As content generated by Large Language Model (LLM) has grown exponentially,\\nthe ability to accurately identify and fingerprint such text has become\\nincreasingly crucial. In this work, we introduce a novel black-box approach for\\nfingerprinting LLMs, achieving an impressive 72% accuracy in identifying the\\ncorrect family of models (Such as Llama, Mistral, Gemma, etc) among a lineup of\\nLLMs. We present an evolutionary strategy that leverages the capabilities of\\none LLM to discover the most salient features for identifying other LLMs. Our\\nmethod employs a unique \"Hide and Seek\" algorithm, where an Auditor LLM\\ngenerates discriminative prompts, and a Detective LLM analyzes the responses to\\nfingerprint the target models. This approach not only demonstrates the\\nfeasibility of LLM-driven model identification but also reveals insights into\\nthe semantic manifolds of different LLM families. By iteratively refining\\nprompts through in-context learning, our system uncovers subtle distinctions\\nbetween model outputs, providing a powerful tool for LLM analysis and\\nverification. This research opens new avenues for understanding LLM behavior\\nand has significant implications for model attribution, security, and the\\nbroader field of AI transparency.', 'post': '', 'evaluation': ''}, {'title': 'On The Stability of Moral Preferences: A Problem with Computational Elicitation Methods', 'summary': \"Preference elicitation frameworks feature heavily in the research on\\nparticipatory ethical AI tools and provide a viable mechanism to enquire and\\nincorporate the moral values of various stakeholders. As part of the\\nelicitation process, surveys about moral preferences, opinions, and judgments\\nare typically administered only once to each participant. This methodological\\npractice is reasonable if participants' responses are stable over time such\\nthat, all other relevant factors being held constant, their responses today\\nwill be the same as their responses to the same questions at a later time.\\nHowever, we do not know how often that is the case. It is possible that\\nparticipants' true moral preferences change, are subject to temporary moods or\\nwhims, or are influenced by environmental factors we don't track. If\\nparticipants' moral responses are unstable in such ways, it would raise\\nimportant methodological and theoretical issues for how participants' true\\nmoral preferences, opinions, and judgments can be ascertained. We address this\\npossibility here by asking the same survey participants the same moral\\nquestions about which patient should receive a kidney when only one is\\navailable ten times in ten different sessions over two weeks, varying only\\npresentation order across sessions. We measured how often participants gave\\ndifferent responses to simple (Study One) and more complicated (Study Two)\\nrepeated scenarios. On average, the fraction of times participants changed\\ntheir responses to controversial scenarios was around 10-18% across studies,\\nand this instability is observed to have positive associations with response\\ntime and decision-making difficulty. We discuss the implications of these\\nresults for the efficacy of moral preference elicitation, highlighting the role\\nof response instability in causing value misalignment between stakeholders and\\nAI tools trained on their moral judgments.\", 'post': '', 'evaluation': ''}, {'title': 'On the Variability of AI-based Software Systems Due to Environment Configurations', 'summary': '[Context] Nowadays, many software systems include Artificial Intelligence\\n(AI) components and changes in the development environment have been known to\\ninduce variability in an AI-based system. [Objective] However, how an\\nenvironment configuration impacts the variability of these systems is yet to be\\nexplored. Understanding and quantifying the degree of variability due to such\\nconfigurations can help practitioners decide the best environment configuration\\nfor the most stable AI products. [Method] To achieve this goal, we performed\\nexperiments with eight different combinations of three key environment\\nvariables (operating system, Python version, and CPU architecture) on 30\\nopen-source AI-based systems using the Travis CI platform. We evaluate\\nvariability using three metrics: the output of an AI component like an ML model\\n(performance), the time required to build and run a system (processing time),\\nand the cost associated with building and running a system (expense). [Results]\\nOur results indicate that variability exists in all three metrics; however, it\\nis observed more frequently with respect to processing time and expense than\\nperformance. For example, between Linux and MacOS, variabilities are observed\\nin 23%, 96.67%, and 100% of the studied projects in performance, processing\\ntime, and expense, respectively. [Conclusion] Our findings underscore the\\nimportance of identifying the optimal combination of configuration settings to\\nmitigate performance drops and reduce retraining time and cost before deploying\\nan AI-based system.', 'post': '', 'evaluation': ''}, {'title': 'Development of REGAI: Rubric Enabled Generative Artificial Intelligence', 'summary': 'This paper presents and evaluates a new retrieval augmented generation (RAG)\\nand large language model (LLM)-based artificial intelligence (AI) technique:\\nrubric enabled generative artificial intelligence (REGAI). REGAI uses rubrics,\\nwhich can be created manually or automatically by the system, to enhance the\\nperformance of LLMs for evaluation purposes. REGAI improves on the performance\\nof both classical LLMs and RAG-based LLM techniques. This paper describes\\nREGAI, presents data regarding its performance and discusses several possible\\napplication areas for the technology.', 'post': '', 'evaluation': ''}, {'title': 'Language Model Can Listen While Speaking', 'summary': \"Dialogue serves as the most natural manner of human-computer interaction\\n(HCI). Recent advancements in speech language models (SLM) have significantly\\nenhanced speech-based conversational AI. However, these models are limited to\\nturn-based conversation, lacking the ability to interact with humans in\\nreal-time spoken scenarios, for example, being interrupted when the generated\\ncontent is not satisfactory. To address these limitations, we explore full\\nduplex modeling (FDM) in interactive speech language models (iSLM), focusing on\\nenhancing real-time interaction and, more explicitly, exploring the\\nquintessential ability of interruption. We introduce a novel model design,\\nnamely listening-while-speaking language model (LSLM), an end-to-end system\\nequipped with both listening and speaking channels. Our LSLM employs a\\ntoken-based decoder-only TTS for speech generation and a streaming\\nself-supervised learning (SSL) encoder for real-time audio input. LSLM fuses\\nboth channels for autoregressive generation and detects turn-taking in real\\ntime. Three fusion strategies -- early fusion, middle fusion, and late fusion\\n-- are explored, with middle fusion achieving an optimal balance between speech\\ngeneration and real-time interaction. Two experimental settings, command-based\\nFDM and voice-based FDM, demonstrate LSLM's robustness to noise and sensitivity\\nto diverse instructions. Our results highlight LSLM's capability to achieve\\nduplex communication with minimal impact on existing systems. This study aims\\nto advance the development of interactive speech dialogue systems, enhancing\\ntheir applicability in real-world contexts.\", 'post': '', 'evaluation': ''}, {'title': 'AI-Driven Strategies for Reducing Student Withdrawal -- A Study of EMU Student Stopout', 'summary': 'Not everyone who enrolls in college will leave with a certificate or degree,\\nbut the number of people who drop out or take a break is much higher than\\nexperts previously believed. In December 2013, there were 29 million people\\nwith some college education but no degree. That number jumped to 36 million by\\nDecember of 2018, according to a new report from the National Student\\nClearinghouse Research Center[1]. It is imperative to understand the underlying\\nfactors contributing to student withdrawal and to assist decision-makers to\\nidentify effective strategies to prevent it. By analyzing the characteristics\\nand educational pathways of the stopout student population, our aim is to\\nprovide actionable insights that can benefit institutions facing similar\\nchallenges. Eastern Michigan University (EMU) faces significant challenges in\\nstudent retention, with approximately 55% of its undergraduate students not\\ncompleting their degrees within six years. As an institution committed to\\nstudent success, EMU conducted a comprehensive study of student withdrawals to\\nunderstand the influencing factors. And the paper revealed a high correlation\\nbetween certain factors and withdrawals, even in the early stages of university\\nattendance. Based on these findings, we developed a predictive model that\\nemploys artificial intelligence techniques to assess the potential risk that\\nstudents abandon their studies. These models enable universities to implement\\nearly intervention strategies, support at-risk students, and improve overall\\nhigher education success.', 'post': '', 'evaluation': ''}, {'title': 'Operational range bounding of spectroscopy models with anomaly detection', 'summary': \"Safe operation of machine learning models requires architectures that\\nexplicitly delimit their operational ranges. We evaluate the ability of anomaly\\ndetection algorithms to provide indicators correlated with degraded model\\nperformance. By placing acceptance thresholds over such indicators, hard\\nboundaries are formed that define the model's coverage. As a use case, we\\nconsider the extraction of exoplanetary spectra from transit light curves,\\nspecifically within the context of ESA's upcoming Ariel mission. Isolation\\nForests are shown to effectively identify contexts where prediction models are\\nlikely to fail. Coverage/error trade-offs are evaluated under conditions of\\ndata and concept drift. The best performance is seen when Isolation Forests\\nmodel projections of the prediction model's explainability SHAP values.\", 'post': '', 'evaluation': ''}, {'title': 'Artificial Intelligence for Public Health Surveillance in Africa: Applications and Opportunities', 'summary': \"Artificial Intelligence (AI) is revolutionizing various fields, including\\npublic health surveillance. In Africa, where health systems frequently\\nencounter challenges such as limited resources, inadequate infrastructure,\\nfailed health information systems and a shortage of skilled health\\nprofessionals, AI offers a transformative opportunity. This paper investigates\\nthe applications of AI in public health surveillance across the continent,\\npresenting successful case studies and examining the benefits, opportunities,\\nand challenges of implementing AI technologies in African healthcare settings.\\nOur paper highlights AI's potential to enhance disease monitoring and health\\noutcomes, and support effective public health interventions. The findings\\npresented in the paper demonstrate that AI can significantly improve the\\naccuracy and timeliness of disease detection and prediction, optimize resource\\nallocation, and facilitate targeted public health strategies. Additionally, our\\npaper identified key barriers to the widespread adoption of AI in African\\npublic health systems and proposed actionable recommendations to overcome these\\nchallenges.\", 'post': '', 'evaluation': ''}, {'title': 'Reasons to Doubt the Impact of AI Risk Evaluations', 'summary': 'AI safety practitioners invest considerable resources in AI system\\nevaluations, but these investments may be wasted if evaluations fail to realize\\ntheir impact. This paper questions the core value proposition of evaluations:\\nthat they significantly improve our understanding of AI risks and,\\nconsequently, our ability to mitigate those risks. Evaluations may fail to\\nimprove understanding in six ways, such as risks manifesting beyond the AI\\nsystem or insignificant returns from evaluations compared to real-world\\nobservations. Improved understanding may also not lead to better risk\\nmitigation in four ways, including challenges in upholding and enforcing\\ncommitments. Evaluations could even be harmful, for example, by triggering the\\nweaponization of dual-use capabilities or invoking high opportunity costs for\\nAI safety. This paper concludes with considerations for improving evaluation\\npractices and 12 recommendations for AI labs, external evaluators, regulators,\\nand academic researchers to encourage a more strategic and impactful approach\\nto AI risk assessment and mitigation.', 'post': '', 'evaluation': ''}, {'title': 'Generative AI as a Service in 6G Edge-Cloud: Generation Task Offloading by In-context Learning', 'summary': \"Generative artificial intelligence (GAI) is a promising technique towards 6G\\nnetworks, and generative foundation models such as large language models (LLMs)\\nhave attracted considerable interest from academia and telecom industry. This\\nwork considers a novel edge-cloud deployment of foundation models in 6G\\nnetworks. Specifically, it aims to minimize the service delay of foundation\\nmodels by radio resource allocation and task offloading, i.e., offloading\\ndiverse content generation tasks to proper LLMs at the network edge or cloud.\\nIn particular, we first introduce the communication system model, i.e.,\\nallocating radio resources and calculating link capacity to support generated\\ncontent transmission, and then we present the LLM inference model to calculate\\nthe delay of content generation. After that, we propose a novel in-context\\nlearning method to optimize the task offloading decisions. It utilizes LLM's\\ninference capabilities, and avoids the difficulty of dedicated model training\\nor fine-tuning as in conventional machine learning algorithms. Finally, the\\nsimulations demonstrate that the proposed edge-cloud deployment and in-context\\nlearning task offloading method can achieve satisfactory generation service\\nquality without dedicated model training or fine-tuning.\", 'post': '', 'evaluation': ''}, {'title': 'Towards Coarse-grained Visual Language Navigation Task Planning Enhanced by Event Knowledge Graph', 'summary': 'Visual language navigation (VLN) is one of the important research in embodied\\nAI. It aims to enable an agent to understand the surrounding environment and\\ncomplete navigation tasks. VLN instructions could be categorized into\\ncoarse-grained and fine-grained commands. Fine-grained command describes a\\nwhole task with subtasks step-by-step. In contrast, coarse-grained command\\ngives an abstract task description, which more suites human habits. Most\\nexisting work focuses on the former kind of instruction in VLN tasks, ignoring\\nthe latter abstract instructions belonging to daily life scenarios. To overcome\\nthe above challenge in abstract instruction, we attempt to consider\\ncoarse-grained instruction in VLN by event knowledge enhancement. Specifically,\\nwe first propose a prompt-based framework to extract an event knowledge graph\\n(named VLN-EventKG) for VLN integrally over multiple mainstream benchmark\\ndatasets. Through small and large language model collaboration, we realize\\nknowledge-enhanced navigation planning (named EventNav) for VLN tasks with\\ncoarse-grained instruction input. Additionally, we design a novel dynamic\\nhistory backtracking module to correct potential error action planning in real\\ntime. Experimental results in various public benchmarks show our\\nknowledge-enhanced method has superiority in coarse-grained-instruction VLN\\nusing our proposed VLN-EventKG with over $5\\\\%$ improvement in success rate. Our\\nproject is available at https://sites.google.com/view/vln-eventkg', 'post': '', 'evaluation': ''}, {'title': 'Flow with FlorDB: Incremental Context Maintenance for the Machine Learning Lifecycle', 'summary': \"The metadata involved in integrating code, data, configuration, and feedback\\ninto predictive models is varied and complex. This complexity is further\\ncompounded by the agile development practices favored by data scientists and\\nmachine learning engineers. These practices emphasize high experimentation\\nvelocity and frequent deployments, which can make it challenging to keep track\\nof all the relevant metadata. The iterative nature of agile methods means that\\nmodels, datasets, and configurations are constantly evolving. Each experiment\\nmight involve tweaks to the data preprocessing steps, changes in model\\nhyperparameters, or updates to the deployment environment. The need for rapid\\niteration can lead to shortcuts or oversights in documentation and metadata\\nmanagement. Effective metadata management requires robust yet flexible tools\\nand practices that can integrate and organize this information without slowing\\ndown the development process. Traditional context management often emphasizes a\\n``metadata first'' approach, which can introduce significant friction for\\ndevelopers. FlorDB reduces this friction through multiversion hindsight logging\\nand incremental context maintenance, allowing developers to add and refine\\nmetadata after the fact. This ``metadata later'' approach enables a more\\nflexible and incremental development process, allowing data scientists to focus\\non model creation and refinement without the burden of documentation upfront.\\nAs shown in a demo, FlorDB can be used to build AI/ML applications with\\nintegrated train-infer pipelines and managed feedback loops. Ultimately, the\\ngoal of FlorDB is to ensure that critical metadata is maintained accurately and\\nefficiently, even in fast-paced agile workflows.\", 'post': '', 'evaluation': ''}, {'title': 'A First Look at License Compliance Capability of LLMs in Code Generation', 'summary': 'Recent advances in Large Language Models (LLMs) have revolutionized code\\ngeneration, leading to widespread adoption of AI coding tools by developers.\\nHowever, LLMs can generate license-protected code without providing the\\nnecessary license information, leading to potential intellectual property\\nviolations during software production. This paper addresses the critical, yet\\nunderexplored, issue of license compliance in LLM-generated code by\\nestablishing a benchmark to evaluate the ability of LLMs to provide accurate\\nlicense information for their generated code. To establish this benchmark, we\\nconduct an empirical study to identify a reasonable standard for \"striking\\nsimilarity\" that excludes the possibility of independent creation, indicating a\\ncopy relationship between the LLM output and certain open-source code. Based on\\nthis standard, we propose an evaluation benchmark LiCoEval, to evaluate the\\nlicense compliance capabilities of LLMs. Using LiCoEval, we evaluate 14 popular\\nLLMs, finding that even top-performing LLMs produce a non-negligible proportion\\n(0.88% to 2.01%) of code strikingly similar to existing open-source\\nimplementations. Notably, most LLMs fail to provide accurate license\\ninformation, particularly for code under copyleft licenses. These findings\\nunderscore the urgent need to enhance LLM compliance capabilities in code\\ngeneration tasks. Our study provides a foundation for future research and\\ndevelopment to improve license compliance in AI-assisted software development,\\ncontributing to both the protection of open-source software copyrights and the\\nmitigation of legal risks for LLM users.', 'post': '', 'evaluation': ''}, {'title': 'An investigation into the causes of race bias in AI-based cine CMR segmentation', 'summary': 'Artificial intelligence (AI) methods are being used increasingly for the\\nautomated segmentation of cine cardiac magnetic resonance (CMR) imaging.\\nHowever, these methods have been shown to be subject to race bias, i.e. they\\nexhibit different levels of performance for different races depending on the\\n(im)balance of the data used to train the AI model. In this paper we\\ninvestigate the source of this bias, seeking to understand its root cause(s) so\\nthat it can be effectively mitigated. We perform a series of classification and\\nsegmentation experiments on short-axis cine CMR images acquired from Black and\\nWhite subjects from the UK Biobank and apply AI interpretability methods to\\nunderstand the results. In the classification experiments, we found that race\\ncan be predicted with high accuracy from the images alone, but less accurately\\nfrom ground truth segmentations, suggesting that the distributional shift\\nbetween races, which is often the cause of AI bias, is mostly image-based\\nrather than segmentation-based. The interpretability methods showed that most\\nattention in the classification models was focused on non-heart regions, such\\nas subcutaneous fat. Cropping the images tightly around the heart reduced\\nclassification accuracy to around chance level. Similarly, race can be\\npredicted from the latent representations of a biased segmentation model,\\nsuggesting that race information is encoded in the model. Cropping images\\ntightly around the heart reduced but did not eliminate segmentation bias. We\\nalso investigate the influence of possible confounders on the bias observed.', 'post': '', 'evaluation': ''}, {'title': \"Rayleigh-Bénard convective motion of stratified fluids in the Earth's troposphere\", 'summary': 'Recently, Kaladze and Misra [Phys. Scr. 99 (2024) 085013] showed that the\\ntropospheric stratified fluid flows may be unstable by the effects of the\\nnegative temperature gradient and the temperature-dependent density\\ninhomogeneity arising from the thermal expansion. They also predicted that the\\nmodification in the Brunt-V\\\\\"ais\\\\\"al\\\\\"a frequency by the density inhomogeneity\\ncan lead to Rayleigh-B\\\\\\'enard convective instability in the tropospheric\\nunbounded layers. The purpose of the present work is to revisit the\\nRayleigh-B\\\\\\'enard convective instability in more detail by considering both\\nunbounded and bounded tropospheric layers. We show that the conditions for\\ninstability in these two cases significantly differ. The critical values of the\\nRaleigh numbers and the expressions for the instability growth rates of thermal\\nwaves in the two cases are obtained and analyzed. In the case of the bounded\\nregion, we also derive the necessary boundary conditions and note that the\\nvertical wave number is quantified, and the corresponding eigenvalue problem is\\nwell-set.', 'post': '', 'evaluation': ''}, {'title': 'Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns', 'summary': \"This study analyzes hybrid AI systems' design patterns and their\\neffectiveness in clinical decision-making using the boxology framework. It\\ncategorizes and copares various architectures combining machine learning and\\nrule-based reasoning to provide insights into their structural foundations and\\nhealthcare applications. Addressing two main questions, how to categorize these\\nsystems againts established design patterns and how to extract insights through\\ncomparative analysis, the study uses design patterns from software engineering\\nto understand and optimize healthcare AI systems. Boxology helps identify\\ncommonalities and create reusable solutions, enhancing these systems'\\nscalability, reliability, and performance. Five primary architectures are\\nexamined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and\\nweaknesses, highlighting the need for tailored approaches in clinical tasks.\\nREML excels in high-accuracy prediction for datasets with limited data; MLRB in\\nhandling large datasets and complex data integration; RBML in explainability\\nand trustworthiness; RMLT in managing high-dimensional data; and PERML, though\\nlimited in analysis, shows promise in urgent care scenarios. The study\\nintroduces four new patterns, creates five abstract categorization patterns,\\nand refines those five further to specific systems. These contributions enhance\\nBoxlogy's taxonomical organization and offer novel approaches to integrating\\nexpert knowledge with machine learning. Boxology's structured, modular apporach\\noffers significant advantages in developing and analyzing hybrid AI systems,\\nrevealing commonalities, and promoting reusable solutions. In conclusion, this\\nstudy underscores hybrid AI systems' crucial role in advancing healthcare and\\nBoxology's potential to drive further innovation in AI integration, ultimately\\nimproving clinical decision support and patient outcomes.\", 'post': '', 'evaluation': ''}, {'title': 'FE-Adapter: Adapting Image-based Emotion Classifiers to Videos', 'summary': 'Utilizing large pre-trained models for specific tasks has yielded impressive\\nresults. However, fully fine-tuning these increasingly large models is becoming\\nprohibitively resource-intensive. This has led to a focus on more\\nparameter-efficient transfer learning, primarily within the same modality. But\\nthis approach has limitations, particularly in video understanding where\\nsuitable pre-trained models are less common. Addressing this, our study\\nintroduces a novel cross-modality transfer learning approach from images to\\nvideos, which we call parameter-efficient image-to-video transfer learning. We\\npresent the Facial-Emotion Adapter (FE-Adapter), designed for efficient\\nfine-tuning in video tasks. This adapter allows pre-trained image models, which\\ntraditionally lack temporal processing capabilities, to analyze dynamic video\\ncontent efficiently. Notably, it uses about 15 times fewer parameters than\\nprevious methods, while improving accuracy. Our experiments in video emotion\\nrecognition demonstrate that the FE-Adapter can match or even surpass existing\\nfine-tuning and video emotion models in both performance and efficiency. This\\nbreakthrough highlights the potential for cross-modality approaches in\\nenhancing the capabilities of AI models, particularly in fields like video\\nemotion analysis where the demand for efficiency and accuracy is constantly\\nrising.', 'post': '', 'evaluation': ''}, {'title': 'PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy', 'summary': 'Convolutional Neural Networks (CNNs), a prominent type of Deep Neural\\nNetworks (DNNs), have emerged as a state-of-the-art solution for solving\\nmachine learning tasks. To improve the performance and energy efficiency of CNN\\ninference, the employment of specialized hardware accelerators is prevalent.\\nHowever, CNN accelerators still face performance- and energy-efficiency\\nchallenges due to high off-chip memory (DRAM) access latency and energy, which\\nare especially crucial for latency- and energy-constrained embedded\\napplications. Moreover, different DRAM architectures have different profiles of\\naccess latency and energy, thus making it challenging to optimize them for high\\nperformance and energy-efficient CNN accelerators. To address this, we present\\nPENDRAM, a novel design space exploration methodology that enables\\nhigh-performance and energy-efficient CNN acceleration through a generalized\\nDRAM data mapping policy. Specifically, it explores the impact of different\\nDRAM data mapping policies and DRAM architectures across different CNN\\npartitioning and scheduling schemes on the DRAM access latency and energy, then\\nidentifies the pareto-optimal design choices. The experimental results show\\nthat our DRAM data mapping policy improves the energy-delay-product of DRAM\\naccesses in the CNN accelerator over other mapping policies by up to 96%. In\\nthis manner, our PENDRAM methodology offers high-performance and\\nenergy-efficient CNN acceleration under any given DRAM architectures for\\ndiverse embedded AI applications.', 'post': '', 'evaluation': ''}, {'title': 'Enhancing AI-based Generation of Software Exploits with Contextual Information', 'summary': \"This practical experience report explores Neural Machine Translation (NMT)\\nmodels' capability to generate offensive security code from natural language\\n(NL) descriptions, highlighting the significance of contextual understanding\\nand its impact on model performance. Our study employs a dataset comprising\\nreal shellcodes to evaluate the models across various scenarios, including\\nmissing information, necessary context, and unnecessary context. The\\nexperiments are designed to assess the models' resilience against incomplete\\ndescriptions, their proficiency in leveraging context for enhanced accuracy,\\nand their ability to discern irrelevant information. The findings reveal that\\nthe introduction of contextual data significantly improves performance.\\nHowever, the benefits of additional context diminish beyond a certain point,\\nindicating an optimal level of contextual information for model training.\\nMoreover, the models demonstrate an ability to filter out unnecessary context,\\nmaintaining high levels of accuracy in the generation of offensive security\\ncode. This study paves the way for future research on optimizing context use in\\nAI-driven code generation, particularly for applications requiring a high\\ndegree of technical precision such as the generation of offensive code.\", 'post': '', 'evaluation': ''}, {'title': 'Responsibility and Regulation: Exploring Social Measures of Trust in Medical AI', 'summary': 'This paper explores expert accounts of autonomous systems (AS) development in\\nthe medical device domain (MD) involving applications of artificial\\nintelligence (AI), machine learning (ML), and other algorithmic and\\nmathematical modelling techniques. We frame our observations with respect to\\nnotions of responsible innovation (RI) and the emerging problem of how to do RI\\nin practice. In contribution to the ongoing discourse surrounding trustworthy\\nautonomous system (TAS) [29], we illuminate practical challenges inherent in\\ndeploying novel AS within existing governance structures, including domain\\nspecific regulations and policies, and rigorous testing and development\\nprocesses, and discuss the implications of these for the distribution of\\nresponsibility in novel AI deployment.', 'post': '', 'evaluation': ''}, {'title': 'Operationalizing Contextual Integrity in Privacy-Conscious Assistants', 'summary': \"Advanced AI assistants combine frontier LLMs and tool access to autonomously\\nperform complex tasks on behalf of users. While the helpfulness of such\\nassistants can increase dramatically with access to user information including\\nemails and documents, this raises privacy concerns about assistants sharing\\ninappropriate information with third parties without user supervision. To steer\\ninformation-sharing assistants to behave in accordance with privacy\\nexpectations, we propose to operationalize $\\\\textit{contextual integrity}$\\n(CI), a framework that equates privacy with the appropriate flow of information\\nin a given context. In particular, we design and evaluate a number of\\nstrategies to steer assistants' information-sharing actions to be CI compliant.\\nOur evaluation is based on a novel form filling benchmark composed of synthetic\\ndata and human annotations, and it reveals that prompting frontier LLMs to\\nperform CI-based reasoning yields strong results.\", 'post': '', 'evaluation': ''}, {'title': 'Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability', 'summary': \"Because of its strong predictive skills, deep learning has emerged as an\\nessential tool in many industries, including healthcare. Traditional deep\\nlearning models, on the other hand, frequently lack interpretability and omit\\nto take prediction uncertainty into account two crucial components of clinical\\ndecision making. In order to produce explainable and uncertainty aware\\npredictions, this study presents a novel framework called Bayesian Kolmogorov\\nArnold Networks (BKANs), which combines the expressive capacity of Kolmogorov\\nArnold Networks with Bayesian inference. We employ BKANs on two medical\\ndatasets, which are widely used benchmarks for assessing machine learning\\nmodels in medical diagnostics: the Pima Indians Diabetes dataset and the\\nCleveland Heart Disease dataset. Our method provides useful insights into\\nprediction confidence and decision boundaries and outperforms traditional deep\\nlearning models in terms of prediction accuracy. Moreover, BKANs' capacity to\\nrepresent aleatoric and epistemic uncertainty guarantees doctors receive more\\nsolid and trustworthy decision support. Our Bayesian strategy improves the\\ninterpretability of the model and considerably minimises overfitting, which is\\nimportant for tiny and imbalanced medical datasets, according to experimental\\nresults. We present possible expansions to further use BKANs in more\\ncomplicated multimodal datasets and address the significance of these\\ndiscoveries for future research in building reliable AI systems for healthcare.\\nThis work paves the way for a new paradigm in deep learning model deployment in\\nvital sectors where transparency and reliability are crucial.\", 'post': '', 'evaluation': ''}, {'title': \"On the consistent reasoning paradox of intelligence and optimal trust in AI: The power of 'I don't know'\", 'summary': \"We introduce the Consistent Reasoning Paradox (CRP). Consistent reasoning,\\nwhich lies at the core of human intelligence, is the ability to handle tasks\\nthat are equivalent, yet described by different sentences ('Tell me the time!'\\nand 'What is the time?'). The CRP asserts that consistent reasoning implies\\nfallibility -- in particular, human-like intelligence in AI necessarily comes\\nwith human-like fallibility. Specifically, it states that there are problems,\\ne.g. in basic arithmetic, where any AI that always answers and strives to mimic\\nhuman intelligence by reasoning consistently will hallucinate (produce wrong,\\nyet plausible answers) infinitely often. The paradox is that there exists a\\nnon-consistently reasoning AI (which therefore cannot be on the level of human\\nintelligence) that will be correct on the same set of problems. The CRP also\\nshows that detecting these hallucinations, even in a probabilistic sense, is\\nstrictly harder than solving the original problems, and that there are problems\\nthat an AI may answer correctly, but it cannot provide a correct logical\\nexplanation for how it arrived at the answer. Therefore, the CRP implies that\\nany trustworthy AI (i.e., an AI that never answers incorrectly) that also\\nreasons consistently must be able to say 'I don't know'. Moreover, this can\\nonly be done by implicitly computing a new concept that we introduce, termed\\nthe 'I don't know' function -- something currently lacking in modern AI. In\\nview of these insights, the CRP also provides a glimpse into the behaviour of\\nArtificial General Intelligence (AGI). An AGI cannot be 'almost sure', nor can\\nit always explain itself, and therefore to be trustworthy it must be able to\\nsay 'I don't know'.\", 'post': '', 'evaluation': ''}, {'title': 'Earth System Data Cubes: Avenues for advancing Earth system research', 'summary': 'Recent advancements in Earth system science have been marked by the\\nexponential increase in the availability of diverse, multivariate datasets\\ncharacterised by moderate to high spatio-temporal resolutions. Earth System\\nData Cubes (ESDCs) have emerged as one suitable solution for transforming this\\nflood of data into a simple yet robust data structure. ESDCs achieve this by\\norganising data into an analysis-ready format aligned with a spatio-temporal\\ngrid, facilitating user-friendly analysis and diminishing the need for\\nextensive technical data processing knowledge. Despite these significant\\nbenefits, the completion of the entire ESDC life cycle remains a challenging\\ntask. Obstacles are not only of a technical nature but also relate to\\ndomain-specific problems in Earth system research. There exist barriers to\\nrealising the full potential of data collections in light of novel cloud-based\\ntechnologies, particularly in curating data tailored for specific application\\ndomains. These include transforming data to conform to a spatio-temporal grid\\nwith minimum distortions and managing complexities such as spatio-temporal\\nautocorrelation issues. Addressing these challenges is pivotal for the\\neffective application of Artificial Intelligence (AI) approaches. Furthermore,\\nadhering to open science principles for data dissemination, reproducibility,\\nvisualisation, and reuse is crucial for fostering sustainable research.\\nOvercoming these challenges offers a substantial opportunity to advance\\ndata-driven Earth system research, unlocking the full potential of an\\nintegrated, multidimensional view of Earth system processes. This is\\nparticularly true when such research is coupled with innovative research\\nparadigms and technological progress.', 'post': '', 'evaluation': ''}, {'title': 'Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction', 'summary': 'Advancements in AI and natural language processing have revolutionized\\nmachine-human language interactions, with question answering (QA) systems\\nplaying a pivotal role. The knowledge base question answering (KBQA) task,\\nutilizing structured knowledge graphs (KG), allows for handling extensive\\nknowledge-intensive questions. However, a significant gap exists in KBQA\\ndatasets, especially for low-resource languages. Many existing construction\\npipelines for these datasets are outdated and inefficient in human labor, and\\nmodern assisting tools like Large Language Models (LLM) are not utilized to\\nreduce the workload. To address this, we have designed and implemented a\\nmodern, semi-automated approach for creating datasets, encompassing tasks such\\nas KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),\\ntailored explicitly for low-resource environments. We executed this pipeline\\nand introduced the PUGG dataset, the first Polish KBQA dataset, and novel\\ndatasets for MRC and IR. Additionally, we provide a comprehensive\\nimplementation, insightful findings, detailed statistics, and evaluation of\\nbaseline models.', 'post': '', 'evaluation': ''}, {'title': 'A Lean Transformer Model for Dynamic Malware Analysis and Detection', 'summary': 'Malware is a fast-growing threat to the modern computing world and existing\\nlines of defense are not efficient enough to address this issue. This is mainly\\ndue to the fact that many prevention solutions rely on signature-based\\ndetection methods that can easily be circumvented by hackers. Therefore, there\\nis a recurrent need for behavior-based analysis where a suspicious file is ran\\nin a secured environment and its traces are collected to reports for analysis.\\nPrevious works have shown some success leveraging Neural Networks and API calls\\nsequences extracted from these execution reports.\\n  Recently, Large Language Models and Generative AI have demonstrated\\nimpressive capabilities mainly in Natural Language Processing tasks and\\npromising applications in the cybersecurity field for both attackers and\\ndefenders.\\n  In this paper, we design an Encoder-Only model, based on the Transformers\\narchitecture, to detect malicious files, digesting their API call sequences\\ncollected by an execution emulation solution. We are also limiting the size of\\nthe model architecture and the number of its parameters since it is often\\nconsidered that Large Language Models may be overkill for specific tasks such\\nas the one we are dealing with hereafter. In addition to achieving decent\\ndetection results, this approach has the advantage of reducing our carbon\\nfootprint by limiting training and inference times and facilitating technical\\noperations with less hardware requirements.\\n  We also carry out some analysis of our results and highlight the limits and\\npossible improvements when using Transformers to analyze malicious files.', 'post': '', 'evaluation': ''}, {'title': 'Backward Compatibility in Attributive Explanation and Enhanced Model Training Method', 'summary': 'Model update is a crucial process in the operation of ML/AI systems. While\\nupdating a model generally enhances the average prediction performance, it also\\nsignificantly impacts the explanations of predictions. In real-world\\napplications, even minor changes in explanations can have detrimental\\nconsequences. To tackle this issue, this paper introduces BCX, a quantitative\\nmetric that evaluates the backward compatibility of feature attribution\\nexplanations between pre- and post-update models. BCX utilizes practical\\nagreement metrics to calculate the average agreement between the explanations\\nof pre- and post-update models, specifically among samples on which both models\\naccurately predict. In addition, we propose BCXR, a BCX-aware model training\\nmethod by designing surrogate losses which theoretically lower bounds agreement\\nscores. Furthermore, we present a universal variant of BCXR that improves all\\nagreement metrics, utilizing L2 distance among the explanations of the models.\\nTo validate our approach, we conducted experiments on eight real-world\\ndatasets, demonstrating that BCXR achieves superior trade-offs between\\npredictive performances and BCX scores, showcasing the effectiveness of our\\nBCXR methods.', 'post': '', 'evaluation': ''}, {'title': 'Perception Matters: Enhancing Embodied AI with Uncertainty-Aware Semantic Segmentation', 'summary': 'Embodied AI has made significant progress acting in unexplored environments.\\nHowever, tasks such as object search have largely focused on efficient policy\\nlearning. In this work, we identify several gaps in current search methods:\\nThey largely focus on dated perception models, neglect temporal aggregation,\\nand transfer from ground truth directly to noisy perception at test time,\\nwithout accounting for the resulting overconfidence in the perceived state. We\\naddress the identified problems through calibrated perception probabilities and\\nuncertainty across aggregation and found decisions, thereby adapting the models\\nfor sequential tasks. The resulting methods can be directly integrated with\\npretrained models across a wide family of existing search approaches at no\\nadditional training cost. We perform extensive evaluations of aggregation\\nmethods across both different semantic perception models and policies,\\nconfirming the importance of calibrated uncertainties in both the aggregation\\nand found decisions. We make the code and trained models available at\\nhttp://semantic-search.cs.uni-freiburg.de.', 'post': '', 'evaluation': ''}, {'title': 'A complete characterization of split digraphs with a strong arc decomposition', 'summary': 'A \\\\textbf{strong arc decomposition} of a (multi-)digraph $D(V, A)$ is a\\npartition of its arc set $A$ into two disjoint arc sets $A_1$ and $A_2$ such\\nthat both of the spanning subdigraphs $D(V, A_1)$ and $D(V, A_2)$ are strong.\\nIn this paper, we fully characterize all split digraphs that do not have a\\nstrong decomposition. This resolves two problems proposed by Bang-Jensen and\\nWang and contributes to a series of efforts aimed at addressing this problem\\nfor specific graph classes. This work continues the research on semicomplete\\ncomposition [Bang-Jensen, Gutin and Yeo, J. Graph Theory, 2020]; on locally\\nsemicomplete digraphs [Bang-Jensen and Huang, J. Combin. Theory Ser. B, 2010];\\non a type of tournaments [Bang-Jensen and Yeo, Combinatorica, 2004].', 'post': '', 'evaluation': ''}, {'title': 'Evaluating Vision-Language Models for Zero-Shot Detection, Classification, and Association of Motorcycles, Passengers, and Helmets', 'summary': 'Motorcycle accidents pose significant risks, particularly when riders and\\npassengers do not wear helmets. This study evaluates the efficacy of an\\nadvanced vision-language foundation model, OWLv2, in detecting and classifying\\nvarious helmet-wearing statuses of motorcycle occupants using video data. We\\nextend the dataset provided by the CVPR AI City Challenge and employ a cascaded\\nmodel approach for detection and classification tasks, integrating OWLv2 and\\nCNN models. The results highlight the potential of zero-shot learning to\\naddress challenges arising from incomplete and biased training datasets,\\ndemonstrating the usage of such models in detecting motorcycles, helmet usage,\\nand occupant positions under varied conditions. We have achieved an average\\nprecision of 0.5324 for helmet detection and provided precision-recall curves\\ndetailing the detection and classification performance. Despite limitations\\nsuch as low-resolution data and poor visibility, our research shows promising\\nadvancements in automated vehicle safety and traffic safety enforcement\\nsystems.', 'post': '', 'evaluation': ''}, {'title': 'A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction', 'summary': \"Legal charge prediction, an essential task in legal AI, seeks to assign\\naccurate charge labels to case descriptions, attracting significant recent\\ninterest. Existing methods primarily employ diverse neural network structures\\nfor modeling case descriptions directly, failing to effectively leverage\\nmulti-source external knowledge. We propose a prompt learning framework-based\\nmethod that simultaneously leverages multi-source heterogeneous external\\nknowledge from a legal knowledge base, a conversational LLM, and related legal\\narticles. Specifically, we match knowledge snippets in case descriptions via\\nthe legal knowledge base and encapsulate them into the input through a hard\\nprompt template. Additionally, we retrieve legal articles related to a given\\ncase description through contrastive learning, and then obtain factual elements\\nwithin the case description through a conversational LLM. We fuse the embedding\\nvectors of soft prompt tokens with the encoding vector of factual elements to\\nachieve knowledge-enhanced model forward inference. Experimental results show\\nthat our method achieved state-of-the-art results on CAIL-2018, the largest\\nlegal charge prediction dataset, and our method has lower data dependency. Case\\nstudies also demonstrate our method's strong interpretability.\", 'post': '', 'evaluation': ''}, {'title': \"ProCreate, Don't Reproduce! Propulsive Energy Diffusion for Creative Generation\", 'summary': 'In this paper, we propose ProCreate, a simple and easy-to-implement method to\\nimprove sample diversity and creativity of diffusion-based image generative\\nmodels and to prevent training data reproduction. ProCreate operates on a set\\nof reference images and actively propels the generated image embedding away\\nfrom the reference embeddings during the generation process. We propose FSCG-8\\n(Few-Shot Creative Generation 8), a few-shot creative generation dataset on\\neight different categories -- encompassing different concepts, styles, and\\nsettings -- in which ProCreate achieves the highest sample diversity and\\nfidelity. Furthermore, we show that ProCreate is effective at preventing\\nreplicating training data in a large-scale evaluation using training text\\nprompts. Code and FSCG-8 are available at\\nhttps://github.com/Agentic-Learning-AI-Lab/procreate-diffusion-public. The\\nproject page is available at https://procreate-diffusion.github.io.', 'post': '', 'evaluation': ''}, {'title': 'More Than Positive and Negative: Communicating Fine Granularity in Medical Diagnosis', 'summary': 'With the advance of deep learning, much progress has been made in building\\npowerful artificial intelligence (AI) systems for automatic Chest X-ray (CXR)\\nanalysis. Most existing AI models are trained to be a binary classifier with\\nthe aim of distinguishing positive and negative cases. However, a large gap\\nexists between the simple binary setting and complicated real-world medical\\nscenarios. In this work, we reinvestigate the problem of automatic radiology\\ndiagnosis. We first observe that there is considerable diversity among cases\\nwithin the positive class, which means simply classifying them as positive\\nloses many important details. This motivates us to build AI models that can\\ncommunicate fine-grained knowledge from medical images like human experts. To\\nthis end, we first propose a new benchmark on fine granularity learning from\\nmedical images. Specifically, we devise a division rule based on medical\\nknowledge to divide positive cases into two subcategories, namely atypical\\npositive and typical positive. Then, we propose a new metric termed\\nAUC$^\\\\text{FG}$ on the two subcategories for evaluation of the ability to\\nseparate them apart. With the proposed benchmark, we encourage the community to\\ndevelop AI diagnosis systems that could better learn fine granularity from\\nmedical images. Last, we propose a simple risk modulation approach to this\\nproblem by only using coarse labels in training. Empirical results show that\\ndespite its simplicity, the proposed method achieves superior performance and\\nthus serves as a strong baseline.', 'post': '', 'evaluation': ''}, {'title': 'Towards AI-Safety-by-Design: A Taxonomy of Runtime Guardrails in Foundation Model based Systems', 'summary': 'The rapid advancement and widespread deployment of foundation model (FM)\\nbased systems have revolutionized numerous applications across various domains.\\nHowever, the fast-growing capabilities and autonomy have also raised\\nsignificant concerns about responsible AI and AI safety. Recently, there have\\nbeen increasing attention toward implementing guardrails to ensure the runtime\\nbehavior of FM-based systems is safe and responsible. Given the early stage of\\nFMs and their applications (such as agents), the design of guardrails have not\\nyet been systematically studied. It remains underexplored which software\\nqualities should be considered when designing guardrails and how these\\nqualities can be ensured from a software architecture perspective. Therefore,\\nin this paper, we present a taxonomy for guardrails to classify and compare the\\ncharacteristics and design options of guardrails. Our taxonomy is organized\\ninto three main categories: the motivation behind adopting runtime guardrails,\\nthe quality attributes to consider, and the design options available. This\\ntaxonomy provides structured and concrete guidance for making architectural\\ndesign decisions when designing guardrails and highlights trade-offs arising\\nfrom the design decisions.', 'post': '', 'evaluation': ''}, {'title': \"Distilling Machine Learning's Added Value: Pareto Fronts in Atmospheric Applications\", 'summary': \"While the added value of machine learning (ML) for weather and climate\\napplications is measurable, explaining it remains challenging, especially for\\nlarge deep learning models. Inspired by climate model hierarchies, we propose\\nthat a full hierarchy of Pareto-optimal models, defined within an appropriately\\ndetermined error-complexity plane, can guide model development and help\\nunderstand the models' added value. We demonstrate the use of Pareto fronts in\\natmospheric physics through three sample applications, with hierarchies ranging\\nfrom semi-empirical models with minimal tunable parameters (simplest) to deep\\nlearning algorithms (most complex). First, in cloud cover parameterization, we\\nfind that neural networks identify nonlinear relationships between cloud cover\\nand its thermodynamic environment, and assimilate previously neglected features\\nsuch as vertical gradients in relative humidity that improve the representation\\nof low cloud cover. This added value is condensed into a ten-parameter equation\\nthat rivals the performance of deep learning models. Second, we establish a ML\\nmodel hierarchy for emulating shortwave radiative transfer, distilling the\\nimportance of bidirectional vertical connectivity for accurately representing\\nabsorption and scattering, especially for multiple cloud layers. Third, we\\nemphasize the importance of convective organization information when modeling\\nthe relationship between tropical precipitation and its surrounding\\nenvironment. We discuss the added value of temporal memory when high-resolution\\nspatial information is unavailable, with implications for precipitation\\nparameterization. Therefore, by comparing data-driven models directly with\\nexisting schemes using Pareto optimality, we promote process understanding by\\nhierarchically unveiling system complexity, with the hope of improving the\\ntrustworthiness of ML models in atmospheric applications.\", 'post': '', 'evaluation': ''}, {'title': 'Investigating the hyperparameter space of deep neural network models for reaction coordinate optimization: Application to alanine dipeptide in water', 'summary': 'Identifying reaction coordinates (RCs) from many collective variable\\ncandidates have been of great challenge in understanding reaction mechanisms in\\ncomplex systems. Machine learning approaches, especially the deep neural\\nnetwork (DNN), have become a powerful tool and are actively applied. On the\\nother hand, selecting the hyperparameters that define the DNN model structure\\nremains to be a nontrivial and tedious task. Here we develop the hyperparameter\\ntuning approach to determine the parameters in an automatic fashion from the\\ntrajectory data. The DNN models are constructed to obtain a RC from many\\ncollective variables that can adequately describe the changes of the committor\\nfrom the reactant to product. The approach is applied to study the\\nisomerization of alanine dipeptide in vacuum and in water. We find that\\nmultiple DNN models with similar accuracy can be obtained, indicating that\\nhyperparameter space is multimodal. Nevertheless, despite the differences in\\nthe DNN model structure, the key features extracted using the explainable AI\\n(XAI) tools show that all RC share the same character. In particular, the\\nreaction in vacuum is characterized by the dihedral angles $\\\\phi$ and $\\\\theta$.\\nThe reaction in water also involves these dihedral angles as key features, and\\nin addition, the electrostatic potential from the solvent to the hydrogen\\n(H${}_{18}$) plays a role at about the transition state. The current study thus\\nshows that, in contrast to the diversity in the DNN models, suitably optimized\\nDNN models share the same features and share the common mechanism for the\\nreaction of interest.', 'post': '', 'evaluation': ''}, {'title': 'Self-calibrating Intelligent OCT-SLO System', 'summary': 'A unique sample independent 3D self calibration methodology is tested on a\\nunique optical coherence tomography and multi-spectral scanning laser\\nophthalmoscope (OCT-SLO) hybrid system. Operators visual cognition is replaced\\nby computer vision using the proposed novel fully automatic AI-driven system\\ndesign. Sample specific automatic contrast adjustment of the beam is achieved\\non the pre-instructed region of interest. The AI model deduces infrared,\\nfluorescence, and visual spectrum optical alignment by estimating\\npre-instructed features quantitatively. The tested approach, however, is\\nflexible enough to utilize any apt AI model. Relative comparison with classical\\nsignal-to-noise-driven automation is shown to be 200 percent inferior and 130\\npercent slower than the AI-driven approach. The best spatial resolution of the\\nsystem is found to be (a) 2.41 microns in glass bead eye phantom, 0.76 with STD\\n0.46 microns in the mouse retina in the axial direction, and (b) better than\\n228 line pair per millimeter (lp per mm) or 2 microns for all three spectrums,\\ni.e., 488 nm, 840 nm, and 520 to 550 nm emission in coronal, frontal or x-y\\nplane. Intelligent automation reduces the possibility of developing cold\\ncataracts (especially in mouse imaging) and patient-associated discomfort due\\nto delay during manual alignment by facilitating easy handling for swift ocular\\nimaging and better accuracy. The automatic novel tabletop compact system\\nprovides true functional 3D images in three different spectrums for dynamic\\nsample profiles. This is especially useful for photodynamic imaging treatment.', 'post': '', 'evaluation': ''}, {'title': 'DNA-SE: Towards Deep Neural-Nets Assisted Semiparametric Estimation', 'summary': 'Semiparametric statistics play a pivotal role in a wide range of domains,\\nincluding but not limited to missing data, causal inference, and transfer\\nlearning, to name a few. In many settings, semiparametric theory leads to\\n(nearly) statistically optimal procedures that yet involve numerically solving\\nFredholm integral equations of the second kind. Traditional numerical methods,\\nsuch as polynomial or spline approximations, are difficult to scale to\\nmulti-dimensional problems. Alternatively, statisticians may choose to\\napproximate the original integral equations by ones with closed-form solutions,\\nresulting in computationally more efficient, but statistically suboptimal or\\neven incorrect procedures. To bridge this gap, we propose a novel framework by\\nformulating the semiparametric estimation problem as a bi-level optimization\\nproblem; and then we develop a scalable algorithm called Deep Neural-Nets\\nAssisted Semiparametric Estimation (DNA-SE) by leveraging the universal\\napproximation property of Deep Neural-Nets (DNN) to streamline semiparametric\\nprocedures. Through extensive numerical experiments and a real data analysis,\\nwe demonstrate the numerical and statistical advantages of $\\\\dnase$ over\\ntraditional methods. To the best of our knowledge, we are the first to bring\\nDNN into semiparametric statistics as a numerical solver of integral equations\\nin our proposed general framework.', 'post': '', 'evaluation': ''}, {'title': 'Robustness of Watermarking on Text-to-Image Diffusion Models', 'summary': \"Watermarking has become one of promising techniques to not only aid in\\nidentifying AI-generated images but also serve as a deterrent against the\\nunethical use of these models. However, the robustness of watermarking\\ntechniques has not been extensively studied recently. In this paper, we\\ninvestigate the robustness of generative watermarking, which is created from\\nthe integration of watermarking embedding and text-to-image generation\\nprocessing in generative models, e.g., latent diffusion models. Specifically,\\nwe propose three attacking methods, i.e., discriminator-based attacks, edge\\nprediction-based attacks, and fine-tune-based attacks, under the scenario where\\nthe watermark decoder is not accessible. The model is allowed to be fine-tuned\\nto created AI agents with specific generative tasks for personalizing or\\nspecializing. We found that generative watermarking methods are robust to\\ndirect evasion attacks, like discriminator-based attacks, or manipulation based\\non the edge information in edge prediction-based attacks but vulnerable to\\nmalicious fine-tuning. Experimental results show that our fine-tune-based\\nattacks can decrease the accuracy of the watermark detection to nearly\\n$67.92\\\\%$. In addition, We conduct an ablation study on the length of\\nfine-tuned messages, encoder/decoder's depth and structure to identify key\\nfactors that impact the performance of fine-tune-based attacks.\", 'post': '', 'evaluation': ''}, {'title': 'The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations', 'summary': \"Calls to use open generative language models in academic research have\\nhighlighted the need for reproducibility and transparency in scientific\\nresearch. However, the impact of generative AI extends well beyond academia, as\\ncorporations and public interest organizations have begun integrating these\\nmodels into their data science pipelines. We expand this lens to include the\\nimpact of open models on organizations, focusing specifically on fact-checking\\norganizations, which use AI to observe and analyze large volumes of circulating\\nmisinformation, yet must also ensure the reproducibility and impartiality of\\ntheir work. We wanted to understand where fact-checking organizations use open\\nmodels in their data science pipelines; what motivates their use of open models\\nor proprietary models; and how their use of open or proprietary models can\\ninform research on the societal impact of generative AI. To answer these\\nquestions, we conducted an interview study with N=24 professionals at 20\\nfact-checking organizations on six continents. Based on these interviews, we\\noffer a five-component conceptual model of where fact-checking organizations\\nemploy generative AI to support or automate parts of their data science\\npipeline, including Data Ingestion, Data Analysis, Data Retrieval, Data\\nDelivery, and Data Sharing. We then provide taxonomies of fact-checking\\norganizations' motivations for using open models and the limitations that\\nprevent them for further adopting open models, finding that they prefer open\\nmodels for Organizational Autonomy, Data Privacy and Ownership, Application\\nSpecificity, and Capability Transparency. However, they nonetheless use\\nproprietary models due to perceived advantages in Performance, Usability, and\\nSafety, as well as Opportunity Costs related to participation in emerging\\ngenerative AI ecosystems. Our work provides novel perspective on open models in\\ndata-driven organizations.\", 'post': '', 'evaluation': ''}, {'title': 'Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study', 'summary': \"Popular and news media often portray teenagers with sensationalism, as both a\\nrisk to society and at risk from society. As AI begins to absorb some of the\\nepistemic functions of traditional media, we study how teenagers in two\\ncountries speaking two languages: 1) are depicted by AI, and 2) how they would\\nprefer to be depicted. Specifically, we study the biases about teenagers\\nlearned by static word embeddings (SWEs) and generative language models (GLMs),\\ncomparing these with the perspectives of adolescents living in the U.S. and\\nNepal. We find English-language SWEs associate teenagers with societal\\nproblems, and more than 50% of the 1,000 words most associated with teenagers\\nin the pretrained GloVe SWE reflect such problems. Given prompts about\\nteenagers, 30% of outputs from GPT2-XL and 29% from LLaMA-2-7B GLMs discuss\\nsocietal problems, most commonly violence, but also drug use, mental illness,\\nand sexual taboo. Nepali models, while not free of such associations, are less\\ndominated by social problems. Data from workshops with N=13 U.S. adolescents\\nand N=18 Nepalese adolescents show that AI presentations are disconnected from\\nteenage life, which revolves around activities like school and friendship.\\nParticipant ratings of how well 20 trait words describe teens are decorrelated\\nfrom SWE associations, with Pearson's r=.02, n.s. in English FastText and\\nr=.06, n.s. in GloVe; and r=.06, n.s. in Nepali FastText and r=-.23, n.s. in\\nGloVe. U.S. participants suggested AI could fairly present teens by\\nhighlighting diversity, while Nepalese participants centered positivity.\\nParticipants were optimistic that, if it learned from adolescents, rather than\\nmedia sources, AI could help mitigate stereotypes. Our work offers an\\nunderstanding of the ways SWEs and GLMs misrepresent a developmentally\\nvulnerable group and provides a template for less sensationalized\\ncharacterization.\", 'post': '', 'evaluation': ''}, {'title': 'Dataset Scale and Societal Consistency Mediate Facial Impression Bias in Vision-Language AI', 'summary': 'Multimodal AI models capable of associating images and text hold promise for\\nnumerous domains, ranging from automated image captioning to accessibility\\napplications for blind and low-vision users. However, uncertainty about bias\\nhas in some cases limited their adoption and availability. In the present work,\\nwe study 43 CLIP vision-language models to determine whether they learn\\nhuman-like facial impression biases, and we find evidence that such biases are\\nreflected across three distinct CLIP model families. We show for the first time\\nthat the the degree to which a bias is shared across a society predicts the\\ndegree to which it is reflected in a CLIP model. Human-like impressions of\\nvisually unobservable attributes, like trustworthiness and sexuality, emerge\\nonly in models trained on the largest dataset, indicating that a better fit to\\nuncurated cultural data results in the reproduction of increasingly subtle\\nsocial biases. Moreover, we use a hierarchical clustering approach to show that\\ndataset size predicts the extent to which the underlying structure of facial\\nimpression bias resembles that of facial impression bias in humans. Finally, we\\nshow that Stable Diffusion models employing CLIP as a text encoder learn facial\\nimpression biases, and that these biases intersect with racial biases in Stable\\nDiffusion XL-Turbo. While pretrained CLIP models may prove useful for\\nscientific studies of bias, they will also require significant dataset curation\\nwhen intended for use as general-purpose models in a zero-shot setting.', 'post': '', 'evaluation': ''}, {'title': 'The Artificial Intelligence Disclosure (AID) Framework: An Introduction', 'summary': 'As the use of Generative Artificial Intelligence tools have grown in higher\\neducation and research, there have been increasing calls for transparency and\\ngranularity around the use and attribution of the use of these tools. Thus far,\\nthis need has been met via the recommended inclusion of a note, with little to\\nno guidance on what the note itself should include. This has been identified as\\na problem to the use of AI in academic and research contexts. This article\\nintroduces The Artificial Intelligence Disclosure (AID) Framework, a standard,\\ncomprehensive, and detailed framework meant to inform the development and\\nwriting of GenAI disclosure for education and research.', 'post': '', 'evaluation': ''}, {'title': 'Quantifying gendered citation imbalance in computer science conferences', 'summary': \"The number of citations received by papers often exhibits imbalances in terms\\nof author attributes such as country of affiliation and gender. While recent\\nstudies have quantified citation imbalance in terms of the authors' gender in\\njournal papers, the computer science discipline, where researchers frequently\\npresent their work at conferences, may exhibit unique patterns in gendered\\ncitation imbalance. Additionally, understanding how network properties in\\ncitations influence citation imbalances remains challenging due to a lack of\\nsuitable reference models. In this paper, we develop a family of reference\\nmodels for citation networks and investigate gender imbalance in citations\\nbetween papers published in computer science conferences. By deploying these\\nreference models, we found that homophily in citations is strongly associated\\nwith gendered citation imbalance in computer science, whereas heterogeneity in\\nthe number of citations received per paper has a relatively minor association\\nwith it. Furthermore, we found that the gendered citation imbalance is most\\npronounced in papers published in the highest-ranked conferences, is present\\nacross different subfields, and extends to citation-based rankings of papers.\\nOur study provides a framework for investigating associations between network\\nproperties and citation imbalances, aiming to enhance our understanding of the\\nstructure and dynamics of citations between research publications.\", 'post': '', 'evaluation': ''}, {'title': 'BEVPlace++: Fast, Robust, and Lightweight LiDAR Global Localization for Unmanned Ground Vehicles', 'summary': \"This article introduces BEVPlace++, a novel, fast, and robust LiDAR global\\nlocalization method for unmanned ground vehicles. It uses lightweight\\nconvolutional neural networks (CNNs) on Bird's Eye View (BEV) image-like\\nrepresentations of LiDAR data to achieve accurate global localization through\\nplace recognition followed by 3-DoF pose estimation. Our detailed analyses\\nreveal an interesting fact that CNNs are inherently effective at extracting\\ndistinctive features from LiDAR BEV images. Remarkably, keypoints of two BEV\\nimages with large translations can be effectively matched using CNN-extracted\\nfeatures. Building on this insight, we design a rotation equivariant module\\n(REM) to obtain distinctive features while enhancing robustness to rotational\\nchanges. A Rotation Equivariant and Invariant Network (REIN) is then developed\\nby cascading REM and a descriptor generator, NetVLAD, to sequentially generate\\nrotation equivariant local features and rotation invariant global descriptors.\\nThe global descriptors are used first to achieve robust place recognition, and\\nthe local features are used for accurate pose estimation. Experimental results\\non multiple public datasets demonstrate that BEVPlace++, even when trained on a\\nsmall dataset (3000 frames of KITTI) only with place labels, generalizes well\\nto unseen environments, performs consistently across different days and years,\\nand adapts to various types of LiDAR scanners. BEVPlace++ achieves\\nstate-of-the-art performance in subtasks of global localization including place\\nrecognition, loop closure detection, and global localization. Additionally,\\nBEVPlace++ is lightweight, runs in real-time, and does not require accurate\\npose supervision, making it highly convenient for deployment. The source codes\\nare publicly available at\\n\\\\href{https://github.com/zjuluolun/BEVPlace}{https://github.com/zjuluolun/BEVPlace}.\", 'post': '', 'evaluation': ''}, {'title': 'MiniCPM-V: A GPT-4V Level MLLM on Your Phone', 'summary': 'The recent surge of Multimodal Large Language Models (MLLMs) has\\nfundamentally reshaped the landscape of AI research and industry, shedding\\nlight on a promising path toward the next AI milestone. However, significant\\nchallenges remain preventing MLLMs from being practical in real-world\\napplications. The most notable challenge comes from the huge cost of running an\\nMLLM with a massive number of parameters and extensive computation. As a\\nresult, most MLLMs need to be deployed on high-performing cloud servers, which\\ngreatly limits their application scopes such as mobile, offline,\\nenergy-sensitive, and privacy-protective scenarios. In this work, we present\\nMiniCPM-V, a series of efficient MLLMs deployable on end-side devices. By\\nintegrating the latest MLLM techniques in architecture, pretraining and\\nalignment, the latest MiniCPM-Llama3-V 2.5 has several notable features: (1)\\nStrong performance, outperforming GPT-4V-1106, Gemini Pro and Claude 3 on\\nOpenCompass, a comprehensive evaluation over 11 popular benchmarks, (2) strong\\nOCR capability and 1.8M pixel high-resolution image perception at any aspect\\nratio, (3) trustworthy behavior with low hallucination rates, (4) multilingual\\nsupport for 30+ languages, and (5) efficient deployment on mobile phones. More\\nimportantly, MiniCPM-V can be viewed as a representative example of a promising\\ntrend: The model sizes for achieving usable (e.g., GPT-4V) level performance\\nare rapidly decreasing, along with the fast growth of end-side computation\\ncapacity. This jointly shows that GPT-4V level MLLMs deployed on end devices\\nare becoming increasingly possible, unlocking a wider spectrum of real-world AI\\napplications in the near future.', 'post': '', 'evaluation': ''}, {'title': 'MathLearner: A Large Language Model Agent Framework for Learning to Solve Mathematical Problems', 'summary': 'With the development of artificial intelligence (AI), large language models\\n(LLM) are widely used in many fields. However, the reasoning ability of LLM is\\nstill very limited when it comes to mathematical reasoning. Mathematics plays\\nan important role in all aspects of human society and is a technical guarantee\\nin the fields of healthcare, transport and aerospace, for this reason, the\\ndevelopment of AI big language models in the field of mathematics has great\\npotential significance. To improve the mathematical reasoning ability of large\\nlanguage models, we proposed an agent framework for learning to solve\\nmathematical problems based on inductive reasoning. By emulating the human\\nlearning process of generalization of learned information and effective\\napplication of previous knowledge in new reasoning tasks, this framework has\\ngreat performance in the mathematical reasoning process. It improves global\\naccuracy over the baseline method (chain-of-thought) by 20.96% and solves\\n17.54% of the mathematical problems that the baseline cannot solve. Benefiting\\nfrom the efficient RETRIEVAL method, our model improves the ability of large\\nlanguage models to efficiently use external knowledge, i.e., the mathematical\\ncomputation of the model can be based on written procedures. In education, our\\nmodel can be used as a personalised learning aid, thus reducing the inequality\\nof educational resources.', 'post': '', 'evaluation': ''}, {'title': 'Building Living Software Systems with Generative & Agentic AI', 'summary': 'This paper is an opinion paper that looks at the future of computing in the\\nage of Generative \\\\& Agentic AI. Current software systems are static and\\ninflexible, leading to significant challenges in translating human goals into\\ncomputational actions. \"Living software systems\" powered by generative AI offer\\na solution to this fundamental problem in computing. Traditional software\\ndevelopment involves multiple layers of imperfect translation, from business\\nrequirements to code, resulting in rigid systems that struggle to adapt to\\nchanging user needs and contexts. Generative AI, particularly large language\\nmodels, can serve as a universal translator between human intent and computer\\noperations. This approach enables the creation of more flexible, context-aware\\nsystems that can dynamically evolve to meet user goals. Two pathways for\\nimplementing living software systems are explored: using generative AI to\\naccelerate traditional software development, and leveraging agentic AI to\\ncreate truly adaptive systems. New skills like Prompt Engineering are\\nnecessary. By reimagining software as a living, adaptable entity, we can create\\ncomputing interfaces that are more intuitive, powerful, and responsive to human\\nneeds.', 'post': '', 'evaluation': ''}, {'title': 'Advancing Green AI: Efficient and Accurate Lightweight CNNs for Rice Leaf Disease Identification', 'summary': \"Rice plays a vital role as a primary food source for over half of the world's\\npopulation, and its production is critical for global food security.\\nNevertheless, rice cultivation is frequently affected by various diseases that\\ncan severely decrease yield and quality. Therefore, early and accurate\\ndetection of rice diseases is necessary to prevent their spread and minimize\\ncrop losses. In this research, we explore three mobile-compatible CNN\\narchitectures, namely ShuffleNet, MobileNetV2, and EfficientNet-B0, for rice\\nleaf disease classification. These models are selected due to their\\ncompatibility with mobile devices, as they demand less computational power and\\nmemory compared to other CNN models. To enhance the performance of the three\\nmodels, we added two fully connected layers separated by a dropout layer. We\\nused early stop creation to prevent the model from being overfiting. The\\nresults of the study showed that the best performance was achieved by the\\nEfficientNet-B0 model with an accuracy of 99.8%. Meanwhile, MobileNetV2 and\\nShuffleNet only achieved accuracies of 84.21% and 66.51%, respectively. This\\nstudy shows that EfficientNet-B0 when combined with the proposed layer and\\nearly stop, can produce a high-accuracy model.\\n  Keywords: rice leaf detection; green AI; smart agriculture; EfficientNet;\", 'post': '', 'evaluation': ''}, {'title': 'The Drama Machine: Simulating Character Development with LLM Agents', 'summary': \"This paper explores use of multiple large language model (LLM) agents to\\nsimulate complex, dynamic characters in dramatic scenarios. We introduce a\\n`drama machine' framework that coordinates interactions between LLM agents\\nplaying different `Ego' and `Superego' psychological roles. In roleplay\\nsimulations, this design allows intersubjective dialogue and intra-subjective\\ninternal monologue to develop in parallel. We apply this framework to two\\ndramatic scenarios - an interview and a detective story - and compare character\\ndevelopment with and without the Superego's influence. Though exploratory,\\nresults suggest this multi-agent approach can produce more nuanced, adaptive\\nnarratives that evolve over a sequence of dialogical turns. We discuss\\ndifferent modalities of LLM-based roleplay and character development, along\\nwith what this might mean for conceptualization of AI subjectivity. The paper\\nconcludes by considering how this approach opens possibilities for thinking of\\nthe roles of internal conflict and social performativity in AI-based\\nsimulation.\", 'post': '', 'evaluation': ''}, {'title': 'Voices from the Frontier: A Comprehensive Analysis of the OpenAI Developer Forum', 'summary': \"OpenAI's advanced large language models (LLMs) have revolutionized natural\\nlanguage processing and enabled developers to create innovative applications.\\nAs adoption grows, understanding the experiences and challenges of developers\\nworking with these technologies is crucial. This paper presents a comprehensive\\nanalysis of the OpenAI Developer Forum, focusing on (1) popularity trends and\\nuser engagement patterns, and (2) a taxonomy of challenges and concerns faced\\nby developers. We first employ a quantitative analysis of the metadata from\\n29,576 forum topics, investigating temporal trends in topic creation, the\\npopularity of topics across different categories, and user contributions at\\nvarious trust levels. We then qualitatively analyze content from 9,301 recently\\nactive topics on developer concerns. From a sample of 886 topics, we construct\\na taxonomy of concerns in the OpenAI Developer Forum. Our findings uncover\\ncritical concerns raised by developers in creating AI-powered applications and\\noffer targeted recommendations to address them. This work not only advances\\nAI-assisted software engineering but also empowers developer communities to\\nshape the responsible evolution and integration of AI technology in society.\", 'post': '', 'evaluation': ''}, {'title': 'Music2P: A Multi-Modal AI-Driven Tool for Simplifying Album Cover Design', 'summary': \"In today's music industry, album cover design is as crucial as the music\\nitself, reflecting the artist's vision and brand. However, many AI-driven album\\ncover services require subscriptions or technical expertise, limiting\\naccessibility. To address these challenges, we developed Music2P, an\\nopen-source, multi-modal AI-driven tool that streamlines album cover creation,\\nmaking it efficient, accessible, and cost-effective through Ngrok. Music2P\\nautomates the design process using techniques such as Bootstrapping Language\\nImage Pre-training (BLIP), music-to-text conversion (LP-music-caps), image\\nsegmentation (LoRA), and album cover and QR code generation (ControlNet). This\\npaper demonstrates the Music2P interface, details our application of these\\ntechnologies, and outlines future improvements. Our ultimate goal is to provide\\na tool that empowers musicians and producers, especially those with limited\\nresources or expertise, to create compelling album covers.\", 'post': '', 'evaluation': ''}, {'title': 'Search for $X(3872)\\\\toπ^0π^0χ_{c1,2}$', 'summary': 'Using 10.1 fb$^{-1}$ of $e^+e^-$ collision data collected by the BESIII\\ndetector with center-of-mass energies between 4.15 GeV and 4.30 GeV, we search\\nfor the decays $X(3872)\\\\to\\\\pi^0\\\\pi^0\\\\chi_{c1,2}$, where the $X(3872)$ is\\nproduced in $e^+e^-\\\\to\\\\gamma X(3872)$. No evidence above $3\\\\sigma$ is found for\\neither decay. Upper limits at the $90\\\\%$ C.L. on the branching fractions of\\n$X(3872)\\\\to\\\\pi^0\\\\pi^0\\\\chi_{c1,2}$ normalized to the branching fraction of\\n$X(3872)\\\\to\\\\pi^+\\\\pi^-J/\\\\psi$ are set to be\\n$\\\\mathcal{B}(X(3872)\\\\to\\\\pi^0\\\\pi^0\\\\chi_{c1})/\\\\mathcal{B}(X(3872)\\\\to\\\\pi^+\\\\pi^-J/\\\\psi)\\n< 1.1$ and\\n$\\\\mathcal{B}(X(3872)\\\\to\\\\pi^0\\\\pi^0\\\\chi_{c2})/\\\\mathcal{B}(X(3872)\\\\to\\\\pi^+\\\\pi^-J/\\\\psi)\\n< 0.5$, taking into account both statistical and systematic uncertainties.', 'post': '', 'evaluation': ''}, {'title': '\"I don\\'t see myself represented here at all\": User Experiences of Stable Diffusion Outputs Containing Representational Harms across Gender Identities and Nationalities', 'summary': \"Though research into text-to-image generators (T2Is) such as Stable Diffusion\\nhas demonstrated their amplification of societal biases and potentials to cause\\nharm, such research has primarily relied on computational methods instead of\\nseeking information from real users who experience harm, which is a significant\\nknowledge gap. In this paper, we conduct the largest human subjects study of\\nStable Diffusion, with a combination of crowdsourced data from 133 crowdworkers\\nand 14 semi-structured interviews across diverse countries and genders. Through\\na mixed-methods approach of intra-set cosine similarity hierarchies (i.e.,\\ncomparing multiple Stable Diffusion outputs for the same prompt with each other\\nto examine which result is 'closest' to the prompt) and qualitative thematic\\nanalysis, we first demonstrate a large disconnect between user expectations for\\nStable Diffusion outputs with those generated, evidenced by a set of Stable\\nDiffusion renditions of `a Person' providing images far away from such\\nexpectations. We then extend this finding of general dissatisfaction into\\nhighlighting representational harms caused by Stable Diffusion upon our\\nsubjects, especially those with traditionally marginalized identities,\\nsubjecting them to incorrect and often dehumanizing stereotypes about their\\nidentities. We provide recommendations for a harm-aware approach to (re)design\\nfuture versions of Stable Diffusion and other T2Is.\", 'post': '', 'evaluation': ''}, {'title': 'Interpretations, Representations, and Stereotypes of Caste within Text-to-Image Generators', 'summary': \"The surge in the popularity of text-to-image generators (T2Is) has been\\nmatched by extensive research into ensuring fairness and equitable outcomes,\\nwith a focus on how they impact society. However, such work has typically\\nfocused on globally-experienced identities or centered Western contexts. In\\nthis paper, we address interpretations, representations, and stereotypes\\nsurrounding a tragically underexplored context in T2I research: caste. We\\nexamine how the T2I Stable Diffusion displays people of various castes, and\\nwhat professions they are depicted as performing. Generating 100 images per\\nprompt, we perform CLIP-cosine similarity comparisons with default depictions\\nof an 'Indian person' by Stable Diffusion, and explore patterns of similarity.\\nOur findings reveal how Stable Diffusion outputs perpetuate systems of\\n'castelessness', equating Indianness with high-castes and depicting\\ncaste-oppressed identities with markers of poverty. In particular, we note the\\nstereotyping and representational harm towards the historically-marginalized\\nDalits, prominently depicted as living in rural areas and always at protests.\\nOur findings underscore a need for a caste-aware approach towards T2I design,\\nand we conclude with design recommendations.\", 'post': '', 'evaluation': ''}, {'title': 'Telecom Foundation Models: Applications, Challenges, and Future Trends', 'summary': 'Telecom networks are becoming increasingly complex, with diversified\\ndeployment scenarios, multi-standards, and multi-vendor support. The intricate\\nnature of the telecom network ecosystem presents challenges to effectively\\nmanage, operate, and optimize networks. To address these hurdles, Artificial\\nIntelligence (AI) has been widely adopted to solve different tasks in telecom\\nnetworks. However, these conventional AI models are often designed for specific\\ntasks, rely on extensive and costly-to-collect labeled data that require\\nspecialized telecom expertise for development and maintenance. The AI models\\nusually fail to generalize and support diverse deployment scenarios and\\napplications. In contrast, Foundation Models (FMs) show effective\\ngeneralization capabilities in various domains in language, vision, and\\ndecision-making tasks. FMs can be trained on multiple data modalities generated\\nfrom the telecom ecosystem and leverage specialized domain knowledge. Moreover,\\nFMs can be fine-tuned to solve numerous specialized tasks with minimal\\ntask-specific labeled data and, in some instances, are able to leverage context\\nto solve previously unseen problems. At the dawn of 6G, this paper investigates\\nthe potential opportunities of using FMs to shape the future of telecom\\ntechnologies and standards. In particular, the paper outlines a conceptual\\nprocess for developing Telecom FMs (TFMs) and discusses emerging opportunities\\nfor orchestrating specialized TFMs for network configuration, operation, and\\nmaintenance. Finally, the paper discusses the limitations and challenges of\\ndeveloping and deploying TFMs.', 'post': '', 'evaluation': ''}, {'title': 'pathfinder: A Semantic Framework for Literature Review and Knowledge Discovery in Astronomy', 'summary': \"The exponential growth of astronomical literature poses significant\\nchallenges for researchers navigating and synthesizing general insights or even\\ndomain-specific knowledge. We present Pathfinder, a machine learning framework\\ndesigned to enable literature review and knowledge discovery in astronomy,\\nfocusing on semantic searching with natural language instead of syntactic\\nsearches with keywords. Utilizing state-of-the-art large language models (LLMs)\\nand a corpus of 350,000 peer-reviewed papers from the Astrophysics Data System\\n(ADS), Pathfinder offers an innovative approach to scientific inquiry and\\nliterature exploration. Our framework couples advanced retrieval techniques\\nwith LLM-based synthesis to search astronomical literature by semantic context\\nas a complement to currently existing methods that use keywords or citation\\ngraphs. It addresses complexities of jargon, named entities, and temporal\\naspects through time-based and citation-based weighting schemes. We demonstrate\\nthe tool's versatility through case studies, showcasing its application in\\nvarious research scenarios. The system's performance is evaluated using custom\\nbenchmarks, including single-paper and multi-paper tasks. Beyond literature\\nreview, Pathfinder offers unique capabilities for reformatting answers in ways\\nthat are accessible to various audiences (e.g. in a different language or as\\nsimplified text), visualizing research landscapes, and tracking the impact of\\nobservatories and methodologies. This tool represents a significant advancement\\nin applying AI to astronomical research, aiding researchers at all career\\nstages in navigating modern astronomy literature.\", 'post': '', 'evaluation': ''}, {'title': 'PiCoGen2: Piano cover generation with transfer learning approach and weakly aligned data', 'summary': 'Piano cover generation aims to create a piano cover from a pop song. Existing\\napproaches mainly employ supervised learning and the training demands\\nstrongly-aligned and paired song-to-piano data, which is built by remapping\\npiano notes to song audio. This would, however, result in the loss of piano\\ninformation and accordingly cause inconsistencies between the original and\\nremapped piano versions. To overcome this limitation, we propose a transfer\\nlearning approach that pre-trains our model on piano-only data and fine-tunes\\nit on weakly-aligned paired data constructed without note remapping. During\\npre-training, to guide the model to learn piano composition concepts instead of\\nmerely transcribing audio, we use an existing lead sheet transcription model as\\nthe encoder to extract high-level features from the piano recordings. The\\npre-trained model is then fine-tuned on the paired song-piano data to transfer\\nthe learned composition knowledge to the pop song domain. Our evaluation shows\\nthat this training strategy enables our model, named PiCoGen2, to attain\\nhigh-quality results, outperforming baselines on both objective and subjective\\nmetrics across five pop genres.', 'post': '', 'evaluation': ''}, {'title': 'Can multivariate Granger causality detect directed connectivity of a multistable and dynamic biological decision network model?', 'summary': \"Extracting causal connections can advance interpretable AI and machine\\nlearning. Granger causality (GC) is a robust statistical method for estimating\\ndirected influences (DC) between signals. While GC has been widely applied to\\nanalysing neuronal signals in biological neural networks and other domains, its\\napplication to complex, nonlinear, and multistable neural networks is less\\nexplored. In this study, we applied time-domain multi-variate Granger causality\\n(MVGC) to the time series neural activity of all nodes in a trained multistable\\nbiologically based decision neural network model with real-time decision\\nuncertainty monitoring. Our analysis demonstrated that challenging two-choice\\ndecisions, where input signals could be closely matched, and the appropriate\\napplication of fine-grained sliding time windows, could readily reveal the\\noriginal model's DC. Furthermore, the identified DC varied based on whether the\\nnetwork had correct or error decisions. Integrating the identified DC from\\ndifferent decision outcomes recovered most of the original model's\\narchitecture, despite some spurious and missing connectivity. This approach\\ncould be used as an initial exploration to enhance the interpretability and\\ntransparency of dynamic multistable and nonlinear biological or AI systems by\\nrevealing causal connections throughout different phases of neural network\\ndynamics and outcomes.\", 'post': '', 'evaluation': ''}, {'title': 'Reconstructing and Forecasting Marine Dynamic Variable Fields across Space and Time Globally and Gaplessly', 'summary': \"Spatiotemporal projections in marine science are essential for understanding\\nocean systems and their impact on Earth's climate. However, existing AI-based\\nand statistics-based inversion methods face challenges in leveraging ocean\\ndata, generating continuous outputs, and incorporating physical constraints. We\\npropose the Marine Dynamic Reconstruction and Forecast Neural Networks\\n(MDRF-Net), which integrates marine physical mechanisms and observed data to\\nreconstruct and forecast continuous ocean temperature-salinity and dynamic\\nfields. MDRF-Net leverages statistical theories and techniques, incorporating\\nparallel neural network sharing initial layer, two-step training strategy, and\\nensemble methodology, facilitating in exploring challenging marine areas like\\nthe Arctic zone. We have theoretically justified the efficacy of our ensemble\\nmethod and the rationality of it by providing an upper bound on its\\ngeneralization error.The effectiveness of MDRF-Net's is validated through a\\ncomprehensive simulation study, which highlights its capability to reliably\\nestimate unknown parameters. Comparison with other inversion methods and\\nreanalysis data are also conducted, and the global test error is 0.455{\\\\deg}C\\nfor temperature and 0.0714psu for salinity. Overall, MDRF-Net effectively\\nlearns the ocean dynamics system using physical mechanisms and statistical\\ninsights, contributing to a deeper understanding of marine systems and their\\nimpact on the environment and human use of the ocean.\", 'post': '', 'evaluation': ''}, {'title': 'Derivation of Back-propagation for Graph Convolutional Networks using Matrix Calculus and its Application to Explainable Artificial Intelligence', 'summary': \"This paper provides a comprehensive and detailed derivation of the\\nbackpropagation algorithm for graph convolutional neural networks using matrix\\ncalculus. The derivation is extended to include arbitrary element-wise\\nactivation functions and an arbitrary number of layers. The study addresses two\\nfundamental problems, namely node classification and link prediction. To\\nvalidate our method, we compare it with reverse-mode automatic differentiation.\\nThe experimental results demonstrate that the median sum of squared errors of\\nthe updated weight matrices, when comparing our method to the approach using\\nreverse-mode automatic differentiation, falls within the range of $10^{-18}$ to\\n$10^{-14}$. These outcomes are obtained from conducting experiments on a\\nfive-layer graph convolutional network, applied to a node classification\\nproblem on Zachary's karate club social network and a link prediction problem\\non a drug-drug interaction network. Finally, we show how the derived\\nclosed-form solution can facilitate the development of explainable AI and\\nsensitivity analysis.\", 'post': '', 'evaluation': ''}, {'title': 'Coalitions of Large Language Models Increase the Robustness of AI Agents', 'summary': 'The emergence of Large Language Models (LLMs) have fundamentally altered the\\nway we interact with digital systems and have led to the pursuit of LLM powered\\nAI agents to assist in daily workflows. LLMs, whilst powerful and capable of\\ndemonstrating some emergent properties, are not logical reasoners and often\\nstruggle to perform well at all sub-tasks carried out by an AI agent to plan\\nand execute a workflow. While existing studies tackle this lack of proficiency\\nby generalised pretraining at a huge scale or by specialised fine-tuning for\\ntool use, we assess if a system comprising of a coalition of pretrained LLMs,\\neach exhibiting specialised performance at individual sub-tasks, can match the\\nperformance of single model agents. The coalition of models approach showcases\\nits potential for building robustness and reducing the operational costs of\\nthese AI agents by leveraging traits exhibited by specific models. Our findings\\ndemonstrate that fine-tuning can be mitigated by considering a coalition of\\npretrained models and believe that this approach can be applied to other\\nnon-agentic systems which utilise LLMs.', 'post': '', 'evaluation': ''}, {'title': 'Adaptive Recruitment Resource Allocation to Improve Cohort Representativeness in Participatory Biomedical Datasets', 'summary': 'Large participatory biomedical studies, studies that recruit individuals to\\njoin a dataset, are gaining popularity and investment, especially for analysis\\nby modern AI methods. Because they purposively recruit participants, these\\nstudies are uniquely able to address a lack of historical representation, an\\nissue that has affected many biomedical datasets. In this work, we define\\nrepresentativeness as the similarity to a target population distribution of a\\nset of attributes and our goal is to mirror the U.S. population across\\ndistributions of age, gender, race, and ethnicity. Many participatory studies\\nrecruit at several institutions, so we introduce a computational approach to\\nadaptively allocate recruitment resources among sites to improve\\nrepresentativeness. In simulated recruitment of 10,000-participant cohorts from\\nmedical centers in the STAR Clinical Research Network, we show that our\\napproach yields a more representative cohort than existing baselines. Thus, we\\nhighlight the value of computational modeling in guiding recruitment efforts.', 'post': '', 'evaluation': ''}, {'title': 'Prompt Refinement or Fine-tuning? Best Practices for using LLMs in Computational Social Science Tasks', 'summary': 'Large Language Models are expressive tools that enable complex tasks of text\\nunderstanding within Computational Social Science. Their versatility, while\\nbeneficial, poses a barrier for establishing standardized best practices within\\nthe field. To bring clarity on the values of different strategies, we present\\nan overview of the performance of modern LLM-based classification methods on a\\nbenchmark of 23 social knowledge tasks. Our results point to three best\\npractices: select models with larger vocabulary and pre-training corpora; avoid\\nsimple zero-shot in favor of AI-enhanced prompting; fine-tune on task-specific\\ndata, and consider more complex forms instruction-tuning on multiple datasets\\nonly when only training data is more abundant.', 'post': '', 'evaluation': ''}, {'title': 'A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks', 'summary': 'In an era defined by the explosive growth of data and rapid technological\\nadvancements, Multimodal Large Language Models (MLLMs) stand at the forefront\\nof artificial intelligence (AI) systems. Designed to seamlessly integrate\\ndiverse data types-including text, images, videos, audio, and physiological\\nsequences-MLLMs address the complexities of real-world applications far beyond\\nthe capabilities of single-modality systems. In this paper, we systematically\\nsort out the applications of MLLM in multimodal tasks such as natural language,\\nvision, and audio. We also provide a comparative analysis of the focus of\\ndifferent MLLMs in the tasks, and provide insights into the shortcomings of\\ncurrent MLLMs, and suggest potential directions for future research. Through\\nthese discussions, this paper hopes to provide valuable insights for the\\nfurther development and application of MLLM.', 'post': '', 'evaluation': ''}, {'title': 'A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment', 'summary': 'Artificial intelligence (AI) has revolutionized decision-making processes and\\nsystems throughout society and, in particular, has emerged as a significant\\ntechnology in high-impact scenarios of national interest. Yet, despite AI\\'s\\nimpressive predictive capabilities in controlled settings, it still suffers\\nfrom a range of practical setbacks preventing its widespread use in various\\ncritical scenarios. In particular, it is generally unclear if a given AI\\nsystem\\'s predictions can be trusted by decision-makers in downstream\\napplications. To address the need for more transparent, robust, and trustworthy\\nAI systems, a suite of tools has been developed to quantify the uncertainty of\\nAI predictions and, more generally, enable AI to \"self-assess\" the reliability\\nof its predictions. In this manuscript, we categorize methods for AI\\nself-assessment along several key dimensions and provide guidelines for\\nselecting and designing the appropriate method for a practitioner\\'s needs. In\\nparticular, we focus on uncertainty estimation techniques that consider the\\nimpact of self-assessment on the choices made by downstream decision-makers and\\non the resulting costs and benefits of decision outcomes. To demonstrate the\\nutility of our methodology for self-assessment design, we illustrate its use\\nfor two realistic national-interest scenarios. This manuscript is a practical\\nguide for machine learning engineers and AI system users to select the ideal\\nself-assessment techniques for each problem.', 'post': '', 'evaluation': ''}, {'title': 'TrIM: Triangular Input Movement Systolic Array for Convolutional Neural Networks -- Part I: Dataflow and Analytical Modelling', 'summary': 'In order to follow the ever-growing computational complexity and data\\nintensity of state-of-the-art AI models, new computing paradigms are being\\nproposed. These paradigms aim at achieving high energy efficiency, by\\nmitigating the Von Neumann bottleneck that relates to the energy cost of moving\\ndata between the processing cores and the memory. Convolutional Neural Networks\\n(CNNs) are particularly susceptible to this bottleneck, given the massive data\\nthey have to manage. Systolic Arrays (SAs) are promising architectures to\\nmitigate the data transmission cost, thanks to high data utilization carried\\nout by an array of Processing Elements (PEs). These PEs continuously exchange\\nand process data locally based on specific dataflows (like weight stationary\\nand row stationary), in turn reducing the number of memory accesses to the main\\nmemory. The hardware specialization of SAs can meet different workloads,\\nranging from matrix multiplications to multi-dimensional convolutions. In this\\npaper, we propose TrIM: a novel dataflow for SAs based on a Triangular Input\\nMovement and compatible with CNN computing. When compared to state-of-the-art\\nSA dataflows, like weight stationary and row stationary, the high data\\nutilization offered by TrIM guarantees ~10x less memory access. Furthermore,\\nconsidering that PEs continuously overlap multiplications and accumulations,\\nTrIM achieves high throughput (up to 81.8% higher than row stationary), other\\nthan requiring a limited number of registers (up to 15.6x fewer registers than\\nrow stationary).', 'post': '', 'evaluation': ''}, {'title': 'Metareasoning in uncertain environments: a meta-BAMDP framework', 'summary': \"In decision-making scenarios, \\\\textit{reasoning} can be viewed as an\\nalgorithm $P$ that makes a choice of an action $a^* \\\\in \\\\mathcal{A}$, aiming to\\noptimize some outcome such as maximizing the value function of a Markov\\ndecision process (MDP). However, executing $P$ itself may bear some costs\\n(time, energy, limited capacity, etc.) and needs to be considered alongside\\nexplicit utility obtained by making the choice in the underlying decision\\nproblem. Such costs need to be taken into account in order to accurately model\\nhuman behavior, as well as optimizing AI planning, as all physical systems are\\nbound to face resource constraints. Finding the right $P$ can itself be framed\\nas an optimization problem over the space of reasoning processes $P$, generally\\nreferred to as \\\\textit{metareasoning}. Conventionally, human metareasoning\\nmodels assume that the agent knows the transition and reward distributions of\\nthe underlying MDP. This paper generalizes such models by proposing a meta\\nBayes-Adaptive MDP (meta-BAMDP) framework to handle metareasoning in\\nenvironments with unknown reward/transition distributions, which encompasses a\\nfar larger and more realistic set of planning problems that humans and AI\\nsystems face. As a first step, we apply the framework to two-armed Bernoulli\\nbandit (TABB) tasks, which have often been used to study human decision making.\\nOwing to the meta problem's complexity, our solutions are necessarily\\napproximate, but nevertheless robust within a range of assumptions that are\\narguably realistic for human decision-making scenarios. These results offer a\\nnormative framework for understanding human exploration under cognitive\\nconstraints. This integration of Bayesian adaptive strategies with\\nmetareasoning enriches both the theoretical landscape of decision-making\\nresearch and practical applications in designing AI systems that plan under\\nuncertainty and resource constraints.\", 'post': '', 'evaluation': ''}, {'title': 'Sustainable Diffusion-based Incentive Mechanism for Generative AI-driven Digital Twins in Industrial Cyber-Physical Systems', 'summary': 'Industrial Cyber-Physical Systems (ICPSs) are an integral component of modern\\nmanufacturing and industries. By digitizing data throughout the product life\\ncycle, Digital Twins (DTs) in ICPSs enable a shift from current industrial\\ninfrastructures to intelligent and adaptive infrastructures. Thanks to data\\nprocess capability, Generative Artificial Intelligence (GAI) can drive the\\nconstruction and update of DTs to improve predictive accuracy and prepare for\\ndiverse smart manufacturing. However, mechanisms that leverage sensing\\nIndustrial Internet of Things (IIoT) devices to share data for the construction\\nof DTs are susceptible to adverse selection problems. In this paper, we first\\ndevelop a GAI-driven DT architecture for ICPSs. To address the adverse\\nselection problem caused by information asymmetry, we propose a contract theory\\nmodel and develop the sustainable diffusion-based soft actor-critic algorithm\\nto identify the optimal feasible contract. Specifically, we leverage the\\ndynamic structured pruning technique to reduce parameter numbers of actor\\nnetworks, allowing sustainability and efficient implementation of the proposed\\nalgorithm. Finally, numerical results demonstrate the effectiveness of the\\nproposed scheme.', 'post': '', 'evaluation': ''}, {'title': 'Algorithm, Expert, or Both? Evaluating the Role of Feature Selection Methods on User Preferences and Reliance', 'summary': \"The integration of users and experts in machine learning is a widely studied\\ntopic in artificial intelligence literature. Similarly, human-computer\\ninteraction research extensively explores the factors that influence the\\nacceptance of AI as a decision support system. In this experimental study, we\\ninvestigate users' preferences regarding the integration of experts in the\\ndevelopment of such systems and how this affects their reliance on these\\nsystems. Specifically, we focus on the process of feature selection -- an\\nelement that is gaining importance due to the growing demand for transparency\\nin machine learning models. We differentiate between three feature selection\\nmethods: algorithm-based, expert-based, and a combined approach. In the first\\ntreatment, we analyze users' preferences for these methods. In the second\\ntreatment, we randomly assign users to one of the three methods and analyze\\nwhether the method affects advice reliance. Users prefer the combined method,\\nfollowed by the expert-based and algorithm-based methods. However, the users in\\nthe second treatment rely equally on all methods. Thus, we find a remarkable\\ndifference between stated preferences and actual usage. Moreover, allowing the\\nusers to choose their preferred method had no effect, and the preferences and\\nthe extent of reliance were domain-specific. The findings underscore the\\nimportance of understanding cognitive processes in AI-supported decisions and\\nthe need for behavioral experiments in human-AI interactions.\", 'post': '', 'evaluation': ''}, {'title': 'Being Accountable is Smart: Navigating the Technical and Regulatory Landscape of AI-based Services for Power Grid', 'summary': \"The emergence of artificial intelligence and digitization of the power grid\\nintroduced numerous effective application scenarios for AI-based services for\\nthe smart grid. Nevertheless, adopting AI in critical infrastructures presents\\nchallenges due to unclear regulations and lacking risk quantification\\ntechniques. Regulated and accountable approaches for integrating AI-based\\nservices into the smart grid could accelerate the adoption of innovative\\nmethods in daily practices and address society's general safety concerns. This\\npaper contributes to this objective by defining accountability and highlighting\\nits importance for AI-based services in the energy sector. It underlines the\\ncurrent shortcomings of the AI Act and proposes an approach to address these\\nissues in a potential delegated act. The proposed technical approach for\\ndeveloping and operating accountable AI-based smart grid services allows for\\nassessing different service life cycle phases and identifying related\\naccountability risks.\", 'post': '', 'evaluation': ''}, {'title': 'Contribution-based Low-Rank Adaptation with Pre-training Model for Real Image Restoration', 'summary': 'Recently, pre-trained model and efficient parameter tuning have achieved\\nremarkable success in natural language processing and high-level computer\\nvision with the aid of masked modeling and prompt tuning. In low-level computer\\nvision, however, there have been limited investigations on pre-trained models\\nand even efficient fine-tuning strategy has not yet been explored despite its\\nimportance and benefit in various real-world tasks such as alleviating memory\\ninflation issue when integrating new tasks on AI edge devices. Here, we propose\\na novel efficient parameter tuning approach dubbed contribution-based low-rank\\nadaptation (CoLoRA) for multiple image restorations along with effective\\npre-training method with random order degradations (PROD). Unlike prior arts\\nthat tune all network parameters, our CoLoRA effectively fine-tunes small\\namount of parameters by leveraging LoRA (low-rank adaptation) for each new\\nvision task with our contribution-based method to adaptively determine layer by\\nlayer capacity for that task to yield comparable performance to full tuning.\\nFurthermore, our PROD strategy allows to extend the capability of pre-trained\\nmodels with improved performance as well as robustness to bridge synthetic\\npre-training and real-world fine-tuning. Our CoLoRA with PROD has demonstrated\\nits superior performance in various image restoration tasks across diverse\\ndegradation types on both synthetic and real-world datasets for known and novel\\ntasks.', 'post': '', 'evaluation': ''}, {'title': 'The EAP-AIAS: Adapting the AI Assessment Scale for English for Academic Purposes', 'summary': 'The rapid advancement of Generative Artificial Intelligence (GenAI) presents\\nboth opportunities and challenges for English for Academic Purposes (EAP)\\ninstruction. This paper proposes an adaptation of the AI Assessment Scale\\n(AIAS) specifically tailored for EAP contexts, termed the EAP-AIAS.\\n  This framework aims to provide a structured approach for integrating GenAI\\ntools into EAP assessment practices while maintaining academic integrity and\\nsupporting language development. The EAP-AIAS consists of five levels, ranging\\nfrom \"No AI\" to \"Full AI\", each delineating appropriate GenAI usage in EAP\\ntasks. We discuss the rationale behind this adaptation, considering the unique\\nneeds of language learners and the dual focus of EAP on language proficiency\\nand academic acculturation.\\n  This paper explores potential applications of the EAP-AIAS across various EAP\\nassessment types, including writing tasks, presentations, and research\\nprojects. By offering a flexible framework, the EAP-AIAS seeks to empower EAP\\npractitioners seeking to deal with the complexities of GenAI integration in\\neducation and prepare students for an AI-enhanced academic and professional\\nfuture. This adaptation represents a step towards addressing the pressing need\\nfor ethical and pedagogically sound AI integration in language education.', 'post': '', 'evaluation': ''}, {'title': 'Amodal Segmentation for Laparoscopic Surgery Video Instruments', 'summary': 'Segmentation of surgical instruments is crucial for enhancing surgeon\\nperformance and ensuring patient safety. Conventional techniques such as\\nbinary, semantic, and instance segmentation share a common drawback: they do\\nnot accommodate the parts of instruments obscured by tissues or other\\ninstruments. Precisely predicting the full extent of these occluded instruments\\ncan significantly improve laparoscopic surgeries by providing critical guidance\\nduring operations and assisting in the analysis of potential surgical errors,\\nas well as serving educational purposes. In this paper, we introduce Amodal\\nSegmentation to the realm of surgical instruments in the medical field. This\\ntechnique identifies both the visible and occluded parts of an object. To\\nachieve this, we introduce a new Amoal Instruments Segmentation (AIS) dataset,\\nwhich was developed by reannotating each instrument with its complete mask,\\nutilizing the 2017 MICCAI EndoVis Robotic Instrument Segmentation Challenge\\ndataset. Additionally, we evaluate several leading amodal segmentation methods\\nto establish a benchmark for this new dataset.', 'post': '', 'evaluation': ''}, {'title': 'From Stem to Stern: Contestability Along AI Value Chains', 'summary': 'This workshop will grow and consolidate a community of interdisciplinary CSCW\\nresearchers focusing on the topic of contestable AI. As an outcome of the\\nworkshop, we will synthesize the most pressing opportunities and challenges for\\ncontestability along AI value chains in the form of a research roadmap. This\\nroadmap will help shape and inspire imminent work in this field. Considering\\nthe length and depth of AI value chains, it will especially spur discussions\\naround the contestability of AI systems along various sites of such chains. The\\nworkshop will serve as a platform for dialogue and demonstrations of concrete,\\nsuccessful, and unsuccessful examples of AI systems that (could or should) have\\nbeen contested, to identify requirements, obstacles, and opportunities for\\ndesigning and deploying contestable AI in various contexts. This will be held\\nprimarily as an in-person workshop, with some hybrid accommodation. The day\\nwill consist of individual presentations and group activities to stimulate\\nideation and inspire broad reflections on the field of contestable AI. Our aim\\nis to facilitate interdisciplinary dialogue by bringing together researchers,\\npractitioners, and stakeholders to foster the design and deployment of\\ncontestable AI.', 'post': '', 'evaluation': ''}, {'title': 'The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines', 'summary': \"The recent surge of open-source large language models (LLMs) enables\\ndevelopers to create AI-based solutions while maintaining control over aspects\\nsuch as privacy and compliance, thereby providing governance and ownership of\\nthe model deployment process. To utilize these LLMs, inference engines are\\nneeded. These engines load the model's weights onto available resources, such\\nas GPUs, and process queries to generate responses. The speed of inference, or\\nperformance, of the LLM, is critical for real-time applications, as it computes\\nmillions or billions of floating point operations per inference. Recently,\\nadvanced inference engines such as vLLM have emerged, incorporating novel\\nmechanisms such as efficient memory management to achieve state-of-the-art\\nperformance. In this paper, we analyze the performance, particularly the\\nthroughput (tokens generated per unit of time), of 20 LLMs using two inference\\nlibraries: vLLM and HuggingFace's pipelines. We investigate how various\\nhyperparameters, which developers must configure, influence inference\\nperformance. Our results reveal that throughput landscapes are irregular, with\\ndistinct peaks, highlighting the importance of hyperparameter optimization to\\nachieve maximum performance. We also show that applying hyperparameter\\noptimization when upgrading or downgrading the GPU model used for inference can\\nimprove throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,\\nrespectively.\", 'post': '', 'evaluation': ''}, {'title': 'GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular Representation Learning with GNNs', 'summary': 'Effective molecular representation learning is crucial for molecular property\\nprediction and drug design. However, existing approaches struggle with\\nlimitations in insufficient annotations and suboptimal architecture design. For\\ninstance, Graph Neural Networks (GNNs) suffer from over-squashing, causing the\\nloss of important structural details in molecules, thus impairing molecular\\nrepresentations. In this work, we propose a new class of GNNs, GNN-MolKAN and\\nits augmented variant, GNN-MolKAN+, that integrate the Kolmogorov-Arnold\\nNetworks (KAN) architecture from AI + Science into GNNs to address these\\nchallenges. Additionally, we introduce Adaptive FastKAN (AdFastKAN), an\\nadvanced KAN that offers increased stability and speed, further enhancing the\\nperformance of standard GNNs. Notably, our approach holds three key benefits:\\n1) Superior Performance: GNN-MolKAN and GNN-MolKAN+ demonstrate superior\\nprediction ability, robust generalization to unseen scaffolds, and versatile\\ntransferability across different GNN architectures. 2) Efficiency: These models\\nrequire less computational time and fewer parameters while matching or\\nsurpassing the state-of-the-art (SOTA) self-supervised methods. 3) Few-shot\\nLearning Ability: GNN-MolKAN demonstrates great potential in few-shot learning\\nscenarios, achieving an average improvement of 6.97% across few-shot\\nbenchmarks. Overall, we validate our architecture on 6 classification datasets,\\n6 regression datasets, and 4 few-shot learning datasets, consistently achieving\\nhighly competitive results across all of them.', 'post': '', 'evaluation': ''}, {'title': 'Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs', 'summary': 'In recent years, Large Language Models (LLMs) have demonstrated remarkable\\ncapabilities across a wide range of natural language processing (NLP) tasks,\\nsuch as question-answering, sentiment analysis, text summarization, and machine\\ntranslation. However, the ever-growing complexity of LLMs demands immense\\ncomputational resources, hindering the broader research and application of\\nthese models. To address this, various parameter-efficient fine-tuning\\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\\ndeveloped. Despite their potential, these methods often face limitations in\\ncompressibility. Specifically, LoRA struggles to scale effectively with the\\nincreasing number of trainable parameters in modern large scale LLMs.\\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\\nutilizes tensor train decomposition, has not yet achieved the level of\\ncompression necessary for fine-tuning very large scale models with limited\\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\\nwith optimized tensor train (TT) decomposition integration. By eliminating\\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\\ncompression without compromising downstream task performance, along with\\nreduced inference latency and computational overhead. We conduct an exhaustive\\nparameter search to establish benchmarks that highlight the trade-off between\\nmodel compression and performance. Our results demonstrate significant\\ncompression of LLMs while maintaining comparable performance to larger models,\\nfacilitating their deployment on resource-constraint platforms.', 'post': '', 'evaluation': ''}, {'title': 'FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation', 'summary': 'Large-scale text-to-image diffusion models have been a revolutionary\\nmilestone in the evolution of generative AI and multimodal technology, allowing\\nwonderful image generation with natural-language text prompt. However, the\\nissue of lacking controllability of such models restricts their practical\\napplicability for real-life content creation. Thus, attention has been focused\\non leveraging a reference image to control text-to-image synthesis, which is\\nalso regarded as manipulating (or editing) a reference image as per a text\\nprompt, namely, text-driven image-to-image translation. This paper contributes\\na novel, concise, and efficient approach that adapts pre-trained large-scale\\ntext-to-image (T2I) diffusion model to the image-to-image (I2I) paradigm in a\\nplug-and-play manner, realizing high-quality and versatile text-driven I2I\\ntranslation without any model training, model fine-tuning, or online\\noptimization process. To guide T2I generation with a reference image, we\\npropose to decompose diverse guiding factors with different frequency bands of\\ndiffusion features in the DCT spectral space, and accordingly devise a novel\\nfrequency band substitution layer which realizes dynamic control of the\\nreference image to the T2I generation result in a plug-and-play manner. We\\ndemonstrate that our method allows flexible control over both guiding factor\\nand guiding intensity of the reference image simply by tuning the type and\\nbandwidth of the substituted frequency band, respectively. Extensive\\nqualitative and quantitative experiments verify superiority of our approach\\nover related methods in I2I translation visual quality, versatility, and\\ncontrollability. The code is publicly available at:\\nhttps://github.com/XiangGao1102/FBSDiff.', 'post': '', 'evaluation': ''}, {'title': 'A SAT-based approach to rigorous verification of Bayesian networks', 'summary': 'Recent advancements in machine learning have accelerated its widespread\\nadoption across various real-world applications. However, in safety-critical\\ndomains, the deployment of machine learning models is riddled with challenges\\ndue to their complexity, lack of interpretability, and absence of formal\\nguarantees regarding their behavior. In this paper, we introduce a verification\\nframework tailored for Bayesian networks, designed to address these drawbacks.\\nOur framework comprises two key components: (1) a two-step compilation and\\nencoding scheme that translates Bayesian networks into Boolean logic literals,\\nand (2) formal verification queries that leverage these literals to verify\\nvarious properties encoded as constraints. Specifically, we introduce two\\nverification queries: if-then rules (ITR) and feature monotonicity (FMO). We\\nbenchmark the efficiency of our verification scheme and demonstrate its\\npractical utility in real-world scenarios.', 'post': '', 'evaluation': ''}, {'title': 'Extracting Object Heights From LiDAR & Aerial Imagery', 'summary': 'This work shows a procedural method for extracting object heights from LiDAR\\nand aerial imagery. We discuss how to get heights and the future of LiDAR and\\nimagery processing. SOTA object segmentation allows us to take get object\\nheights with no deep learning background. Engineers will be keeping track of\\nworld data across generations and reprocessing them. They will be using older\\nprocedural methods like this paper and newer ones discussed here. SOTA methods\\nare going beyond analysis and into generative AI. We cover both a procedural\\nmethodology and the newer ones performed with language models. These include\\npoint cloud, imagery and text encoding allowing for spatially aware AI.', 'post': '', 'evaluation': ''}, {'title': 'Integrating ESG and AI: A Comprehensive Responsible AI Assessment Framework', 'summary': \"Artificial Intelligence (AI) is a widely developed and adopted technology\\nacross entire industry sectors. Integrating environmental, social, and\\ngovernance (ESG) considerations with AI investments is crucial for ensuring\\nethical and sustainable technological advancement. Particularly from an\\ninvestor perspective, this integration not only mitigates risks but also\\nenhances long-term value creation by aligning AI initiatives with broader\\nsocietal goals. Yet, this area has been less explored in both academia and\\nindustry. To bridge the gap, we introduce a novel ESG-AI framework, which is\\ndeveloped based on insights from engagements with 28 companies and comprises\\nthree key components. The framework provides a structured approach to this\\nintegration, developed in collaboration with industry practitioners. The ESG-AI\\nframework provides an overview of the environmental and social impacts of AI\\napplications, helping users such as investors assess the materiality of AI use.\\nMoreover, it enables investors to evaluate a company's commitment to\\nresponsible AI through structured engagements and thorough assessment of\\nspecific risk areas. We have publicly released the framework and toolkit in\\nApril 2024, which has received significant attention and positive feedback from\\nthe investment community. This paper details each component of the framework,\\ndemonstrating its applicability in real-world contexts and its potential to\\nguide ethical AI investments.\", 'post': '', 'evaluation': ''}, {'title': 'MIS-ME: A Multi-modal Framework for Soil Moisture Estimation', 'summary': 'Soil moisture estimation is an important task to enable precision agriculture\\nin creating optimal plans for irrigation, fertilization, and harvest. It is\\ncommon to utilize statistical and machine learning models to estimate soil\\nmoisture from traditional data sources such as weather forecasts, soil\\nproperties, and crop properties. However, there is a growing interest in\\nutilizing aerial and geospatial imagery to estimate soil moisture. Although\\nthese images capture high-resolution crop details, they are expensive to curate\\nand challenging to interpret. Imagine, an AI-enhanced software tool that\\npredicts soil moisture using visual cues captured by smartphones and\\nstatistical data given by weather forecasts. This work is a first step towards\\nthat goal of developing a multi-modal approach for soil moisture estimation. In\\nparticular, we curate a dataset consisting of real-world images taken from\\nground stations and their corresponding weather data. We also propose MIS-ME -\\nMeteorological & Image based Soil Moisture Estimator, a multi-modal framework\\nfor soil moisture estimation. Our extensive analysis shows that MIS-ME achieves\\na MAPE of 10.79%, outperforming traditional unimodal approaches with a\\nreduction of 2.6% in MAPE for meteorological data and 1.5% in MAPE for image\\ndata, highlighting the effectiveness of tailored multi-modal approaches.', 'post': '', 'evaluation': ''}, {'title': 'Generalisation of Total Uncertainty in AI: A Theoretical Study', 'summary': 'AI has been dealing with uncertainty to have highly accurate results. This\\nbecomes even worse with reasonably small data sets or a variation in the data\\nsets. This has far-reaching effects on decision-making, forecasting and\\nlearning mechanisms. This study seeks to unpack the nature of uncertainty that\\nexists within AI by drawing ideas from established works, the latest\\ndevelopments and practical applications and provide a novel total uncertainty\\ndefinition in AI.\\n  From inception theories up to current methodologies, this paper provides an\\nintegrated view of dealing with better total uncertainty as well as\\ncomplexities of uncertainty in AI that help us understand its meaning and value\\nacross different domains.', 'post': '', 'evaluation': ''}, {'title': 'Stop-and-go waves reconstruction via iterative refinement', 'summary': 'Stop-and-go waves are a fundamental phenomenon in freeway traffic flow,\\ncontributing to inefficiencies, crashes, and emissions. Recent advancements in\\nhigh-fidelity sensor technologies have improved the ability to capture detailed\\ntraffic dynamics, yet such systems remain scarce and costly. In contrast,\\nconventional traffic sensors are widely deployed but suffer from relatively\\ncoarse-grain data resolution, potentially impeding accurate analysis of\\nstop-and-go waves. This article explores whether generative AI models can\\nenhance the resolution of conventional traffic sensor to approximate the\\nquality of high-fidelity observations. We present a novel approach using a\\nconditional diffusion denoising model, designed to reconstruct fine-grained\\ntraffic speed field from radar-based conventional sensors via iterative\\nrefinement. We introduce a new dataset, I24-WaveX, comprising 132 hours of data\\nfrom both low and high-fidelity sensor systems, totaling over 2 million vehicle\\nmiles traveled. Our approach leverages this dataset to formulate the traffic\\nmeasurement enhancement problem as a spatio-temporal super-resolution task. We\\ndemonstrate that our model can effectively reproduce the patterns of\\nstop-and-go waves, achieving high accuracy in capturing these critical traffic\\ndynamics. Our results show promising advancements in traffic data enhancement,\\noffering a cost-effective way to leverage existing low spatio-temporal\\nresolution sensor networks for improved traffic analysis and management. We\\nalso open-sourced our trained model and code to facilitate further research and\\napplications.', 'post': '', 'evaluation': ''}, {'title': 'WHITE PAPER: A Brief Exploration of Data Exfiltration using GCG Suffixes', 'summary': \"The cross-prompt injection attack (XPIA) is an effective technique that can\\nbe used for data exfiltration, and that has seen increasing use. In this\\nattack, the attacker injects a malicious instruction into third party data\\nwhich an LLM is likely to consume when assisting a user, who is the victim.\\nXPIA is often used as a means for data exfiltration, and the estimated cost of\\nthe average data breach for a business is nearly $4.5 million, which includes\\nbreaches such as compromised enterprise credentials. With the rise of\\ngradient-based attacks such as the GCG suffix attack, the odds of an XPIA\\noccurring which uses a GCG suffix are worryingly high. As part of my work in\\nMicrosoft's AI Red Team, I demonstrated a viable attack model using a GCG\\nsuffix paired with an injection in a simulated XPIA scenario. The results\\nindicate that the presence of a GCG suffix can increase the odds of successful\\ndata exfiltration by nearly 20%, with some caveats.\", 'post': '', 'evaluation': ''}, {'title': 'Annotator in the Loop: A Case Study of In-Depth Rater Engagement to Create a Bridging Benchmark Dataset', 'summary': \"With the growing prevalence of large language models, it is increasingly\\ncommon to annotate datasets for machine learning using pools of crowd raters.\\nHowever, these raters often work in isolation as individual crowdworkers. In\\nthis work, we regard annotation not merely as inexpensive, scalable labor, but\\nrather as a nuanced interpretative effort to discern the meaning of what is\\nbeing said in a text. We describe a novel, collaborative, and iterative\\nannotator-in-the-loop methodology for annotation, resulting in a 'Bridging\\nBenchmark Dataset' of comments relevant to bridging divides, annotated from\\n11,973 textual posts in the Civil Comments dataset. The methodology differs\\nfrom popular anonymous crowd-rating annotation processes due to its use of an\\nin-depth, iterative engagement with seven US-based raters to (1)\\ncollaboratively refine the definitions of the to-be-annotated concepts and then\\n(2) iteratively annotate complex social concepts, with check-in meetings and\\ndiscussions. This approach addresses some shortcomings of current anonymous\\ncrowd-based annotation work, and we present empirical evidence of the\\nperformance of our annotation process in the form of inter-rater reliability.\\nOur findings indicate that collaborative engagement with annotators can enhance\\nannotation methods, as opposed to relying solely on isolated work conducted\\nremotely. We provide an overview of the input texts, attributes, and annotation\\nprocess, along with the empirical results and the resulting benchmark dataset,\\ncategorized according to the following attributes: Alienation, Compassion,\\nReasoning, Curiosity, Moral Outrage, and Respect.\", 'post': '', 'evaluation': ''}, {'title': 'HAIGEN: Towards Human-AI Collaboration for Facilitating Creativity and Style Generation in Fashion Design', 'summary': 'The process of fashion design usually involves sketching, refining, and\\ncoloring, with designers drawing inspiration from various images to fuel their\\ncreative endeavors. However, conventional image search methods often yield\\nirrelevant results, impeding the design process. Moreover, creating and\\ncoloring sketches can be time-consuming and demanding, acting as a bottleneck\\nin the design workflow. In this work, we introduce HAIGEN (Human-AI\\nCollaboration for GENeration), an efficient fashion design system for Human-AI\\ncollaboration developed to aid designers. Specifically, HAIGEN consists of four\\nmodules. T2IM, located in the cloud, generates reference inspiration images\\ndirectly from text prompts. With three other modules situated locally, the I2SM\\nbatch generates the image material library into a certain designer-style sketch\\nmaterial library. The SRM recommends similar sketches in the generated library\\nto designers for further refinement, and the STM colors the refined sketch\\naccording to the styles of inspiration images. Through our system, any designer\\ncan perform local personalized fine-tuning and leverage the powerful generation\\ncapabilities of large models in the cloud, streamlining the entire design\\ndevelopment process. Given that our approach integrates both cloud and local\\nmodel deployment schemes, it effectively safeguards design privacy by avoiding\\nthe need to upload personalized data from local designers. We validated the\\neffectiveness of each module through extensive qualitative and quantitative\\nexperiments. User surveys also confirmed that HAIGEN offers significant\\nadvantages in design efficiency, positioning it as a new generation of aid-tool\\nfor designers.', 'post': '', 'evaluation': ''}, {'title': 'An FDA for AI? Pitfalls and Plausibility of Approval Regulation for Frontier Artificial Intelligence', 'summary': \"Observers and practitioners of artificial intelligence (AI) have proposed an\\nFDA-style licensing regime for the most advanced AI models, or 'frontier'\\nmodels. In this paper, we explore the applicability of approval regulation --\\nthat is, regulation of a product that combines experimental minima with\\ngovernment licensure conditioned partially or fully upon that experimentation\\n-- to the regulation of frontier AI. There are a number of reasons to believe\\nthat approval regulation, simplistically applied, would be inapposite for\\nfrontier AI risks. Domains of weak fit include the difficulty of defining the\\nregulated product, the presence of Knightian uncertainty or deep ambiguity\\nabout harms from AI, the potentially transmissible nature of risks, and\\ndistributed activities among actors involved in the AI lifecycle. We conclude\\nby highlighting the role of policy learning and experimentation in regulatory\\ndevelopment, describing how learning from other forms of AI regulation and\\nimprovements in evaluation and testing methods can help to overcome some of the\\nchallenges we identify.\", 'post': '', 'evaluation': ''}, {'title': 'CERT-ED: Certifiably Robust Text Classification for Edit Distance', 'summary': 'With the growing integration of AI in daily life, ensuring the robustness of\\nsystems to inference-time attacks is crucial. Among the approaches for\\ncertifying robustness to such adversarial examples, randomized smoothing has\\nemerged as highly promising due to its nature as a wrapper around arbitrary\\nblack-box models. Previous work on randomized smoothing in natural language\\nprocessing has primarily focused on specific subsets of edit distance\\noperations, such as synonym substitution or word insertion, without exploring\\nthe certification of all edit operations. In this paper, we adapt Randomized\\nDeletion (Huang et al., 2023) and propose, CERTified Edit Distance defense\\n(CERT-ED) for natural language classification. Through comprehensive\\nexperiments, we demonstrate that CERT-ED outperforms the existing Hamming\\ndistance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of\\nboth accuracy and the cardinality of the certificate. By covering various\\nthreat models, including 5 direct and 5 transfer attacks, our method improves\\nempirical robustness in 38 out of 50 settings.', 'post': '', 'evaluation': ''}, {'title': 'Future of Artificial Intelligence in Agile Software Development', 'summary': 'The advent of Artificial intelligence has promising advantages that can be\\nutilized to transform the landscape of software project development. The\\nSoftware process framework consists of activities that constantly require\\nroutine human interaction, leading to the possibility of errors and\\nuncertainties. AI can assist software development managers, software testers,\\nand other team members by leveraging LLMs, GenAI models, and AI agents to\\nperform routine tasks, risk analysis and prediction, strategy recommendations,\\nand support decision making. AI has the potential to increase efficiency and\\nreduce the risks encountered by the project management team while increasing\\nthe project success rates. Additionally, it can also break down complex notions\\nand development processes for stakeholders to make informed decisions. In this\\npaper, we propose an approach in which AI tools and technologies can be\\nutilized to bestow maximum assistance for agile software projects, which have\\nbecome increasingly favored in the industry in recent years.', 'post': '', 'evaluation': ''}, {'title': 'Refinement of genetic variants needs attention', 'summary': \"Variant calling refinement is crucial for distinguishing true genetic\\nvariants from technical artifacts in high-throughput sequencing data. Manual\\nreview is time-consuming while heuristic filtering often lacks optimal\\nsolutions. Traditional variant calling methods often struggle with accuracy,\\nespecially in regions of low read coverage, leading to false-positive or\\nfalse-negative calls. Here, we introduce VariantTransformer, a\\nTransformer-based deep learning model, designed to automate variant calling\\nrefinement directly from VCF files in low-coverage data (10-15X).\\nVariantTransformer, trained on two million variants, including SNPs and short\\nInDels, from low-coverage sequencing data, achieved an accuracy of 89.26% and a\\nROC AUC of 0.88. When integrated into conventional variant calling pipelines,\\nVariantTransformer outperformed traditional heuristic filters and approached\\nthe performance of state-of-the-art AI-based variant callers like DeepVariant.\\nComparative analysis demonstrated VariantTransformer's superiority in\\nfunctionality, variant type coverage, training size, and input data type.\\nVariantTransformer represents a significant advancement in variant calling\\nrefinement for low-coverage genomic studies.\", 'post': '', 'evaluation': ''}, {'title': 'AI-Enabled sensor fusion of time of flight imaging and mmwave for concealed metal detection', 'summary': 'In the field of detection and ranging, multiple complementary sensing\\nmodalities may be used to enrich the information obtained from a dynamic scene.\\nOne application of this sensor fusion is in public security and surveillance,\\nwhose efficacy and privacy protection measures must be continually evaluated.\\nWe present a novel deployment of sensor fusion for the discrete detection of\\nconcealed metal objects on persons whilst preserving their privacy. This is\\nachieved by coupling off-the-shelf mmWave radar and depth camera technology\\nwith a novel neural network architecture that processes the radar signals using\\nconvolutional Long Short-term Memory (LSTM) blocks and the depth signal, using\\nconvolutional operations. The combined latent features are then magnified using\\na deep feature magnification to learn cross-modality dependencies in the data.\\nWe further propose a decoder, based on the feature extraction and embedding\\nblock, to learn an efficient upsampling of the latent space to learn the\\nlocation of the concealed object in the spatial domain through radar feature\\nguidance. We demonstrate the detection of presence and inference of 3D location\\nof concealed metal objects with an accuracy of up to 95%, using a technique\\nthat is robust to multiple persons. This work provides a demonstration of the\\npotential for cost effective and portable sensor fusion, with strong\\nopportunities for further development.', 'post': '', 'evaluation': ''}, {'title': 'Unlocking Fair Use in the Generative AI Supply Chain: A Systematized Literature Review', 'summary': 'Through a systematization of generative AI (GenAI) stakeholder goals and\\nexpectations, this work seeks to uncover what value different stakeholders see\\nin their contributions to the GenAI supply line. This valuation enables us to\\nunderstand whether fair use advocated by GenAI companies to train model\\nprogresses the copyright law objective of promoting science and arts. While\\nassessing the validity and efficacy of the fair use argument, we uncover\\nresearch gaps and potential avenues for future works for researchers and\\npolicymakers to address.', 'post': '', 'evaluation': ''}, {'title': 'Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Model', 'summary': \"In recent years, Generative Artificial Intelligence (GenAI) has undergone a\\nprofound transformation in addressing intricate tasks involving diverse\\nmodalities such as textual, auditory, visual, and pictorial generation. Within\\nthis spectrum, text-to-image (TTI) models have emerged as a formidable approach\\nto generating varied and aesthetically appealing compositions, spanning\\napplications from artistic creation to realistic facial synthesis, and\\ndemonstrating significant advancements in computer vision, image processing,\\nand multimodal tasks. The advent of Latent Diffusion Models (LDMs) signifies a\\nparadigm shift in the domain of AI capabilities. This article delves into the\\nfeasibility of employing the Stable Diffusion LDM to illustrate literary works.\\nFor this exploration, seven classic Brazilian books have been selected as case\\nstudies. The objective is to ascertain the practicality of this endeavor and to\\nevaluate the potential of Stable Diffusion in producing illustrations that\\naugment and enrich the reader's experience. We will outline the beneficial\\naspects, such as the capacity to generate distinctive and contextually\\npertinent images, as well as the drawbacks, including any shortcomings in\\nfaithfully capturing the essence of intricate literary depictions. Through this\\nstudy, we aim to provide a comprehensive assessment of the viability and\\nefficacy of utilizing AI-generated illustrations in literary contexts,\\nelucidating both the prospects and challenges encountered in this pioneering\\napplication of technology.\", 'post': '', 'evaluation': ''}, {'title': 'The Energy Cost of Artificial Intelligence of Things Lifecycle', 'summary': 'Artificial intelligence (AI)coupled with existing Internet of Things (IoT)\\nenables more streamlined and autonomous operations across various economic\\nsectors. Consequently, the paradigm of Artificial Intelligence of Things (AIoT)\\nhaving AI techniques at its core implies additional energy and carbon costs\\nthat may become significant with more complex neural architectures. To better\\nunderstand the energy and Carbon Footprint (CF) of some AIoT components, very\\nrecent studies employ conventional metrics. However, these metrics are not\\ndesigned to capture energy efficiency aspects of inference. In this paper, we\\npropose a new metric, the Energy Cost of AIoT Lifecycle (eCAL) to capture the\\noverall energy cost of inference over the lifecycle of an AIoT system. We\\ndevise a new methodology for determining eCAL of an AIoT system by analyzing\\nthe complexity of data manipulation in individual components involved in the\\nAIoT lifecycle and derive the overall and per bit energy consumption. With eCAL\\nwe show that the better a model is and the more it is used, the more energy\\nefficient an inference is. For an example AIoT configuration, eCAL for making\\n$100$ inferences is $1.43$ times higher than for $1000$ inferences. We also\\nevaluate the CF of the AIoT system by calculating the equivalent CO$_{2}$\\nemissions based on the energy consumption and the Carbon Intensity (CI) across\\ndifferent countries. Using 2023 renewable data, our analysis reveals that\\ndeploying an AIoT system in Germany results in emitting $4.62$ times higher\\nCO$_2$ than in Finland, due to latter using more low-CI energy sources.', 'post': '', 'evaluation': ''}, {'title': 'Jailbreaking Text-to-Image Models with LLM-Based Agents', 'summary': \"Recent advancements have significantly improved automated task-solving\\ncapabilities using autonomous agents powered by large language models (LLMs).\\nHowever, most LLM-based agents focus on dialogue, programming, or specialized\\ndomains, leaving gaps in addressing generative AI safety tasks. These gaps are\\nprimarily due to the challenges posed by LLM hallucinations and the lack of\\nclear guidelines. In this paper, we propose Atlas, an advanced LLM-based\\nmulti-agent framework that integrates an efficient fuzzing workflow to target\\ngenerative AI models, specifically focusing on jailbreak attacks against\\ntext-to-image (T2I) models with safety filters. Atlas utilizes a\\nvision-language model (VLM) to assess whether a prompt triggers the T2I model's\\nsafety filter. It then iteratively collaborates with both LLM and VLM to\\ngenerate an alternative prompt that bypasses the filter. Atlas also enhances\\nthe reasoning abilities of LLMs in attack scenarios by leveraging multi-agent\\ncommunication, in-context learning (ICL) memory mechanisms, and the\\nchain-of-thought (COT) approach. Our evaluation demonstrates that Atlas\\nsuccessfully jailbreaks several state-of-the-art T2I models in a black-box\\nsetting, which are equipped with multi-modal safety filters. In addition, Atlas\\noutperforms existing methods in both query efficiency and the quality of the\\ngenerated images.\", 'post': '', 'evaluation': ''}, {'title': 'FlowGPT: Exploring Domains, Output Modalities, and Goals of Community-Generated AI Chatbots', 'summary': 'The advent of Generative AI and Large Language Models has not only enhanced\\nthe intelligence of interactive applications but also catalyzed the formation\\nof communities passionate about customizing these AI capabilities. FlowGPT, an\\nemerging platform for sharing AI prompts and use cases, exemplifies this trend,\\nattracting many creators who develop and share chatbots with a broader\\ncommunity. Despite its growing popularity, there remains a significant gap in\\nunderstanding the types and purposes of the AI tools created and shared by\\ncommunity members. In this study, we delve into FlowGPT and present our\\npreliminary findings on the domain, output modality, and goals of chatbots. We\\naim to highlight common types of AI applications and identify future directions\\nfor research in AI-sharing communities.', 'post': '', 'evaluation': ''}, {'title': 'Partial wave analysis of $ψ(3686)\\\\toΛ\\\\barΣ^0π^0+c.c.$', 'summary': 'Based on a sample of $(2712.4\\\\pm14.3)\\\\times10^6\\\\;\\\\psi(3686)$ events collected\\nwith the BESIII detector, a partial wave analysis of the decay\\n$\\\\psi(3686)\\\\to\\\\Lambda\\\\bar\\\\Sigma^0\\\\pi^0+c.c.$ is performed to investigate\\n$\\\\Lambda^*$ and $\\\\Sigma^*$ resonances in the $\\\\pi^0\\\\bar{\\\\Sigma}^0$ and\\n$\\\\pi^0\\\\Lambda$ invariant mass distributions. Significant contributions are\\nfound from the $\\\\Lambda(1405)$, $\\\\Lambda(1520)$, $\\\\Lambda(1600)$,\\n$\\\\Lambda(1670)$, $\\\\Lambda(1690)$, $\\\\Lambda(1800)$, $\\\\Lambda(1890)$,\\n$\\\\Lambda(2325)$, $\\\\Sigma(1385)$, $\\\\Sigma(1660)$, $\\\\Sigma(1670)$,\\n$\\\\Sigma(1750)$, and $\\\\Sigma(1910)$. The masses, widths, and production\\nbranching fractions for each component are determined. In addition, the\\nbranching fraction of $\\\\psi(3686)\\\\to\\\\Lambda\\\\bar\\\\Sigma^0\\\\pi^0+c.c.$ is measured\\nto be $(1.544\\\\pm0.013\\\\pm0.069)\\\\times10^{-4}$ for the first time, where the\\nfirst uncertainty is statistical and the second systematic.', 'post': '', 'evaluation': ''}, {'title': 'Explainable Emotion Decoding for Human and Computer Vision', 'summary': 'Modern Machine Learning (ML) has significantly advanced various research\\nfields, but the opaque nature of ML models hinders their adoption in several\\ndomains. Explainable AI (XAI) addresses this challenge by providing additional\\ninformation to help users understand the internal decision-making process of ML\\nmodels. In the field of neuroscience, enriching a ML model for brain decoding\\nwith attribution-based XAI techniques means being able to highlight which brain\\nareas correlate with the task at hand, thus offering valuable insights to\\ndomain experts. In this paper, we analyze human and Computer Vision (CV)\\nsystems in parallel, training and explaining two ML models based respectively\\non functional Magnetic Resonance Imaging (fMRI) and movie frames. We do so by\\nleveraging the \"StudyForrest\" dataset, which includes functional Magnetic\\nResonance Imaging (fMRI) scans of subjects watching the \"Forrest Gump\" movie,\\nemotion annotations, and eye-tracking data. For human vision the ML task is to\\nlink fMRI data with emotional annotations, and the explanations highlight the\\nbrain regions strongly correlated with the label. On the other hand, for\\ncomputer vision, the input data is movie frames, and the explanations are\\npixel-level heatmaps. We cross-analyzed our results, linking human attention\\n(obtained through eye-tracking) with XAI saliency on CV models and brain region\\nactivations. We show how a parallel analysis of human and computer vision can\\nprovide useful information for both the neuroscience community (allocation\\ntheory) and the ML community (biological plausibility of convolutional models).', 'post': '', 'evaluation': ''}, {'title': 'GalleryGPT: Analyzing Paintings with Large Multimodal Models', 'summary': 'Artwork analysis is important and fundamental skill for art appreciation,\\nwhich could enrich personal aesthetic sensibility and facilitate the critical\\nthinking ability. Understanding artworks is challenging due to its subjective\\nnature, diverse interpretations, and complex visual elements, requiring\\nexpertise in art history, cultural background, and aesthetic theory. However,\\nlimited by the data collection and model ability, previous works for\\nautomatically analyzing artworks mainly focus on classification, retrieval, and\\nother simple tasks, which is far from the goal of AI. To facilitate the\\nresearch progress, in this paper, we step further to compose comprehensive\\nanalysis inspired by the remarkable perception and generation ability of large\\nmultimodal models. Specifically, we first propose a task of composing paragraph\\nanalysis for artworks, i.e., painting in this paper, only focusing on visual\\ncharacteristics to formulate more comprehensive understanding of artworks. To\\nsupport the research on formal analysis, we collect a large dataset\\nPaintingForm, with about 19k painting images and 50k analysis paragraphs. We\\nfurther introduce a superior large multimodal model for painting analysis\\ncomposing, dubbed GalleryGPT, which is slightly modified and fine-tuned based\\non LLaVA architecture leveraging our collected data. We conduct formal analysis\\ngeneration and zero-shot experiments across several datasets to assess the\\ncapacity of our model. The results show remarkable performance improvements\\ncomparing with powerful baseline LMMs, demonstrating its superb ability of art\\nanalysis and generalization. \\\\textcolor{blue}{The codes and model are available\\nat: https://github.com/steven640pixel/GalleryGPT.', 'post': '', 'evaluation': ''}, {'title': 'Initial Insights on MLOps: Perception and Adoption by Practitioners', 'summary': 'The accelerated adoption of AI-based software demands precise development\\nguidelines to guarantee reliability, scalability, and ethical compliance. MLOps\\n(Machine Learning and Operations) guidelines have emerged as the principal\\nreference in this field, paving the way for the development of high-level\\nautomated tools and applications. Despite the introduction of MLOps guidelines,\\nthere is still a degree of skepticism surrounding their implementation, with a\\ngradual adoption rate across many companies. In certain instances, a lack of\\nawareness about MLOps has resulted in organizations adopting similar approaches\\nunintentionally, frequently without a comprehensive understanding of the\\nassociated best practices and principles. The objective of this study is to\\ngain insight into the actual adoption of MLOps (or comparable) guidelines in\\ndifferent business contexts. To this end, we surveyed practitioners\\nrepresenting a range of business environments to understand how MLOps is\\nadopted and perceived in their companies. The results of this survey also shed\\nlight on other pertinent aspects related to the advantages and challenges of\\nthese guidelines, the learning curve associated with them, and the future\\ntrends that can be derived from this information. This study aims to provide\\ndeeper insight into MLOps and its impact on the next phase of innovation in\\nmachine learning. By doing so, we aim to lay the foundation for more efficient,\\nreliable, and creative AI applications in the future.', 'post': '', 'evaluation': ''}, {'title': 'DiscipLink: Unfolding Interdisciplinary Information Seeking Process via Human-AI Co-Exploration', 'summary': \"Interdisciplinary studies often require researchers to explore literature in\\ndiverse branches of knowledge. Yet, navigating through the highly scattered\\nknowledge from unfamiliar disciplines poses a significant challenge. In this\\npaper, we introduce DiscipLink, a novel interactive system that facilitates\\ncollaboration between researchers and large language models (LLMs) in\\ninterdisciplinary information seeking (IIS). Based on users' topics of\\ninterest, DiscipLink initiates exploratory questions from the perspectives of\\npossible relevant fields of study, and users can further tailor these\\nquestions. DiscipLink then supports users in searching and screening papers\\nunder selected questions by automatically expanding queries with\\ndisciplinary-specific terminologies, extracting themes from retrieved papers,\\nand highlighting the connections between papers and questions. Our evaluation,\\ncomprising a within-subject comparative experiment and an open-ended\\nexploratory study, reveals that DiscipLink can effectively support researchers\\nin breaking down disciplinary boundaries and integrating scattered knowledge in\\ndiverse fields. The findings underscore the potential of LLM-powered tools in\\nfostering information-seeking practices and bolstering interdisciplinary\\nresearch.\", 'post': '', 'evaluation': ''}, {'title': 'A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality', 'summary': \"Artificial Intelligence (AI) advancements have enabled the development of\\nLarge Language Models (LLMs) that can perform a variety of tasks with\\nremarkable semantic understanding and accuracy. ChatGPT is one such LLM that\\nhas gained significant attention due to its impressive capabilities for\\nassisting in various knowledge-intensive tasks. Due to the knowledge-intensive\\nnature of engineering secure software, ChatGPT's assistance is expected to be\\nexplored for security-related tasks during the development/evolution of\\nsoftware. To gain an understanding of the potential of ChatGPT as an emerging\\ntechnology for supporting software security, we adopted a two-fold approach.\\nInitially, we performed an empirical study to analyse the perceptions of those\\nwho had explored the use of ChatGPT for security tasks and shared their views\\non Twitter. It was determined that security practitioners view ChatGPT as\\nbeneficial for various software security tasks, including vulnerability\\ndetection, information retrieval, and penetration testing. Secondly, we\\ndesigned an experiment aimed at investigating the practicality of this\\ntechnology when deployed as an oracle in real-world settings. In particular, we\\nfocused on vulnerability detection and qualitatively examined ChatGPT outputs\\nfor given prompts within this prominent software security task. Based on our\\nanalysis, responses from ChatGPT in this task are largely filled with generic\\nsecurity information and may not be appropriate for industry use. To prevent\\ndata leakage, we performed this analysis on a vulnerability dataset compiled\\nafter the OpenAI data cut-off date from real-world projects covering 40\\ndistinct vulnerability types and 12 programming languages. We assert that the\\nfindings from this study would contribute to future research aimed at\\ndeveloping and evaluating LLMs dedicated to software security.\", 'post': '', 'evaluation': ''}, {'title': 'Deepfake Media Forensics: State of the Art and Challenges Ahead', 'summary': \"AI-generated synthetic media, also called Deepfakes, have significantly\\ninfluenced so many domains, from entertainment to cybersecurity. Generative\\nAdversarial Networks (GANs) and Diffusion Models (DMs) are the main frameworks\\nused to create Deepfakes, producing highly realistic yet fabricated content.\\nWhile these technologies open up new creative possibilities, they also bring\\nsubstantial ethical and security risks due to their potential misuse. The rise\\nof such advanced media has led to the development of a cognitive bias known as\\nImpostor Bias, where individuals doubt the authenticity of multimedia due to\\nthe awareness of AI's capabilities. As a result, Deepfake detection has become\\na vital area of research, focusing on identifying subtle inconsistencies and\\nartifacts with machine learning techniques, especially Convolutional Neural\\nNetworks (CNNs). Research in forensic Deepfake technology encompasses five main\\nareas: detection, attribution and recognition, passive authentication,\\ndetection in realistic scenarios, and active authentication. Each area tackles\\nspecific challenges, from tracing the origins of synthetic media and examining\\nits inherent characteristics for authenticity. This paper reviews the primary\\nalgorithms that address these challenges, examining their advantages,\\nlimitations, and future prospects.\", 'post': '', 'evaluation': ''}, {'title': 'On the Limitations and Prospects of Machine Unlearning for Generative AI', 'summary': 'Generative AI (GenAI), which aims to synthesize realistic and diverse data\\nsamples from latent variables or other data modalities, has achieved remarkable\\nresults in various domains, such as natural language, images, audio, and\\ngraphs. However, they also pose challenges and risks to data privacy, security,\\nand ethics. Machine unlearning is the process of removing or weakening the\\ninfluence of specific data samples or features from a trained model, without\\naffecting its performance on other data or tasks. While machine unlearning has\\nshown significant efficacy in traditional machine learning tasks, it is still\\nunclear if it could help GenAI become safer and aligned with human desire. To\\nthis end, this position paper provides an in-depth discussion of the machine\\nunlearning approaches for GenAI. Firstly, we formulate the problem of machine\\nunlearning tasks on GenAI and introduce the background. Subsequently, we\\nsystematically examine the limitations of machine unlearning on GenAI models by\\nfocusing on the two representative branches: LLMs and image generative\\n(diffusion) models. Finally, we provide our prospects mainly from three\\naspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and\\nconscientiously advocate for the future development of this field.', 'post': '', 'evaluation': ''}, {'title': 'Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks', 'summary': \"Machine learning (ML) is a rapidly developing area of medicine that uses\\nsignificant resources to apply computer science and statistics to medical\\nissues. ML's proponents laud its capacity to handle vast, complicated, and\\nerratic medical data. It's common knowledge that attackers might cause\\nmisclassification by deliberately creating inputs for machine learning\\nclassifiers. Research on adversarial examples has been extensively conducted in\\nthe field of computer vision applications. Healthcare systems are thought to be\\nhighly difficult because of the security and life-or-death considerations they\\ninclude, and performance accuracy is very important. Recent arguments have\\nsuggested that adversarial attacks could be made against medical image analysis\\n(MedIA) technologies because of the accompanying technology infrastructure and\\npowerful financial incentives. Since the diagnosis will be the basis for\\nimportant decisions, it is essential to assess how strong medical DNN tasks are\\nagainst adversarial attacks. Simple adversarial attacks have been taken into\\naccount in several earlier studies. However, DNNs are susceptible to more risky\\nand realistic attacks. The present paper covers recent proposed adversarial\\nattack strategies against DNNs for medical imaging as well as countermeasures.\\nIn this study, we review current techniques for adversarial imaging attacks,\\ndetections. It also encompasses various facets of these techniques and offers\\nsuggestions for the robustness of neural networks to be improved in the future.\", 'post': '', 'evaluation': ''}, {'title': 'Gradient Flow Decoding', 'summary': 'This paper presents the Gradient Flow (GF) decoding for LDPC codes. GF\\ndecoding, a continuous-time methodology based on gradient flow, employs a\\npotential energy function associated with bipolar codewords of LDPC codes. The\\ndecoding process of the GF decoding is concisely defined by an ordinary\\ndifferential equation and thus it is well suited to an analog circuit\\nimplementation. We experimentally demonstrate that the decoding performance of\\nthe GF decoding for AWGN channels is comparable to that of the multi-bit mode\\ngradient descent bit flipping algorithm. We further introduce the negative\\nlog-likelihood function of the channel for generalizing the GF decoding. The\\nproposed method is shown to be tensor-computable, which means that the gradient\\nof the objective function can be evaluated with the combination of basic tensor\\ncomputations. This characteristic is well-suited to emerging AI accelerators,\\npotentially applicable in wireless signal processing. The paper assesses the\\ndecoding performance of the generalized GF decoding in LDPC-coded MIMO\\nchannels. Our numerical experiments reveal that the decoding performance rivals\\nthat of established techniques like MMSE + BP. Furthermore, an exploration of\\nscore-based channel learning for capturing statistical properties is also\\nprovided.', 'post': '', 'evaluation': ''}, {'title': 'Everything We Hear: Towards Tackling Misinformation in Podcasts', 'summary': 'Advances in generative AI, the proliferation of large multimodal models\\n(LMMs), and democratized open access to these technologies have direct\\nimplications for the production and diffusion of misinformation. In this\\nprequel, we address tackling misinformation in the unique and increasingly\\npopular context of podcasts. The rise of podcasts as a popular medium for\\ndisseminating information across diverse topics necessitates a proactive\\nstrategy to combat the spread of misinformation. Inspired by the proven\\neffectiveness of \\\\textit{auditory alerts} in contexts like collision alerts for\\ndrivers and error pings in mobile phones, our work envisions the application of\\nauditory alerts as an effective tool to tackle misinformation in podcasts. We\\npropose the integration of suitable auditory alerts to notify listeners of\\npotential misinformation within the podcasts they are listening to, in\\nreal-time and without hampering listening experiences. We identify several\\nopportunities and challenges in this path and aim to provoke novel\\nconversations around instruments, methods, and measures to tackle\\nmisinformation in podcasts.', 'post': '', 'evaluation': ''}, {'title': 'Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review and Meta-analysis', 'summary': 'Purpose: Artificial intelligence (AI) techniques have been extensively\\nutilized for diagnosing and prognosis of several diseases in recent years. This\\nstudy identifies, appraises and synthesizes published studies on the use of AI\\nfor the prognosis of COVID-19. Method: Electronic search was performed using\\nMedline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that\\nexamined machine learning or deep learning methods to determine the prognosis\\nof COVID-19 using CT or chest X-ray images were included. Polled sensitivity,\\nspecificity area under the curve and diagnostic odds ratio were calculated.\\nResult: A total of 36 articles were included; various prognosis-related issues,\\nincluding disease severity, mechanical ventilation or admission to the\\nintensive care unit and mortality, were investigated. Several AI models and\\narchitectures were employed, such as the Siamense model, support vector\\nmachine, Random Forest , eXtreme Gradient Boosting, and convolutional neural\\nnetworks. The models achieved 71%, 88% and 67% sensitivity for mortality,\\nseverity assessment and need for ventilation, respectively. The specificity of\\n69%, 89% and 89% were reported for the aforementioned variables. Conclusion:\\nBased on the included articles, machine learning and deep learning methods used\\nfor the prognosis of COVID-19 patients using radiomic features from CT or CXR\\nimages can help clinicians manage patients and allocate resources more\\neffectively. These studies also demonstrate that combining patient demographic,\\nclinical data, laboratory tests and radiomic features improves model\\nperformances.', 'post': '', 'evaluation': ''}, {'title': 'S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images', 'summary': 'Development of artificial intelligence (AI) techniques in medical imaging\\nrequires access to large-scale and diverse datasets for training and\\nevaluation. In dermatology, obtaining such datasets remains challenging due to\\nsignificant variations in patient populations, illumination conditions, and\\nacquisition system characteristics. In this work, we propose S-SYNTH, the first\\nknowledge-based, adaptable open-source skin simulation framework to rapidly\\ngenerate synthetic skin, 3D models and digitally rendered images, using an\\nanatomically inspired multi-layer, multi-component skin and growing lesion\\nmodel. The skin model allows for controlled variation in skin appearance, such\\nas skin color, presence of hair, lesion shape, and blood fraction among other\\nparameters. We use this framework to study the effect of possible variations on\\nthe development and evaluation of AI models for skin lesion segmentation, and\\nshow that results obtained using synthetic data follow similar comparative\\ntrends as real dermatologic images, while mitigating biases and limitations\\nfrom existing datasets including small dataset size, lack of diversity, and\\nunderrepresentation.', 'post': '', 'evaluation': ''}, {'title': 'CREW: Facilitating Human-AI Teaming Research', 'summary': 'With the increasing deployment of artificial intelligence (AI) technologies,\\nthe potential of humans working with AI agents has been growing at a great\\nspeed. Human-AI teaming is an important paradigm for studying various aspects\\nwhen humans and AI agents work together. The unique aspect of Human-AI teaming\\nresearch is the need to jointly study humans and AI agents, demanding\\nmultidisciplinary research efforts from machine learning to human-computer\\ninteraction, robotics, cognitive science, neuroscience, psychology, social\\nscience, and complex systems. However, existing platforms for Human-AI teaming\\nresearch are limited, often supporting oversimplified scenarios and a single\\ntask, or specifically focusing on either human-teaming research or multi-agent\\nAI algorithms. We introduce CREW, a platform to facilitate Human-AI teaming\\nresearch and engage collaborations from multiple scientific disciplines, with a\\nstrong emphasis on human involvement. It includes pre-built tasks for cognitive\\nstudies and Human-AI teaming with expandable potentials from our modular\\ndesign. Following conventional cognitive neuroscience research, CREW also\\nsupports multimodal human physiological signal recording for behavior analysis.\\nMoreover, CREW benchmarks real-time human-guided reinforcement learning agents\\nusing state-of-the-art algorithms and well-tuned baselines. With CREW, we were\\nable to conduct 50 human subject studies within a week to verify the\\neffectiveness of our benchmark.', 'post': '', 'evaluation': ''}, {'title': 'AI for Nuclear Physics: the EXCLAIM project', 'summary': 'In overview of the recent activity of the newly funded EXCLusives with AI and\\nMachine learning (EXCLAIM) collaboration is presented. The main goal of the\\ncollaboration is to develop a framework to implement AI and machine learning\\ntechniques in problems emerging from the phenomenology of high energy exclusive\\nscattering processes from nucleons and nuclei, maximizing the information that\\ncan be extracted from various sets of experimental data, while implementing\\ntheoretical constraints from lattice QCD. A specific perspective embraced by\\nEXCLAIM is to use the methods of theoretical physics to understand the working\\nof ML, beyond its standardized applications to physics analyses which most\\noften rely on industrially provided tools, in an automated way.', 'post': '', 'evaluation': ''}, {'title': 'A Taxonomy of Stereotype Content in Large Language Models', 'summary': \"This study introduces a taxonomy of stereotype content in contemporary large\\nlanguage models (LLMs). We prompt ChatGPT 3.5, Llama 3, and Mixtral 8x7B, three\\npowerful and widely used LLMs, for the characteristics associated with 87\\nsocial categories (e.g., gender, race, occupations). We identify 14 stereotype\\ndimensions (e.g., Morality, Ability, Health, Beliefs, Emotions), accounting for\\n~90% of LLM stereotype associations. Warmth and Competence facets were the most\\nfrequent content, but all other dimensions were significantly prevalent.\\nStereotypes were more positive in LLMs (vs. humans), but there was significant\\nvariability across categories and dimensions. Finally, the taxonomy predicted\\nthe LLMs' internal evaluations of social categories (e.g., how\\npositively/negatively the categories were represented), supporting the\\nrelevance of a multidimensional taxonomy for characterizing LLM stereotypes.\\nOur findings suggest that high-dimensional human stereotypes are reflected in\\nLLMs and must be considered in AI auditing and debiasing to minimize\\nunidentified harms from reliance in low-dimensional views of bias in LLMs.\", 'post': '', 'evaluation': ''}, {'title': 'Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?', 'summary': 'As artificial intelligence systems grow more powerful, there has been\\nincreasing interest in \"AI safety\" research to address emerging and future\\nrisks. However, the field of AI safety remains poorly defined and\\ninconsistently measured, leading to confusion about how researchers can\\ncontribute. This lack of clarity is compounded by the unclear relationship\\nbetween AI safety benchmarks and upstream general capabilities (e.g., general\\nknowledge and reasoning). To address these issues, we conduct a comprehensive\\nmeta-analysis of AI safety benchmarks, empirically analyzing their correlation\\nwith general capabilities across dozens of models and providing a survey of\\nexisting directions in AI safety. Our findings reveal that many safety\\nbenchmarks highly correlate with upstream model capabilities, potentially\\nenabling \"safetywashing\" -- where capability improvements are misrepresented as\\nsafety advancements. Based on these findings, we propose an empirical\\nfoundation for developing more meaningful safety metrics and define AI safety\\nin a machine learning research context as a set of clearly delineated research\\ngoals that are empirically separable from generic capabilities advancements. In\\ndoing so, we aim to provide a more rigorous framework for AI safety research,\\nadvancing the science of safety evaluations and clarifying the path towards\\nmeasurable progress.', 'post': '', 'evaluation': ''}, {'title': 'The Llama 3 Herd of Models', 'summary': 'Modern artificial intelligence (AI) systems are powered by foundation models.\\nThis paper presents a new set of foundation models, called Llama 3. It is a\\nherd of language models that natively support multilinguality, coding,\\nreasoning, and tool usage. Our largest model is a dense Transformer with 405B\\nparameters and a context window of up to 128K tokens. This paper presents an\\nextensive empirical evaluation of Llama 3. We find that Llama 3 delivers\\ncomparable quality to leading language models such as GPT-4 on a plethora of\\ntasks. We publicly release Llama 3, including pre-trained and post-trained\\nversions of the 405B parameter language model and our Llama Guard 3 model for\\ninput and output safety. The paper also presents the results of experiments in\\nwhich we integrate image, video, and speech capabilities into Llama 3 via a\\ncompositional approach. We observe this approach performs competitively with\\nthe state-of-the-art on image, video, and speech recognition tasks. The\\nresulting models are not yet being broadly released as they are still under\\ndevelopment.', 'post': '', 'evaluation': ''}, {'title': 'ShieldGemma: Generative AI Content Moderation Based on Gemma', 'summary': 'We present ShieldGemma, a comprehensive suite of LLM-based safety content\\nmoderation models built upon Gemma2. These models provide robust,\\nstate-of-the-art predictions of safety risks across key harm types (sexually\\nexplicit, dangerous content, harassment, hate speech) in both user input and\\nLLM-generated output. By evaluating on both public and internal benchmarks, we\\ndemonstrate superior performance compared to existing models, such as Llama\\nGuard (+10.8\\\\% AU-PRC on public benchmarks) and WildCard (+4.3\\\\%).\\nAdditionally, we present a novel LLM-based data curation pipeline, adaptable to\\na variety of safety-related tasks and beyond. We have shown strong\\ngeneralization performance for model trained mainly on synthetic data. By\\nreleasing ShieldGemma, we provide a valuable resource to the research\\ncommunity, advancing LLM safety and enabling the creation of more effective\\ncontent moderation solutions for developers.', 'post': '', 'evaluation': ''}, {'title': 'MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts', 'summary': \"We introduce MoMa, a novel modality-aware mixture-of-experts (MoE)\\narchitecture designed for pre-training mixed-modal, early-fusion language\\nmodels. MoMa processes images and text in arbitrary sequences by dividing\\nexpert modules into modality-specific groups. These groups exclusively process\\ndesignated tokens while employing learned routing within each group to maintain\\nsemantically informed adaptivity. Our empirical results reveal substantial\\npre-training efficiency gains through this modality-specific parameter\\nallocation. Under a 1-trillion-token training budget, the MoMa 1.4B model,\\nfeaturing 4 text experts and 4 image experts, achieves impressive FLOPs\\nsavings: 3.7x overall, with 2.6x for text and 5.2x for image processing\\ncompared to a compute-equivalent dense baseline, measured by pre-training loss.\\nThis outperforms the standard expert-choice MoE with 8 mixed-modal experts,\\nwhich achieves 3x overall FLOPs savings (3x for text, 2.8x for image).\\nCombining MoMa with mixture-of-depths (MoD) further improves pre-training FLOPs\\nsavings to 4.2x overall (text: 3.4x, image: 5.3x), although this combination\\nhurts performance in causal inference due to increased sensitivity to router\\naccuracy. These results demonstrate MoMa's potential to significantly advance\\nthe efficiency of mixed-modal, early-fusion language model pre-training, paving\\nthe way for more resource-efficient and capable multimodal AI systems.\", 'post': '', 'evaluation': ''}, {'title': 'Artificial Intelligence Approaches for Energy Efficiency: A Review', 'summary': 'United Nations set Sustainable Development Goals and this paper focuses on\\n7th (Affordable and Clean Energy), 9th (Industries, Innovation and\\nInfrastructure), and 13th (Climate Action) goals. Climate change is a major\\nconcern in our society; for this reason, a current global objective is to\\nreduce energy waste. This work summarizes all main approaches towards energy\\nefficiency using Artificial Intelligence with a particular focus on multi-agent\\nsystems to create smart buildings. It mentions the tight relationship between\\nAI, especially IoT, and Big Data. It explains the application of AI to anomaly\\ndetection in smart buildings and a possible classification of Intelligent\\nEnergy Management Systems: Direct and Indirect. Finally, some drawbacks of AI\\napproaches and some possible future research focuses are proposed.', 'post': '', 'evaluation': ''}, {'title': 'Assessing the State of AI Policy', 'summary': 'The deployment of artificial intelligence (AI) applications has accelerated\\nrapidly. AI enabled technologies are facing the public in many ways including\\ninfrastructure, consumer products and home applications. Because many of these\\ntechnologies present risks either in the form of physical injury, or bias,\\npotentially yielding unfair outcomes, policy makers must consider the need for\\noversight. Most policymakers, however, lack the technical knowledge to judge\\nwhether an emerging AI technology is safe, effective, and requires oversight,\\ntherefore policy makers must depend on expert opinion. But policymakers are\\nbetter served when, in addition to expert opinion, they have some general\\nunderstanding of existing guidelines and regulations. This work provides an\\noverview [the landscape] of AI legislation and directives at the international,\\nU.S. state, city and federal levels. It also reviews relevant business\\nstandards, and technical society initiatives. Then an overlap and gap analysis\\nare performed resulting in a reference guide that includes recommendations and\\nguidance for future policy making.', 'post': '', 'evaluation': ''}, {'title': 'Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components', 'summary': \"Automation of medical image interpretation could alleviate bottlenecks in\\ndiagnostic workflows, and has become of particular interest in recent years due\\nto advancements in natural language processing. Great strides have been made\\ntowards automated radiology report generation via AI, yet ensuring clinical\\naccuracy in generated reports is a significant challenge, hindering deployment\\nof such methods in clinical practice. In this work we propose a quality control\\nframework for assessing the reliability of AI-generated radiology reports with\\nrespect to semantics of diagnostic importance using modular auxiliary auditing\\ncomponents (AC). Evaluating our pipeline on the MIMIC-CXR dataset, our findings\\nshow that incorporating ACs in the form of disease-classifiers can enable\\nauditing that identifies more reliable reports, resulting in higher F1 scores\\ncompared to unfiltered generated reports. Additionally, leveraging the\\nconfidence of the AC labels further improves the audit's effectiveness.\", 'post': '', 'evaluation': ''}, {'title': 'REPS: Recycling Entropies for Packet Spraying to Adaptively Explore Paths and Mitigate Failures', 'summary': 'Most existing datacenter transport protocols rely on in-order packet\\ndelivery, a design choice rooted in legacy systems and simplicity. However,\\nadvancements in technology, such as RDMA, have made it feasible to relax this\\nrequirement, allowing for more effective use of modern datacenter topologies\\nlike FatTree and Dragonfly. The rise of AI/ML workloads underscores the\\nnecessity for enhanced link utilization, a challenge for single-path load\\nbalancers due to issues like ECMP collisions.\\n  In this paper, we introduce REPS, a novel per-packet traffic load-balancing\\nalgorithm that integrates seamlessly with existing congestion control\\nmechanisms. REPS reroutes packets around congested hotspots and unreliable or\\nfailing links with remarkable simplicity and minimal state requirements.\\n  Our evaluation demonstrates that REPS significantly outperforms traditional\\npacket spraying and other state-of-the-art solutions in datacenter networks,\\noffering substantial improvements in performance and link utilization.', 'post': '', 'evaluation': ''}, {'title': \"Between the AI and Me: Analysing Listeners' Perspectives on AI- and Human-Composed Progressive Metal Music\", 'summary': \"Generative AI models have recently blossomed, significantly impacting\\nartistic and musical traditions. Research investigating how humans interact\\nwith and deem these models is therefore crucial. Through a listening and\\nreflection study, we explore participants' perspectives on AI- vs\\nhuman-generated progressive metal, in symbolic format, using rock music as a\\ncontrol group. AI-generated examples were produced by ProgGP, a\\nTransformer-based model. We propose a mixed methods approach to assess the\\neffects of generation type (human vs. AI), genre (progressive metal vs. rock),\\nand curation process (random vs. cherry-picked). This combines quantitative\\nfeedback on genre congruence, preference, creativity, consistency, playability,\\nhumanness, and repeatability, and qualitative feedback to provide insights into\\nlisteners' experiences. A total of 32 progressive metal fans completed the\\nstudy. Our findings validate the use of fine-tuning to achieve genre-specific\\nspecialization in AI music generation, as listeners could distinguish between\\nAI-generated rock and progressive metal. Despite some AI-generated excerpts\\nreceiving similar ratings to human music, listeners exhibited a preference for\\nhuman compositions. Thematic analysis identified key features for genre and AI\\nvs. human distinctions. Finally, we consider the ethical implications of our\\nwork in promoting musical data diversity within MIR research by focusing on an\\nunder-explored genre.\", 'post': '', 'evaluation': ''}]}\n"
     ]
    }
   ],
   "source": [
    "app = build_research_graph()\n",
    "# help me run this thing\n",
    "\n",
    "# Run the graph\n",
    "result = app.invoke({\n",
    "    \"messages\": [],\n",
    "    \"papers\": []\n",
    "})\n",
    "\n",
    "# Print the result\n",
    "print(\"Graph execution result:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCADbAJ0DASIAAhEBAxEB/8QAHQABAAICAwEBAAAAAAAAAAAAAAYIBQcCAwQJAf/EAE8QAAEDAwEDBQkKCggHAAAAAAECAwQABREGBxIhExYxVdMIFBUiQVGUldEjNjdUVnF2gZG0FzJSU2FydJKTsgkzQ2KhsbPSGCVCV3N1gv/EABoBAQEAAwEBAAAAAAAAAAAAAAABAgMEBgX/xAAyEQEAAQIDBAgEBwEAAAAAAAAAAQIRAxJRBBMhkQUUMUFSYaGxI3HB0RUiMjNCU+Hw/9oADAMBAAIRAxEAPwD6p0pSgUpSgVxccS0grWoIQOJUo4ArEX29PxXmbfbmUybrJBKEuZ5NhA6XXCOO6OgJHFRwBgbyk+NGgrbKWHryFahl5J5S4gLbTnyIaxuJA8mBnzknjW6KIiM1c291tqyStT2ZCilV2gpI6QZKPbX5zqsvXED0lHtr8TpOxoSEps1vSkdAEVGB/hX7zVsvU8D0ZHsrL4Pn6LwOdVl64geko9tOdVl64geko9tOatl6ngejI9lOatl6ngejI9lPg+focDnVZeuIHpKPbTnVZeuIHpKPbTmrZep4HoyPZTmrZep4HoyPZT4Pn6HA51WXriB6Sj213xb3bpy9yNPiyFn/AKWnkqP+Bro5q2XqeB6Mj2V0StE6dmo3X7FbXU4x48Rs4+bhwp8Hz9E4M3Sou5Z5mk0mTZlyZ0FABctDzvKEJHSWFq8YK/uKUUnGBuZzUggT490hMy4rgdjvJCkLAIyPmPEHzg8R5awqotGambx/3aWeilKVqQpSlApSlApSlBGNE4uRut7XhT06W4yhXHKWGFqabT82QtfzuGpPUY2eJ72sL0BWQ7BnSo6wRj+2UpJ+tC0H66k9dGP+7VHd3fLu9FntKxOq9V2jQ2nZ9+v09q2WiC3ysiU9ndQnIA6MkkkgAAEkkAcTWWqE7abTaL7svv8AAvtkueobU80gPW+ytlcxfuiSlTISQStCgFjBz4nDPQedEK1z3VGl9NaKtWpLU3OvMOZfotkcSbbMacYU4tHKKU2Wd/eS2sKSgpBWSEpyTipRqfb9ofRlqs9xvNzmQY92ZXIiIVaZini2nG+tbSWitsJ3k5K0pxkZrRMxvaHqbZBLkT7XqPUELTesrXcrP4Wtwj3u4W2O+w67vxwElTiSHAklKVLCc4yeMp2k6rvurNW6alvWvaHD2fyrU+4iFpyDIiXB25B/cS3L3N11hvkxvJ3ihBKsqVgCg2hqDb3oPTLOnnZuoEKRqGKuZaO84z0ozmkBsqLQaQoqOHUEJHjEE4BwcYDTPdI2TUm2G7aGbg3Jkx4kF+LMVa5gDy30urUlzLASwEpQjCnFAKKlAcUkDUuwTQt/tNz2At3XTd0gOaesmoYU4zIiwmG8XmEthS8bo30hW4oHC053SRmtksyLhobuntRzZenr1OtOrLXaYsO522CuTGYeYckJcTIWkHkQA8hW8rAxnjwxQbwpSlAqMafxa9V320IwmOtLdzZQM+KXlOB0fW42pfzuGpPUYt6e+9od4kJzycSDHiE44coVOOKGfLhKmz/9V0Yf6a4nT6wsd6T0pSudClKUClKUClKUEcukV+w3dy9wmFyo76UouMVlJU4oJBCHm0j8ZSQcKSOKk4xlSEoXxvumdJbVbJHZvFstWqbUh3lmm5jKJLSXACneAUCAoBSh5xkipLWBuWirXcZa5iUP2+cviuVb5C461nGMr3CAvh+UD0DzCt8VU1xEV8Jjv+69vaio7m3ZQkKA2b6WAUMEC0scR0/k/oFZTTOxbQGi7u3dbBouxWW5NpUlEuBb2mXUhQwoBSUgjI4V7OZD44J1RfkgeTl2j/iWyacyZHyqv38Znsqu7w/H6SWjVKKVF+ZMj5VX7+Mz2Val7pe9ah2SaDtl4seqLquXIvkG3LEtTS08k86ErwA2OOOg03eH4/SS0arBV1S4rM+K9GktIfjvIU2404neStJGCkg9IIOMVHOZMj5VX7+Mz2VOZMj5VX7+Mz2VN3h+P0ktGqPf8Neyf/tvpYfNaGP9tcm+5u2UtLStGzjSyVpIKVC0sAg+f8Ws/wAyZHyqv38ZnsqcxA7wk6gvspvGCgzeRyPnaShX2GmTD8fpJaNXuvWo0wXe8IKEz704nLUJK8buehx08eTbHlUR5MJClEJPfp+ypsUAsl3viS64p+TIKd0vOqOVKxk4HkAycJCRnhXZaLFAsMdTNvitxkKO8spGVLV0ZUo8VH9JJNe+saqoiMlHZ7nyKUpWlClKUClKUClKUClKUClKUCq793N8Edi+lVp+8CrEVXfu5vgjsX0qtP3gUFiKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKrv3c3wR2L6VWn7wKsRVd+7m+COxfSq0/eBQWIpSlApSlApSlApSlApSlApX4pQQkqUQlIGSSeAFQo6wvd2AkWW2QTbV8WZFwkrbceT5FhtLZ3UnpGTkjpArdh4VWLfL9ltdNqVCPDusPiFj9Le7Onh3WHxCx+lvdnW7qtesc4LJvSoR4d1h8Qsfpb3Z08O6w+IWP0t7s6dVr1jnBZN6VCPDusPiFj9Le7Onh3WHxCx+lvdnTqtesc4LJvXxj7uTYUdiG3K5JhRuR03fSq52wpHiICj7qyPINxZIA8iSjPTX1l8O6w+IWP0t7s61J3Ruwmd3SmnLTar7HtUFy2zUy2ZkWS6XQg8HWuLfBK04+YpSeOMF1WvWOcFkM/oy9jknQGx64atuAWzM1e6080wsY3YrPKJZVg+VRcdV+lJQauLUAt0zU9ot8WDCtNgiw4rSWGGGpLyUNtpACUpHJ8AAAAK9Hh3WHxCx+lvdnTqtesc4LJvSoR4d1h8Qsfpb3Z08O6w+IWP0t7s6dVr1jnBZN6VCPDusPiFj9Le7Onh3WHxCx+lvdnTqtesc4LJvSoR4d1h8Qsfpb3Z08O6w+IWP0t7s6dVr1jnBZN6VHdP6nkTZpt10htwLlyZdbDDpdZfQCAooWUpOQSMpIGMjGRxqRVz10VYc5akYvVBKdM3cg4IhvEEfqGo9pkAabtQAAAiNYA/UFSHVXvYvH7G9/Iaj2mve5av2Rr+QV24P7M/P6L3MlStH7Fbtrna3abVtCkaxFssdykOvMaXj2xhbSYiXFoQhbyhypdISFFQUACSN3hWG2d6z1XP2cap15qvaF4Mtdvk3iMw2LXHUyw2zIdaaedARvuLQU4CEKSFAJBBUSTMyLE0qqNg2jbU587V2lmLpelXV3Sjl/sM+/2SFElB9t0I5MMtFSS25vJGHEBaePDoNehPdjDwo5qMx2zs9NgHJyuHG9iL36Yu95yyoIxn8dJHTTPAs0LzbzdzaROjeFAwJRg8snlwyVboc3M725vAjexjIxXsqvey9u/tberPzqlmbqRWzmK5cXuSQ37uqctS0hKAAAkkpGB0J89WCccQy2pxxQQhAKlKUcAAdJJqxNxypVXdBbZNWyNqmjG/Dl31PovVUmXFZnXGxxoEVRQw4825EUhXLKT7kR7qnCknINSLZSvaPtO0Vfr09tBetsozrtb7Y1HtkQts8lKdbZcd3miVlJRjA3QUgZBVlVSKrjfrzzcZlx55xLTTaStbiyAlKQMkknoArqt1xiXiBHnQJTM2FJbS6xJjuBxt1ChlKkqGQoEcQR01XDZ7tQ1ftx0HrbUabzG05CtVuctSINuRFm79waQFyZKitCxyZPiNoPBSCVEElOPNpjbVdNmWlNEXjUMhp/TF62fsXCFEjxGWEt3SPHQ64y2lpCQA824ClHQC0QkAcKZoFoKVGtmsfUMbQViRqyaLhqUxUOXB4NIbHLKG8pASgBOEk7o4cQkE5JJqB67vGrLttysujLJqdzTVsladlXOQ8xBYkPco3IYbTuF1Kgk+68chQxngCQoZX4XG4aVWTTG1rXO0CNoHSbF7Zst9uT96RddQsQW1rU3bpHIDkWlgthbpUgqyCE+NgcRjgxth11MurWzNq8xU6vXqmRYzqpUFBAhtQxNL3If1fLlCg3u43cgnHkrHNAslFvNvnT50GNOjSJsEoTLjNPJU5HK07yA4kHKSpJBGcZByK9lU8f1nqfY7qPa221cXdU6quWobBZotxXDYQ4VyIqAlZZCm2lLSjIAKkJUoJzgE1t3YzeNpa9Xz7fqqDepGnDBD7F01BFt0aSiUFgFkJhvLStCkq3gSlJBQQScikVX4DZ0g417pnHlRLB+bcT7BU7qByff7pj9SX/AKaanlYbV/D5fWVnuYvVXvYvH7G9/Iaj2mve5av2Rr+QVLpsRE+G/GdzyTzam1Y6cEYP+da/iXKTpeFGtlztdydeitpZEqDBcktPhIACxySVFOccUqAIORxGCdmz/mw5ojtuscYRXT+wO2aTv4m2TUmprVaBNVPGm41wSLaHVKK1gIKCsIUolRbCwjJPCshE2J6dY2aXfQr3fc2x3R2Y7I5d0B3ekPLeXuqSlON1azu8MjAznpOf55xurL96kl9lTnnG6sv3qSX2VbtxX4ZMs6ItpPYfB0trWNqxzUuo77fmoLlsXJu8xt0PRlKQsNqQltKRuqQFAoCSSTvFWaJ7nzRSdCNaQFs/5I3dxektZG8JHfXfHTj8XPueOnk/Fz5alPPON1ZfvUkvsqc843Vl+9SS+ypuK/CZZ0YfVOzxuTrOFrq1mQdUW2A7Baiid3tFntKypLMg8m4d1KzvhSU5B844V5mLxtGnvtxrjojTbdveUG5K29TPOqS0ThZCDBSFHBPilQz0ZHTUh55xurL96kl9lTnnG6sv3qSX2VNzieGUyy1/Ye5msWnp+mJDOo9TyG9MSQ9ZokmehbEJvcUhTCU8mN5soUUZXvLCQAlaeOZDF2N2y37NLtomDdrvBgXJ2W67NjvNplo75fW86lC+T3UglxSQd3ISenPjVn+ecbqy/epJfZVjb9tY0/paG3LvJuVpiuOojofnWuSyhTizhCApTYBUo8AOk03Ffhlcs6MdC2G6as92lzLP31ZGJlmTY5VvgLQmM+yhO4ytSSknlW0EpSsEcDg7wAxzkbENMT9EaM0rOZeuFt0m7Bety5CklzfiJCWlLISArIGFAAA5PAVIOecbqy/epJfZU55xurL96kl9lTcV+EyzoxeoL1r6Jd5DVl0nYrlbE7vIypmoXYrq/FGd5tMNwJwcj8c5AB4ZwOqw6Ok3TWEDXGoIaLTqWLbZFoEGBP77icg4826VlamW1FeWk+QAAnp6Rmeecbqy/epJfZU55xurL96kl9lTc4nhlMsoS53Oen02S2w4d1vdrn2y5TbnBvMKS2iZGcluLcfQlRbKC2rfI3VIPBKc5IzXB3uatLL0kxZm5l5jz2boq9p1GzNxdO/1DdXILpSQVKSdwpKd3dwN3gKnPPON1ZfvUkvsqc843Vl+9SS+ypuK/CuWdEEZ7mnTLtp1XBu1zvmoF6kejSZc25TEmS29HQEsusuNoQW1J3UkY4AjAAHCpboLZ8vQ3fqndUah1O9KDaS7fpiHuSSjewEJQhCU53jk4yrAyTgV7uecbqy/epJfZU55xurL96kl9lTcVx/GTLOjuk+/3TH6kv8A001PKhdhhyb7qCLeHYciBChNOtsIlo3HXlr3cr3OlCUhJHjYJKjwAAKppXJtMxemnSPrM/VJKUpXGhSlKBSlKBSlKBVd+7m+COxfSq0/eBViKrv3c3wR2L6VWn7wKCxFKUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoFV37ub4I7F9KrT94FWIqu/dzfBHYvpVafvAoLEUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUritaWxlSgkecnFcO+mfzzf7wq2kdtfMjur+7hueo3pmzy8bOfANysF/YkPvC9F8OGM7vYSkx0eKsAEKz0EHBr6Zd9M/nm/3hXzu/pONga517sW0jT0UypE9bdnubEZO+pbvRHdwBklQ9zJ/utgcTS0iyvck91VJ7qOBqWavRq9LRLQ5HZbeNw77TKW4HCtIPJN7pQEoJ6f6wdHlsDWqO5n2RQdg2xuw6UQtg3BDffNyebUCHpbgBcOfKBwQD+ShNbS76Z/PN/vClpHbSurvln86j94V20sFKUqBSlKBSlKBSlKBSlKDg66hhpbrq0ttoSVKWs4CQOkk+QVo7WO1O46jkOMWaS7bLOk4S+14r8kflZIy2k+TGFcMkjO7Uq26XhyLp2FaWlbpukjk3uOMsISVrH1kISR5lGtR163ojYaKqOsYkX0+5PB4nrLBkul2RFblPKGFOyRyq1eXipWSftrhzetXVkP0dHsrIUr1l5jhEpmnVj+b1q6sh+jo9lOb1q6sh+jo9lYbVG1DTGjZ4hXa58hK5PllNNR3Xy03xwtzk0q5NPA8VYHA+aum87W9J2KS1HlXYLfeiIntNxI7slTkdZUEupDSVbyfEVkjo4E4BGdc49EXia+zzLzqz/N61dWQ/R0eynN61dWQ/R0eysPd9p2mLHZLZdpV2b7xue73kthC31ycjeHJoQlSlcOJwOHlxXi2U6+XtFs93uJ5AxmLtKhxVsIUjfYbXhtSgok7xB49HzCm/pmqKIq4l51SYaetQORbYef/Aj2V7rSX9OrDlmlP2dY6BDXut/W3xQr60mv2lZ1fnjLVxgzTq3Ts42k851G2XNLce8NpKkFvg3JQOlSQehQ8qfrHDOJ7VVX50i0lu5wziZAWJTJzjKk9KT+hQ3kn9CjVpIUtufDYksneZebS4g+dJGR/nXhOldip2WuK8P9NXdpLLti7upSlfCQpSlApSlApSlBqbb5FUBpud/ZNyHYyjjoLje8n5v6oj5yPPWsqsfqvTcfVtgl2uSotofSNx1I8ZpYIKFj9KVAH6qrvdLZN0/c3Lbc2gxNb4gpzuPJ8i2yelJ+0dBwa9v0NtNNeDuP5U35dpPGHRSojJ2QaHmyXZEjSNlefdWXHHHILZUtROSSccSTXWdjGgicnRtjJ/8AXtf7a+5fE0jn/jBrXUOnnLDtN1dNvNr1hcIF5MeRBkaXkygg7jKW1suoZcSEkFOQpfAhXSKlGjdIJ01tVZRb7XLhWKPpONDjqeSpSW1CS6rki4SQVgEEjJOCPJWy7bbIlmgMQoEZqHDYTuNMMICEIT5gBwAr01op2ammrN5359vFVcNBWy8aCb2fX+5acu86FGtM21uxYsJbsmA6uSFocLON/dUhO7kDgMeQ1srYhHmN2fUsiZbplrM3UU+W0xPZLTnJrc3kq3T5CPKOFbFrCai0Pp7VzjDl7skC7LYBS0qbHQ6UA9IG8DjOBWOHs84Nppm9vtEfQZulQz8C2gc+8yxer2v9tZjT2idPaPVIcstlt9nLwAeVDjoa3wM43t0DOMn7a6onEvxiOf8AiMjdXeQtkpeCohpWEgZKjjgAPKSeFWg09b12mwW2CsgrjRmmVEedKAD/AJVprZlod3VF0i3eU2UWaG6HWt8Y77dTxSU+dCThWfKpIAyAa3rXkem9ppxKqcGmb5b3+ejZ2RYpSleZQpSlApSlApSlArG37Tdr1PDEW6wmZrIO8kOJ8ZCvykqHFJ/SCDWSpWVNU0Tmpm0jWcnYLZ1uExrxeYSPI0h5p1I+txtSvtNdH4AYPylvf2RewradK+hHSW1xw3krdqz8AMH5S3v7IvYU/ADB+Ut7+yL2FbTpV/E9r/s9vsXas/ADB+Ut7+yL2FPwAwflLe/si9hW06U/E9r/ALPb7F2rRsCggjOpL2R5sRewrKWjYnpu3OJclplXtaeIFydC0fW2kJQfrSan1Kwq6Q2quLTiT7exdxQhLaQlICUgYAAwAK5UpXz0KUpQKUpQf//Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "from src.utils import get_pdf_contents, get_oai_response\n",
    "\n",
    "# Detailed Read \n",
    "\n",
    "# Loading Paper from the Cave \n",
    "dir_path = \"cave/paper\"\n",
    "files = glob.glob(dir_path + \"/*.pdf\")\n",
    "\n",
    "# Reading Paper one by one \n",
    "for file in files: \n",
    "    imgs = get_pdf_contents(file, first_page=1, last_page=3)\n",
    "    get_oai_response(prompt=\"What is the main idea of this paper?\", img=imgs, img_type=\"image/png\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
